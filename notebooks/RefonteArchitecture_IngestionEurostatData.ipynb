{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e66d9e-7d3f-40fe-99cb-3e8926ad10de",
   "metadata": {},
   "source": [
    "## Recupérer les tables Eurostat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33945fab-3482-457d-a9f7-ffa6b8f92ff3",
   "metadata": {},
   "source": [
    "### Références\n",
    "\n",
    "* https://cran.r-project.org/web/packages/eurostat/index.html\n",
    "* https://cran.r-project.org/package=maptools\n",
    "* http://ropengov.github.io/eurostat/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a7ffa-6a47-462d-bac9-7a95dce9b01c",
   "metadata": {},
   "source": [
    "### Session Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "222605aa-bb20-4455-98a3-9ac14cb7dc6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R version 4.2.2 Patched (2022-11-10 r83330)\n",
       "Platform: x86_64-pc-linux-gnu (64-bit)\n",
       "Running under: Debian GNU/Linux 12 (bookworm)\n",
       "\n",
       "Matrix products: default\n",
       "BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.11.0\n",
       "LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.11.0\n",
       "\n",
       "locale:\n",
       " [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n",
       " [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n",
       " [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n",
       "[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       " [1] fansi_1.0.6     crayon_1.5.2    digest_0.6.34   utf8_1.2.4     \n",
       " [5] IRdisplay_1.1   repr_1.1.6      lifecycle_1.0.4 jsonlite_1.8.8 \n",
       " [9] evaluate_0.23   pillar_1.9.0    rlang_1.1.3     cli_3.6.2      \n",
       "[13] uuid_1.2-0      vctrs_0.6.5     IRkernel_1.3.2  tools_4.2.2    \n",
       "[17] glue_1.7.0      fastmap_1.1.1   compiler_4.2.2  base64enc_0.1-3\n",
       "[21] pbdZMQ_0.3-11   htmltools_0.5.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Session Info\n",
    "sessionInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b6a09-0a3a-4ad1-b0bd-adb1c2dce9f7",
   "metadata": {},
   "source": [
    "### Résoudre les dépendances externes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1057905-7248-4714-821b-b510919c22eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n",
    "# # other repos we could try: https://github.com/search?q=options%28repos+%3D+c%28CRAN+%3D+&type=code\n",
    "# # \"http://cran.stat.ucla.edu\", \"http://cloud.r-project.org\", \"http://cran.us.r-project.org\"\n",
    "\n",
    "# -----------\n",
    "# Warning message:\n",
    "# “unable to access index for repository http://cran.stat.ucla.edu/src/contrib:\n",
    "#   cannot open URL 'http://cran.stat.ucla.edu/src/contrib/PACKAGES'”Updating HTML index of packages in '.Library'\n",
    "# options(repos = c(CRAN = c(\"http://cloud.r-project.org\", \"http://cran.us.r-project.org\", \"http://cran.stat.ucla.edu\")))\n",
    "options(repos = c(CRAN = c(\"http://cloud.r-project.org\", \"http://cran.us.r-project.org\")))\n",
    "\n",
    "\n",
    "# see https://github.com/jupyter/docker-stacks/blob/main/images/minimal-notebook/Rprofile.site\n",
    "# Add R mimetype to specify how the plot returns from R to the browser.\n",
    "# https://notebook.community/andrie/jupyter-notebook-samples/Changing%20R%20plot%20options%20in%20Jupyter\n",
    "\n",
    "options(jupyter.plot_mimetypes = c('text/plain', 'image/png', 'image/jpeg', 'image/svg+xml', 'application/pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec5f975-9699-48d8-a507-b08171e568b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Télécharger et installer tous les packages dans R_LIBS_SITE\n",
    "#\n",
    "# Ce fichier n'est à executer qu'une seule fois (sauf en cas d'erreur ou il faut le relancer plusieurs fois\n",
    "# car il compile certaine packages qui deviennent alors disponibles)\n",
    "\n",
    "# Option pour éviter le warning : the 'wininet' method is deprecated for http\n",
    "options(download.file.method = \"auto\")\n",
    "\n",
    "# Fonction install_github()\n",
    "# jb: you can use remotes::install_github() instead  of using devtools to have install_github available, see https://stackoverflow.com/questions/75449981/r-does-not-let-me-install-packages\n",
    "install.packages(\"remotes\")\n",
    "# install.packages(\"devtools\")\n",
    "\n",
    "# Pour EuroStat\n",
    "install.packages(\"glue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e24c7f-6594-4785-96e4-f267e9019509",
   "metadata": {},
   "source": [
    "#### Analyse dépednance: le package `aryoda/tryCatchLog`\n",
    "\n",
    "* _source: https://github.com/aryoda/tryCatchLog_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code soruce de ce package, date d'il y a presque 2 ans, exactment en date du `Jan 27, 2023`, commit hash `7943c0ec1e1064208f16fd6be59e718d1916610f`\n",
    "* la dernière publication sur le repository CRAN date de 2021, le `2021-10-25`\n",
    "* url CRAN repository: https://cran.r-project.org/web/packages/tryCatchLog/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.1.0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc06df6-ffba-4aee-a5db-af2c71485afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tryCatchLog\")\n",
    "# browseVignettes(\"tryCatchLog\")  # to show the vignette(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87804bf4-b4d3-4d39-b80b-6c1eef836871",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `sp`\n",
    "\n",
    "* _source: https://github.com/edzer/sp_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Jan 29, 2024`, commit hash `e60dedf3ff3d06d9ebd9d38818b072e4475758cf`\n",
    "* la dernière publication sur le repository CRAN date de 2024, le `2024-01-30`\n",
    "* url CRAN repository: https://cran.r-project.org/web/packages/sp/index.html\n",
    "* github pages: https://edzer.github.io/sp/\n",
    "* version minimale requise de `R`: `R (≥ 3.5.0), methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4812e2-aa96-47f0-baba-003bd34c04e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"sp\")\n",
    "# browseVignettes(\"sp\")  # to show the vignette(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44dab54-638e-4c37-8a84-287f9589ae9c",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `maptools`\n",
    "\n",
    "* _source: https://github.com/ropensci/maptools_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a près de 8 ans, exactment en date du `Apr 4, 2016`, commit hash `7b21eceb1642e5d7661b1153c8b3777893d9c932`\n",
    "* la dernière publication sur les archives du repository CRAN date de 2023, le `2023-07-18 21:10` (ah tiens le jour de mon anniversaire, merci pour le cadeau... https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\n",
    "* url CRAN repository (package is archived) : was at https://cran.r-project.org/web/packages/maptools/index.html archived at https://cran.r-project.org/src/contrib/Archive/maptools/\n",
    "* version minimale requise de `R`: `?`\n",
    "* lors du chargement des dépendances, l'exécution de `library(maptools)` donne le message de warning important suivant:\n",
    "\n",
    "```bash\n",
    "Please note that 'maptools' will be retired during October 2023,\n",
    "plan transition at your earliest convenience (see\n",
    "https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\n",
    "for guidance);some functionality will be moved to 'sp'.\n",
    "```\n",
    "\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 1376705 bytes (1.3 MB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 1.3 MB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | ERROR: dependency ���foreign��� is not available for package ���maptools���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/maptools���\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `foreign` :\n",
    "    * see https://cran.r-project.org/web/packages/foreign/index.html\n",
    "    * https://svn.r-project.org/R-packages/trunk/foreign/\n",
    "    * version minimale requise de `R`: `R (≥ 4.0.0)`\n",
    "* après le fix no1: succès de l'installation du package maptools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbbe316-d933-498e-916c-3ac3ee55ac8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de \"maptools\" - fix no. 1 \n",
    "\n",
    "install.packages(\"foreign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef559eb-cb55-47fb-9a19-1420413379dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "\n",
    "# install.packages(\"maptools\")\n",
    "\n",
    "urlMaptools <- \"https://cran.r-project.org/src/contrib/Archive/maptools/maptools_1.1-8.tar.gz\"\n",
    "install.packages(urlMaptools, type=\"source\", repos=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f019385-7729-414b-bd16-7286a042b62e",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `rgdal`\n",
    "\n",
    "* _source: https://github.com/cran/rgdal_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a 10 mois, exactment en date du `May 31, 2023`, commit hash `5098f49a1c55782b6f52cda94f7a4750b7258ca0`\n",
    "* la dernière publication sur les archives du repository CRAN date de 2023, le `2023-06-01 00:30` https://cran.r-project.org/src/contrib/Archive/rgdal/rgdal_1.6-7.tar.gz\n",
    "* url CRAN repository (package is archived) : was at https://cran.r-project.org/web/packages/rgdal/index.html archived at https://cran.r-project.org/src/contrib/Archive/rgdal/\n",
    "* version minimale requise de `R`: `?`\n",
    "\n",
    "<!--\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `foreign` :\n",
    "    * see https://cran.r-project.org/web/packages/foreign/index.html\n",
    "    * https://svn.r-project.org/R-packages/trunk/foreign/\n",
    "    * version minimale requise de `R`: `R (≥ 4.0.0)`\n",
    "* après le fix no1: succès de l'installation du package maptools \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d795fcb8-36fd-41c3-a6a3-0a608e027ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "\n",
    "# install.packages(\"rgdal\")\n",
    "\n",
    "urlRgdal <- \"https://cran.r-project.org/src/contrib/Archive/rgdal/rgdal_1.6-7.tar.gz\" # “installation of package ‘/tmp/Rtmpymdyxy/downloaded_packages/rgdal_1.6-7.tar.gz’ had non-zero exit status”\n",
    "\n",
    "# urlRgdal <- \"https://cran.r-project.org/src/contrib/Archive/rgdal/rgdal_1.6-6.tar.gz\" # “installation of package ‘/tmp/RtmpgYEDV8/downloaded_packages/rgdal_1.6-6.tar.gz’ had non-zero exit status”\n",
    "# urlRgdal <- \"https://cran.r-project.org/src/contrib/Archive/rgdal/rgdal_1.6-5.tar.gz\"\n",
    "\n",
    "install.packages(urlRgdal, type=\"source\", repos=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d11829-ecca-42c5-a765-d2ac58634c3f",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `tidyr`\n",
    "\n",
    "* _source: https://github.com/tidyverse/tidyr_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Jan 24, 2024`, commit hash `c6c126a61f67a10b5ab9ce6bb1d9dbbb7a380bbd`\n",
    "* la dernière publication sur le repository CRAN date de 2024, le `2024-01-24`\n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/tidyr/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.6)`\n",
    "\n",
    "<!--\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `foreign` :\n",
    "    * see https://cran.r-project.org/web/packages/foreign/index.html\n",
    "    * https://svn.r-project.org/R-packages/trunk/foreign/\n",
    "    * version minimale requise de `R`: `R (≥ 4.0.0)`\n",
    "* après le fix no1: succès de l'installation du package maptools \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97cc5308-daf1-4a09-add6-97d5249138f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "\n",
    "# install.packages(\"tidyr\")\n",
    "\n",
    "# au lieu de # install.packages(\"tidyr\"), cf. https://github.com/decoder-leco/decoderleco_deces_europe_reloaded/issues/5#issuecomment-2000628831\n",
    "urlTidyr <- \"https://cran.r-project.org/src/contrib/Archive/tidyr/tidyr_1.3.0.tar.gz\"\n",
    "install.packages(urlTidyr, type=\"source\", repos=NULL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271dcd75-6a50-4a09-a0c7-93be09aa4cbd",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `maps`\n",
    "\n",
    "* _source (archived only): https://cran.r-project.org/src/contrib/Archive/maps/_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 2 ans, exactment en date du `2022-10-31 00:27`, pas de commit hash le code source est uniquement archivé sur https://cran.r-project.org/src/contrib/Archive/maps/\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2023-12-15 13:40` https://cran.r-project.org/src/contrib/maps_3.4.2.tar.gz\n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/maps/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.5.0)`\n",
    "\n",
    "<!--\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `foreign` :\n",
    "    * see https://cran.r-project.org/web/packages/foreign/index.html\n",
    "    * https://svn.r-project.org/R-packages/trunk/foreign/\n",
    "    * version minimale requise de `R`: `R (≥ 4.0.0)`\n",
    "* après le fix no1: succès de l'installation du package maptools \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9224f0a0-760c-4b2c-bef6-20f31712a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "\n",
    "install.packages(\"maps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6b68a1-b531-428f-b846-3d649a9d47cf",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `eurostat`\n",
    "\n",
    "* _source: https://github.com/rOpenGov/eurostat_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Dec 20, 2023`, commit hash `246da7275dd67602bb045430049dddad0a35ca69`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `\t2023-12-19` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/eurostat/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.6.0)`\n",
    "* github pages: http://ropengov.github.io/eurostat/\n",
    "\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "ERROR: dependencies ���curl���, ���httr2���, ���RefManageR���, ���regions���, ���xml2��� are not available for package ���eurostat���\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `R` `curl` :\n",
    "    * see https://cran.r-project.org/web/packages/curl/index.html\n",
    "    * https://jeroen.r-universe.dev/curl\n",
    "    * https://curl.se/libcurl/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.0)`\n",
    "  * installer le package `R` `httr2` :\n",
    "    * see https://cran.r-project.org/web/packages/httr2/index.html\n",
    "    * https://github.com/r-lib/httr2\n",
    "    * https://httr2.r-lib.org/\n",
    "    * version minimale requise de `R`: `R (≥ 3.6)`\n",
    "  * installer le package `R` `xml2` :\n",
    "    * see https://cran.r-project.org/web/packages/xml2/index.html\n",
    "    * https://github.com/r-lib/xml2\n",
    "    * dernière date de publication sur le repository CRAN: `2023-12-04`\n",
    "    * version minimale requise de `R`: `R (≥ 3.6.0)`\n",
    "  * installer le package `R` `RefManageR` :\n",
    "    * see https://cran.r-project.org/web/packages/RefManageR/index.html\n",
    "    * https://github.com/ropensci/RefManageR/\n",
    "    * dernière date de publication sur le repository CRAN: `2022-09-30`\n",
    "    * version minimale requise de `R`: `R (≥ 3.0)`\n",
    "\n",
    "  * installer le package `R` `regions` :\n",
    "    * see https://cran.r-project.org/web/packages/regions/index.html\n",
    "    * https://github.com/rOpenGov/regions\n",
    "    * dernière date de publication sur le repository CRAN: `2021-06-21`\n",
    "    * version minimale requise de `R`: `R (≥ 2.10)`\n",
    "* après le fix no1: succès de l'installation du package `eurostat`, ave pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'http://cloud.r-project.org/src/contrib/eurostat_4.0.0.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 257270 bytes (251 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 251 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���eurostat��� ...\n",
    "jupyter_deno_1       | ** package ���eurostat��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** data\n",
    "jupyter_deno_1       | *** moving datasets to lazyload DB\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (eurostat)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/Rtmpg6XNC1/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "<!--\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7010cc0-2c89-47d2-9c63-95d3908203d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de eurostat - fix no.1 \n",
    "\n",
    "install.packages(\"curl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae15270e-0c0c-47eb-a472-b8cabc2ff6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de eurostat - fix no.1 \n",
    "\n",
    "install.packages(\"httr2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d70dcc-6aa7-4f6c-b859-8983e10b39bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de eurostat - fix no.1 \n",
    "\n",
    "install.packages(\"xml2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c610a0e-6252-44de-9d2e-e5ad8873d6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de eurostat - fix no.1 \n",
    "\n",
    "install.packages(\"RefManageR\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6f2b75-e7f1-45fe-911a-e3f0553f4a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de eurostat - fix no.1 \n",
    "\n",
    "install.packages(\"regions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d22c56e-8512-46fa-9200-25509306cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "\n",
    "# Enable this universe\n",
    "# options(repos = c(\n",
    "#   ropengov = \"https://ropengov.r-universe.dev\",\n",
    "#   CRAN = \"https://cloud.r-project.org\"\n",
    "# ))\n",
    "\n",
    "install.packages(\"eurostat\")\n",
    "\n",
    "# urlEurostat <- \"https://cloud.r-project.org/src/contrib/eurostat_4.0.0.tar.gz\"\n",
    "# install.packages(urlEurostat, type=\"source\", repos=NULL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbe08c-420b-4988-b631-7dadc6099920",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `leaflet`\n",
    "\n",
    "* _source: https://github.com/rstudio/leaflet_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Feb 19, 2024`, commit hash `dc772e780317481e25335449b957c5f50082bcfd`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2023-11-13` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/leaflet/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.1.0)`\n",
    "* github pages: https://rstudio.github.io/leaflet/\n",
    "* l'installation est particulièrement plus longue que les packages précédents, notamment en raison de nombreuses dépendances transitives, d'ordre N>2, qui doivent pour bcp être compilées.\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "ERROR: dependencies ���curl���, ���httr2���, ���RefManageR���, ���regions���, ���xml2��� are not available for package ���eurostat���\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `R` `curl` :\n",
    "    * see https://cran.r-project.org/web/packages/curl/index.html\n",
    "    * https://jeroen.r-universe.dev/curl\n",
    "    * https://curl.se/libcurl/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.0)`\n",
    "  * installer le package `R` `httr2` :\n",
    "    * see https://cran.r-project.org/web/packages/httr2/index.html\n",
    "    * https://github.com/r-lib/httr2\n",
    "    * https://httr2.r-lib.org/\n",
    "    * version minimale requise de `R`: `R (≥ 3.6)`\n",
    "  * installer le package `R` `xml2` :\n",
    "    * see https://cran.r-project.org/web/packages/xml2/index.html\n",
    "    * https://github.com/r-lib/xml2\n",
    "    * dernière date de publication sur le repository CRAN: `2023-12-04`\n",
    "    * version minimale requise de `R`: `R (≥ 3.6.0)`\n",
    "  * installer le package `R` `RefManageR` :\n",
    "    * see https://cran.r-project.org/web/packages/RefManageR/index.html\n",
    "    * https://github.com/ropensci/RefManageR/\n",
    "    * dernière date de publication sur le repository CRAN: `2022-09-30`\n",
    "    * version minimale requise de `R`: `R (≥ 3.0)`\n",
    "\n",
    "  * installer le package `R` `regions` :\n",
    "    * see https://cran.r-project.org/web/packages/regions/index.html\n",
    "    * https://github.com/rOpenGov/regions\n",
    "    * dernière date de publication sur le repository CRAN: `2021-06-21`\n",
    "    * version minimale requise de `R`: `R (≥ 2.10)`\n",
    "* après le fix no1: succès de l'installation du package `eurostat`, ave pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'http://cloud.r-project.org/src/contrib/eurostat_4.0.0.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 257270 bytes (251 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 251 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���eurostat��� ...\n",
    "jupyter_deno_1       | ** package ���eurostat��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** data\n",
    "jupyter_deno_1       | *** moving datasets to lazyload DB\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (eurostat)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/Rtmpg6XNC1/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a733c2eb-de99-4250-b2e4-dac5a6138aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"leaflet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8cda1a-7ee3-4a70-82cd-ba413c1a883e",
   "metadata": {},
   "source": [
    "#### Analyse dépedance: le package `questionr`\n",
    "\n",
    "* _source: https://github.com/juba/questionr_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 2 ans, exactment en date du `Jan 31, 2023`, commit hash `9dd36ad4b9d6e9a1b75da4a7acc685db40345d32`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2023-01-31` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/questionr/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.5.0)`\n",
    "* github pages: https://juba.github.io/questionr/\n",
    "* xxxxxx\n",
    "\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (labelled)\n",
    "jupyter_deno_1       | ERROR: dependency ���xtable��� is not available for package ���shiny���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/shiny���\n",
    "jupyter_deno_1       | ERROR: dependency ���shiny��� is not available for package ���miniUI���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/miniUI���\n",
    "jupyter_deno_1       | ERROR: dependencies ���shiny���, ���miniUI���, ���styler��� are not available for package ���questionr���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/questionr���\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `R` `xtable` :\n",
    "    * see https://cran.r-project.org/web/packages/xtable/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2019-04-21`\n",
    "    * http://xtable.r-forge.r-project.org/\n",
    "    * version minimale requise de `R`: `R (≥ 2.10.0)`\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "  * installer le package `R` `miniUI` :\n",
    "    * see https://cran.r-project.org/web/packages/miniUI/index.html\n",
    "    * https://cran.r-project.org/web/packages/miniUI/readme/README.html\n",
    "    * dernière date de publication sur le repository CRAN: `2018-05-18`\n",
    "    * version minimale requise de `R`: `?`\n",
    "  * installer le package `R` `styler` :\n",
    "    * see https://cran.r-project.org/web/packages/styler/index.html\n",
    "    * https://github.com/r-lib/styler\n",
    "    * dernière date de publication sur le repository CRAN: `2023-08-29`\n",
    "    * version minimale requise de `R`: `R (≥ 3.6.0)`\n",
    "\n",
    "* après le fix no1: succès de l'installation du package `questionr`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/questionr_0.7.8.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 3694621 bytes (3.5 MB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 3.5 MB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���questionr��� ...\n",
    "jupyter_deno_1       | ** package ���questionr��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** data\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (questionr)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38da9e6-a4af-45a4-b00a-513af8119241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de questionr - fix no.1 \n",
    "install.packages(\"xtable\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27729585-9160-4d8e-90a7-c6f8ae9d00f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de questionr - fix no.1 \n",
    "install.packages(\"shiny\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb5fef3f-cb84-4d82-9eb6-d0457cc56528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de questionr - fix no.1 \n",
    "install.packages(\"miniUI\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8bffddf-1cc8-4796-803c-375614d899d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de questionr - fix no.1 \n",
    "install.packages(\"styler\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f049b84a-f542-4ca7-b2a5-948a3a826fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"questionr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8678f1-0092-42a8-bf81-2eddce230d68",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `sf`\n",
    "\n",
    "* _source: https://github.com/r-spatial/sf_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Feb 22, 2024`, commit hash `bd1940f68dd7607b7e9098ccc32c99e273c30a60`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `\t2023-12-18` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/sf/index.html\n",
    "* version minimale requise de `R`: `methods, R (≥ 3.3.0)`\n",
    "* github pages: https://r-spatial.github.io/sf/\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "<!--\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "-->\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "<!-- \n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be4848e-0ec9-42d8-90c9-db7cf1fe6089",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# installation de fs - fix no.1 \n",
    "install.packages(\"units\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4579a601-a167-4355-84d9-8bb43b9a369c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"sf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a4f43b-3d03-4ebe-bcdc-3a7018f5dca0",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `rnaturalearth`\n",
    "\n",
    "* _source: https://github.com/ropensci/rnaturalearth_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Feb 16, 2024`, commit hash `fc39989bca3201acd9c39d227f1cc65e02640e58`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2023-12-15` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/rnaturalearth/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.1.1)`\n",
    "* github pages: http://ropensci.github.io/rnaturalearth/\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b5c26e-7f7d-4e85-8270-82768cf4e13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"rnaturalearth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71742aed-aafd-4aad-ba5a-6e7ffaa65a06",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `rgeos`\n",
    "\n",
    "* _source: ?_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, est inconnu\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2023-07-18 19:40`  https://cran.r-project.org/src/contrib/Archive/rgeos/rgeos_0.6-4.tar.gz\n",
    "* url CRAN repository archivé (il a été archivé) : https://cran.r-project.org/web/packages/rgeos/index.html https://cran.r-project.org/src/contrib/Archive/rgeos/\n",
    "* version minimale requise de `R`: `?`\n",
    "* github pages: ?\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea11346-47b3-430f-840e-4033e7fc1025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "# install.packages(\"rnaturalearth\")\n",
    "\n",
    "\n",
    "\n",
    "urlRgeos <- \"https://cran.r-project.org/src/contrib/Archive/rgeos/rgeos_0.6-4.tar.gz\"\n",
    "\n",
    "install.packages(urlRgeos, type=\"source\", repos=NULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2871bf-13a9-4b20-a331-8139edd609ef",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `rnaturalearthdata`\n",
    "\n",
    "* _source: https://github.com/ropensci/rnaturalearthdata_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a moins de 6 mois, exactment en date du `Feb 9, 2024`, commit hash `d0e161eafccd28c04b04f7fe7bd054f06b3b4ec9`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2024-02-09` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/rnaturalearthdata/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.1.1)`\n",
    "* doc: https://docs.ropensci.org/rnaturalearthdata/\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e31837-aab8-42a4-a2ee-d653de969072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"rnaturalearthdata\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43b760-20fe-467b-aef9-43495d9c49b6",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `lsr`\n",
    "\n",
    "* _source: https://github.com/djnavarro/lsr_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a plsu de 2 ans, exactment en date du `Dec 1, 2021`, commit hash `190d3f0854858e4c2284fcd6fbcdabcb691e5367`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2021-12-01` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/lsr/index.html\n",
    "* version minimale requise de `R`: `?`\n",
    "* doc: https://cran.r-project.org/web/packages/lsr/lsr.pdf\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dcb7bde-1213-4302-8b51-61d86858ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"lsr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf2a67-8988-431b-a0f0-c9b4ef89f716",
   "metadata": {},
   "source": [
    "#### Analyse dépendance: le package `reshape2`\n",
    "\n",
    "* _source: https://github.com/hadley/reshape_\n",
    "\n",
    "Notes:\n",
    "* le dernier commit sur le code source de ce package, date d'il y a plus de 2 ans, exactment en date du `Mar 8, 2021`, commit hash `b26d183e18aade8ed826927c04fa37d7be79924c`\n",
    "* la dernière publication sur le repository CRAN date de 2023, le `2020-04-09` \n",
    "* url CRAN repository : https://cran.r-project.org/web/packages/reshape2/index.html\n",
    "* version minimale requise de `R`: `R (≥ 3.1)`\n",
    "* doc: https://cran.r-project.org/web/packages/reshape2/reshape2.pdf\n",
    "\n",
    "\n",
    "\n",
    "<!-- \n",
    "_Dépilage des erreurs d'installation_\n",
    "\n",
    "* errreur 1:\n",
    "\n",
    "```bash\n",
    "\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... no\n",
    "jupyter_deno_1       | checking for udunits2/udunits2.h... no\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... no\n",
    "jupyter_deno_1       | configure: error: in `/tmp/RtmpvnVr4F/R.INSTALLccee313ede/units':\n",
    "jupyter_deno_1       | configure: error:\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |   Configuration failed because libudunits2.so was not found. Try installing:\n",
    "jupyter_deno_1       |     * deb: libudunits2-dev (Debian, Ubuntu, ...)\n",
    "jupyter_deno_1       |     * rpm: udunits2-devel (Fedora, EPEL, ...)\n",
    "jupyter_deno_1       |     * brew: udunits (OSX)\n",
    "jupyter_deno_1       |   If udunits2 is already installed in a non-standard location, use:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-lib=/usr/local/lib'\n",
    "jupyter_deno_1       |   if the library was not found, and/or:\n",
    "jupyter_deno_1       |     --configure-args='--with-udunits2-include=/usr/include/udunits2'\n",
    "jupyter_deno_1       |   if the header was not found, replacing paths with appropriate values.\n",
    "jupyter_deno_1       |   You can alternatively set UDUNITS2_INCLUDE and UDUNITS2_LIBS manually.\n",
    "jupyter_deno_1       | --------------------------------------------------------------------------------\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | See `config.log' for more details\n",
    "jupyter_deno_1       | ERROR: configuration failed for package ���units���\n",
    "jupyter_deno_1       | * removing ���/usr/local/lib/R/site-library/units���\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "* fix erreur 1:\n",
    "  * installer le package `Debian` `libudunits2-dev` :\n",
    "    * `docker-compose exec -T jupyter_deno bash -c 'apt-get update -y && apt-get install -y libudunits2-dev'`\n",
    "    * ajouter une cellule de notebook précédente à l'installation du package `fs`, qui installe le package `units` https://cran.r-project.org/web/packages/units/index.html\n",
    "    * lancer l'installation du package `units`\n",
    "    * relancer l'installation du package `fs`\n",
    "    * ajouter son installation dans le `Dockerfile` du JupyterLab\n",
    "  * installer le package `R` `shiny` :\n",
    "    * see https://cran.r-project.org/web/packages/shiny/index.html\n",
    "    * dernière date de publication sur le repository CRAN: `2023-11-17`\n",
    "    * https://github.com/rstudio/shiny\n",
    "    * https://shiny.posit.co/\n",
    "    * version minimale requise de `R`: `R (≥ 3.0.2), methods`\n",
    "\n",
    "* après le fix no1: \n",
    "\n",
    "  * succès de l'installation du package `units`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "jupyter_deno_1       | trying URL 'https://cloud.r-project.org/src/contrib/units_0.8-5.tar.gz'\n",
    "jupyter_deno_1       | Content type 'application/x-gzip' length 247974 bytes (242 KB)\n",
    "jupyter_deno_1       | ==================================================\n",
    "jupyter_deno_1       | downloaded 242 KB\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | * installing *source* package ���units��� ...\n",
    "jupyter_deno_1       | ** package ���units��� successfully unpacked and MD5 sums checked\n",
    "jupyter_deno_1       | ** using staged installation\n",
    "jupyter_deno_1       | configure: units: 0.8-5\n",
    "jupyter_deno_1       | checking whether the C++ compiler works... yes\n",
    "jupyter_deno_1       | checking for C++ compiler default output file name... a.out\n",
    "jupyter_deno_1       | checking for suffix of executables...\n",
    "jupyter_deno_1       | checking whether we are cross compiling... no\n",
    "jupyter_deno_1       | checking for suffix of object files... o\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C++... yes\n",
    "jupyter_deno_1       | checking whether g++ -std=gnu++14 accepts -g... yes\n",
    "jupyter_deno_1       | checking for g++ -std=gnu++14 option to enable C++11 features... none needed\n",
    "jupyter_deno_1       | checking for stdio.h... yes\n",
    "jupyter_deno_1       | checking for stdlib.h... yes\n",
    "jupyter_deno_1       | checking for string.h... yes\n",
    "jupyter_deno_1       | checking for inttypes.h... yes\n",
    "jupyter_deno_1       | checking for stdint.h... yes\n",
    "jupyter_deno_1       | checking for strings.h... yes\n",
    "jupyter_deno_1       | checking for sys/stat.h... yes\n",
    "jupyter_deno_1       | checking for sys/types.h... yes\n",
    "jupyter_deno_1       | checking for unistd.h... yes\n",
    "jupyter_deno_1       | checking for _Bool... no\n",
    "jupyter_deno_1       | checking for stdbool.h that conforms to C99... yes\n",
    "jupyter_deno_1       | checking for error_at_line... yes\n",
    "jupyter_deno_1       | checking for gcc... gcc\n",
    "jupyter_deno_1       | checking whether the compiler supports GNU C... yes\n",
    "jupyter_deno_1       | checking whether gcc accepts -g... yes\n",
    "jupyter_deno_1       | checking for gcc option to enable C11 features... none needed\n",
    "jupyter_deno_1       | checking for XML_ParserCreate in -lexpat... yes\n",
    "jupyter_deno_1       | checking for udunits2.h... yes\n",
    "jupyter_deno_1       | checking for ut_read_xml in -ludunits2... yes\n",
    "jupyter_deno_1       | configure: creating ./config.status\n",
    "jupyter_deno_1       | config.status: creating src/Makevars\n",
    "jupyter_deno_1       | ** libs\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c RcppExports.cpp -o RcppExports.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -I\"/usr/share/R/include\" -DNDEBUG -DUDUNITS2_DIR=0    -I'/usr/local/lib/R/site-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c udunits.cpp -o udunits.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o units.so RcppExports.o udunits.o -lexpat -lexpat -ludunits2 -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-units/00new/units/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (units)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "  * succès de l'installation du package `sf`, avec pour logs:\n",
    "\n",
    "```bash\n",
    "-library/Rcpp/include'    -fpic  -g -O2 -ffile-prefix-map=/build/r-base-wZDgjM/r-base-4.2.2.20221110=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2  -c zm_range.cpp -o zm_range.o\n",
    "jupyter_deno_1       | g++ -std=gnu++14 -shared -L/usr/lib/R/lib -Wl,-z,relro -o sf.so RcppExports.o bbox.o gdal.o gdal_geom.o gdal_read.o gdal_read_stream.o gdal_utils.o gdal_write.o geos.o hex.o mdim.o ops.o polygonize.o proj.o proj_info.o raster2sf.o sfc-sfg.o signed_area.o stars.o wkb.o zm_range.o -lproj -L/usr/lib/x86_64-linux-gnu -lgdal -L/usr/lib/x86_64-linux-gnu -lgeos_c -L/usr/lib/R/lib -lR\n",
    "jupyter_deno_1       | installing to /usr/local/lib/R/site-library/00LOCK-sf/00new/sf/libs\n",
    "jupyter_deno_1       | ** R\n",
    "jupyter_deno_1       | ** demo\n",
    "jupyter_deno_1       | ** inst\n",
    "jupyter_deno_1       | ** byte-compile and prepare package for lazy loading\n",
    "jupyter_deno_1       | in method for ���dbWriteTable��� with signature ���\"PostgreSQLConnection\",\"character\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���dbDataType��� with signature ���\"PostgreSQLConnection\",\"sf\"���: no definition for class ���PostgreSQLConnection���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sf\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"Spatial\",\"sfc\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sf\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sfc\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"XY\",\"Spatial\"���: no definition for class ���Spatial���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"crs\",\"CRS\"���: no definition for class ���CRS���\n",
    "jupyter_deno_1       | in method for ���coerce��� with signature ���\"sgbp\",\"sparseMatrix\"���: no definition for class ���sparseMatrix���\n",
    "jupyter_deno_1       | ** help\n",
    "jupyter_deno_1       | *** installing help indices\n",
    "jupyter_deno_1       | *** copying figures\n",
    "jupyter_deno_1       | ** building package indices\n",
    "jupyter_deno_1       | ** installing vignettes\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from temporary location\n",
    "jupyter_deno_1       | ** checking absolute paths in shared objects and dynamic libraries\n",
    "jupyter_deno_1       | ** testing if installed package can be loaded from final location\n",
    "jupyter_deno_1       | ** testing if installed package keeps a record of temporary installation path\n",
    "jupyter_deno_1       | * DONE (sf)\n",
    "jupyter_deno_1       |\n",
    "jupyter_deno_1       | The downloaded source packages are in\n",
    "jupyter_deno_1       |  ���/tmp/RtmpVRaKR9/downloaded_packages���\n",
    "\n",
    "```\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bdc9602-fe8e-4594-b560-5ba502e1ea21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/usr/local/lib/R/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dépendances de source(\"005_functions.R\")\n",
    "install.packages(\"reshape2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a3469-8233-47bc-b201-3a246cef1de4",
   "metadata": {},
   "source": [
    "### Résoudre les dépendances internes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e44531-c02f-475f-9c55-7dc9342e0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in Sys.setlocale(\"LC_ALL\", \"French\"):\n",
      "“OS reports request to set locale to \"French\" cannot be honored”\n",
      "futile.logger not found. Using tryCatchLog-internal functions for logging...\n",
      "\n",
      "Please note that 'maptools' will be retired during October 2023,\n",
      "plan transition at your earliest convenience (see\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\n",
      "for guidance);some functionality will be moved to 'sp'.\n",
      " Checking rgeos availability: TRUE\n",
      "\n",
      "\n",
      "Attaching package: ‘maptools’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:sp’:\n",
      "\n",
      "    sp2Mondrian\n",
      "\n",
      "\n",
      "Please note that rgdal will be retired during October 2023,\n",
      "plan transition to sf/stars/terra functions using GDAL and PROJ\n",
      "at your earliest convenience.\n",
      "See https://r-spatial.org/r/2023/05/15/evolution4.html and https://github.com/r-spatial/evolution\n",
      "rgdal: version: 1.6-7, (SVN revision 1203)\n",
      "Geospatial Data Abstraction Library extensions to R successfully loaded\n",
      "Loaded GDAL runtime: GDAL 3.6.2, released 2023/01/02\n",
      "Path to GDAL shared files: /usr/share/gdal\n",
      " GDAL does not use iconv for recoding strings.\n",
      "GDAL binary built with GEOS: TRUE \n",
      "Loaded PROJ runtime: Rel. 9.1.1, December 1st, 2022, [PJ_VERSION: 911]\n",
      "Path to PROJ shared files: /root/.local/share/proj:/usr/share/proj\n",
      "PROJ CDN enabled: FALSE\n",
      "Linking to sp version:2.1-3\n",
      "To mute warnings of possible GDAL/OSR exportToProj4() degradation,\n",
      "use options(\"rgdal_show_exportToProj4_warnings\"=\"none\") before loading sp or rgdal.\n",
      "\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    date, intersect, setdiff, union\n",
      "\n",
      "\n",
      "Linking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.1; sf_use_s2() is TRUE\n",
      "\n",
      "code for methods in class “Rcpp_SpatCategories” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatCategories” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatDataFrame” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatDataFrame” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatExtent” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatExtent” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatFactor” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatFactor” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatGraph” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatGraph” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatMessages” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatMessages” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatOptions” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatOptions” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRaster” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRaster” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRasterCollection” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRasterCollection” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRasterStack” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatRasterStack” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatSRS” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatSRS” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatTime_v” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatTime_v” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVector” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVector” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVectorCollection” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVectorCollection” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVectorProxy” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "code for methods in class “Rcpp_SpatVectorProxy” was not checked for suspicious field assignments (recommended package ‘codetools’ not available?)\n",
      "\n",
      "rgeos version: 0.6-4, (SVN revision 699)\n",
      " GEOS runtime version: 3.11.1-CAPI-1.17.1 \n",
      " Please note that rgeos will be retired during October 2023,\n",
      "plan transition to sf or terra functions using GEOS at your earliest convenience.\n",
      "See https://r-spatial.org/r/2023/05/15/evolution4.html for details.\n",
      " GEOS using OverlayNG\n",
      " Linking to sp version: 2.1-3 \n",
      " Polygon checking: TRUE \n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘rgeos’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    symdiff\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘rnaturalearthdata’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:rnaturalearth’:\n",
      "\n",
      "    countries110\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘reshape2’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    smiths\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘purrr’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:maps’:\n",
      "\n",
      "    map\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:rlang’:\n",
      "\n",
      "    %@%, flatten, flatten_chr, flatten_dbl, flatten_int, flatten_lgl,\n",
      "    flatten_raw, invoke, splice\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "################################################################################\n",
    "# Téléchargement et Gestion des fichiers\n",
    "################################################################################\n",
    "\n",
    "source(\"src/files/files.R\")\n",
    "source(\"src/files/directory.R\")\n",
    "source(\"005_functions.R\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a954e11-0867-4841-bbb7-3fb892113ac4",
   "metadata": {},
   "source": [
    "## EuroStat Data Ingestion\n",
    "\n",
    "_Exécution du code qui va chercher toutes les données EUROSTAT_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b234b81a-c864-4acd-9e2d-c3a9461c6baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Téléchargement et Gestion des fichiers\n",
    "################################################################################\n",
    "\n",
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### Preparer les espaces de generation de donnees ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Créer les repertoires\n",
    "if (!dir.exists(\"gen\")) dir.create(\"gen\")\n",
    "if (!dir.exists(\"gen/csv\")) dir.create(\"gen/csv\")\n",
    "\n",
    "if (!dir.exists(\"gen/images\")) dir.create(\"gen/images\")\n",
    "\n",
    "if (!dir.exists(\"gen/rds\")) dir.create(\"gen/rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb272fd-e797-4205-838c-db0ba8b0e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/eu/EuroStat//a__original_es_pjan_le2020.RDS) présent. On re-charge le fichier dans (a__original_es_pjan_le2020), sans le re-télécharger.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### recuperer les tables qui nous interessent chez EuroStat ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Demographie recensée au 1er janvier de chaque année (jusqu'en 2020 inclus)\n",
    "# time = année du recensement, \n",
    "# age = tranche d'âge, \n",
    "# values = population dans cette tranche d'âge à la date time\n",
    "a__original_es_pjan_le2020 <- a__f_downloadEuroStatIfNeeded(var = a__original_es_pjan_le2020, \n",
    "                                                            euroStatFileName = \"demo_pjan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5178c8-6912-40c3-882a-953202006207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/eu/EuroStat//a__original_es_deces_annuel_le2020.RDS) présent. On re-charge le fichier dans (a__original_es_deces_annuel_le2020), sans le re-télécharger.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Décès recensés au 1er janvier de chaque année (jusqu'en 2020 inclus)\n",
    "# time = année du recensement, \n",
    "# age = tranche d'âge des décès, \n",
    "# values = population dans cette tranche d'âge à être décédée\n",
    "a__original_es_deces_annuel_le2020 <- a__f_downloadEuroStatIfNeeded(var = a__original_es_deces_annuel_le2020, \n",
    "                                                                    euroStatFileName = \"demo_magec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb702c13-4fa6-481b-8e94-85d8a48bea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/eu/EuroStat//a__original_es_deces_week.RDS) présent. On re-charge le fichier dans (a__original_es_deces_week), sans le re-télécharger.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Décès par semaine (jusqu'en 2021 inclus)\n",
    "# time = année du recensement, \n",
    "# age = tranche d'âge des décès, \n",
    "# sex\n",
    "# values = population dans cette tranche d'âge à être décédée\n",
    "a__original_es_deces_week <- a__f_downloadEuroStatIfNeeded(var = a__original_es_deces_week, \n",
    "                                                           euroStatFileName = \"demo_r_mwk_05\") %>%\n",
    "  # Trier les lignes\n",
    "  arrange(geo, sex, time, age) %>%\n",
    "  # Reorganiser les colonnes\n",
    "  select(geo, sex, time, age, everything())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26aa330b-cb3c-4b7e-8639-c9a87b88ccf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projections de population depuis 2019\n",
    "# à télécharger manuellement car l'API ne fonctionne pas\n",
    "# sert à récupérer les populations 2022 et 2023\n",
    "\n",
    "a__original_es_proj <- read.csv(\"data/csv/proj_19np__custom_2224172_linear.csv\") %>% \n",
    "  select(-DATAFLOW,-LAST.UPDATE,-freq,-unit,-OBS_FLAG) %>% \n",
    "  filter(sex != \"T\", \n",
    "         age != \"TOTAL\",\n",
    "         projection ==\"BSL\") %>%\n",
    "  dplyr::rename(time = TIME_PERIOD,\n",
    "                population_proj = OBS_VALUE) %>% \n",
    "  mutate(time = as.Date(paste0(time,\"-01-01\")),\n",
    "         age = ifelse(age==\"Y_GE100\",\"Y_OPEN\",age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4ecaad-68b9-4ad1-b292-e4491f1a3023",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Recensement de la Population Européenne jusqu'en 2020 ou 2021 selon les pays ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Initialiser avec les données d'origine d'EuroStat\n",
    "es_pjan <- a__original_es_pjan_le2020\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ba0ce0-881f-41e6-a09f-b998f6020f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommer la colonne \"values\" en \"population\" et supprimer la colonne \"unit\" et freq\n",
    "es_pjan <- es_pjan %>%\n",
    "  dplyr::rename(population = values) %>% \n",
    "  select(-unit,-freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cdb3d31-cf26-421a-be82-984d3d41cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer :\n",
    "#  les totaux : sexe T (T = M+F) et age\n",
    "#  les UNKnown\n",
    "es_pjan <- es_pjan %>%\n",
    "  filter(sex != \"T\", \n",
    "         age != \"TOTAL\", \n",
    "         age != \"UNK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf97db0d-74fc-4661-a708-32309abd764e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, age, time)`\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Compléter la population avec les projections  ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "es_pjan_2021 <- es_pjan %>% filter(time==\"2021-01-01\")\n",
    "es_pjan_2021 <- es_pjan_2021 %>% inner_join(a__original_es_proj) %>% \n",
    "  mutate(erreur= (population_proj-population)/(population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9067d12e-903f-4e02-93fb-2fabef644ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On constate que les seules erreurs significatives concernent les naissances (Y_LT1, et les plus de 90 ans)\n",
    "#On décide de prendre comme population 2022, la population constatée 2021 évoluée de l'évolution de\n",
    "#la projection 2021 - 2022, pareil pour 2023 et 2024\n",
    "\n",
    "\n",
    "proj_2022 <- a__original_es_proj %>% filter(time==\"2022-01-01\")\n",
    "proj_2023 <- a__original_es_proj %>% filter(time==\"2023-01-01\")\n",
    "proj_2024 <- a__original_es_proj %>% filter(time==\"2024-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6924bbb-f837-4ff4-9d1f-cc866bf62404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(projection, sex, age, geo, time)`\n"
     ]
    }
   ],
   "source": [
    "proj_2022_2023 <- proj_2023 %>% mutate(time=time-years(1)) %>% \n",
    "  dplyr::rename(population_proj_suivante = population_proj) %>% \n",
    "  left_join (proj_2022) %>% \n",
    "  mutate(evol_pop2022_2023=(population_proj_suivante-population_proj)/population_proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a501b265-343e-4002-b8e4-050bc315e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(projection, sex, age, geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, age, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, age, time)`\n"
     ]
    }
   ],
   "source": [
    "proj_2023_2024 <- proj_2024 %>% mutate(time=time-years(1)) %>% \n",
    "  dplyr::rename(population_proj_suivante = population_proj) %>% \n",
    "  left_join (proj_2023) %>% \n",
    "  mutate(evol_pop2023_2024=(population_proj_suivante-population_proj)/population_proj)\n",
    "\n",
    "es_pjan_2023 <- es_pjan %>% filter(time==\"2022-01-01\") %>% \n",
    "  left_join(proj_2022_2023) %>% \n",
    "  mutate(population_finale = ifelse(is.na(evol_pop2022_2023),population,population + evol_pop2022_2023*population),\n",
    "         time=time+years(1))\n",
    "  \n",
    "es_pjan_2024 <- es_pjan_2023 %>% \n",
    "  select (geo,sex,age,time,population_finale) %>% \n",
    "  dplyr::rename(population = population_finale) %>% \n",
    "  left_join(proj_2023_2024) %>% \n",
    "  mutate(population_finale = ifelse(is.na(evol_pop2023_2024),population,population + evol_pop2023_2024*population),\n",
    "         time=time+years(1))\n",
    "\n",
    "es_pjan_2023 <- es_pjan_2023 %>% \n",
    "  select (geo,sex,age,time,population_finale) %>% \n",
    "  dplyr::rename(population = population_finale)\n",
    "\n",
    "es_pjan_2024 <- es_pjan_2024 %>% \n",
    "  select (geo,sex,age,time,population_finale) %>% \n",
    "  dplyr::rename(population = population_finale)\n",
    "\n",
    "es_pjan <- es_pjan %>% \n",
    "  rbind(es_pjan_2023) %>% \n",
    "  rbind(es_pjan_2024)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_2021)\n",
    "if (shallDeleteVars) rm(es_pjan_2023)\n",
    "if (shallDeleteVars) rm(es_pjan_2024)\n",
    "if (shallDeleteVars) rm(proj_2023_2024)\n",
    "if (shallDeleteVars) rm(proj_2022_2023)\n",
    "if (shallDeleteVars) rm(proj_2024)\n",
    "if (shallDeleteVars) rm(proj_2023)\n",
    "if (shallDeleteVars) rm(proj_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75917b2e-61f9-47b7-b699-f61626c20017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Calculer l'Age max par pays et année de rencensement ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Retirer le Y de l'age et le transformer en numérique\n",
    "es_pjan_age <- es_pjan %>%\n",
    "  filter(age != \"Y_LT1\",\n",
    "         age != \"Y_OPEN\") %>%\n",
    "  mutate(age = as.double(str_sub(age, 2, length(age))))\n",
    "\n",
    "# Calculer l'Age max par pays et année de rencensement\n",
    "es_age_max_pop <- es_pjan_age %>%\n",
    "  group_by(geo,\n",
    "           time) %>%\n",
    "  summarise(age_max = base::max(age))\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfc41bb-34e1-44a0-8aa8-ea01dd02f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Deces par pays, année de recensement (jusqu'en 2020 seulement) et tranche d'age de deces ####\n",
    "#\n",
    "# Voici les colonnes que l'on va petit à petit ajouter dans la variable \"es_deces_annuels\" :\n",
    "#\n",
    "#  geo\t\t\t\t\t\t: Indicatif du pays\n",
    "#  time\t\t\t\t\t\t: Année du recensement (Ex. 2013-01-01)\n",
    "#  population\t\t\t\t: Population du pays\n",
    "#  pop2020\t\t\t\t\t: Population lors du recensement 2020-01-01\n",
    "#  deces\t\t\t\t\t: Nombre de deces enregistrés durant l'année du recensement (2013)\n",
    "#  deces_theo_si_pop_2020\t\t\t: Décès théoriques qu'il y aurait dû avoir en 2020\n",
    "#  deces2020\t\t\t\t\t\t: Décès réels observés en 2020\n",
    "#  deces_theo_du_pays_si_pop_FR_2020\t\t: Décès que le pays aurait eu s'il avait la population de la France en 2020\n",
    "#\t\t\t\t\t\t\t  Devrait s'appeler : deces_theo_du_pays_si_pop_FR_2020\n",
    "#  surmortalite2020\t\t\t: Augmentation des décès entre 2019 et 2020 (AC)\n",
    "#\t\t\t\t\t\t\t  Devrait s'appeler : surmortalite2020\n",
    "#  location\t\t\t\t\t: Nom du pays\n",
    "#  zone\t\t\t\t\t\t: Est, Ouest\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Initialiser es_deces_annuels que l'on complètera au fur et à mesure dans le fichier\n",
    "b__es_deces_et_pop_par_annee <- a__original_es_deces_annuel_le2020\n",
    "\n",
    "# Filtrer age\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "  dplyr::rename(deces=values) %>% \n",
    "\t\tselect(-unit,-freq) %>%\n",
    "\t\tfilter( sex != \"T\",\n",
    "\t\t\t\tage != \"TOTAL\", \n",
    "\t\t\t\tage != \"UNK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4c8ae1-5a96-4b6e-b26e-1204c74717cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "## Recuperer lignes (pays, recensement) pour lesquels l'âge max des décès est inférieur à 89 ans ##\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Enlever le Y de l'age et le transformer en numérique\n",
    "es_deces_annuel_age <- b__es_deces_et_pop_par_annee %>% \n",
    "\t\tfilter(age !=\"Y_LT1\") %>% \n",
    "\t\tfilter(age !=\"Y_OPEN\") %>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EU\") %>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EEA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EFT\") %>% \n",
    "\t\tmutate(age = as.double(str_sub(age, 2, length(age)))) \n",
    "\n",
    "# Age max des deces par population, année de recensement\n",
    "es_deces_annuel_age_max <- es_deces_annuel_age %>%\n",
    "\t\tgroup_by(geo,\n",
    "\t\t\t\ttime) %>%\n",
    "\t\tsummarise(age_max = base::max(age))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age)\n",
    "\n",
    "\n",
    "# Recuperer lignes pays, recensement pour lesquels l'âge max des décès est inférieur à 89 ans\t\n",
    "\n",
    "es_deces_annuel_pb_age_max_deces <- es_deces_annuel_age_max %>%\n",
    "\t\tfilter(age_max < 89) %>% \n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EU\") %>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EEA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EFT\") %>% \n",
    "  dplyr::rename (age_max_deces=age_max)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8d6393d-fa14-49ce-b4e1-4fa524c68f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "## Recuperer lignes (pays, recensement) pour lesquels l'âge max des vivants est inférieur à 89 ans ##\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Récupérer les pays dont l'âge max de la population est < à 89 ans \n",
    "es_pjan_pb_age_max_pop <- es_age_max_pop %>% \n",
    "\t\tfilter(age_max < 89) %>% \n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EU\")%>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EEA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EFT\")%>% \n",
    "  dplyr::rename (age_max_pop = age_max)\n",
    "\n",
    "if (shallDeleteVars) rm(es_age_max_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b7c56c8-e7f4-4f4c-80af-b47c707fd3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "## Concaténer pays, recensements pour lesquels l'âge max des deces ou des vivants est de moins de 89 ans ##\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "es_pb_age_max <- full_join(es_deces_annuel_pb_age_max_deces,\n",
    "\t\tes_pjan_pb_age_max_pop,\n",
    "\t\tby=c(\"geo\", \"time\"))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_pb_age_max_deces)\n",
    "if (shallDeleteVars) rm(es_pjan_pb_age_max_pop)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cdc3d4ab-90cc-477f-9033-ec46271bcbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "## Retirer les lignes correspondant à des totaux et l'Italie avant 1981 (données incomplètes ?) ##\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# on filtre les vivants et les décès sur les zones geographiques \"spéciales\" \n",
    "# correspondant à des regroupements ou des totaux\n",
    "\n",
    "es_pjan<- es_pjan %>% \n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EU\")%>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EEA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EFT\") %>%\n",
    "\t\tfilter(geo!=\"DE_TOT\") %>%\n",
    "\t\tfilter(geo!=\"TR\")\n",
    "\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>% \n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EU\")%>%\n",
    "\t\tfilter(str_sub(geo,1,2)!=\"EA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EEA\") %>% \n",
    "\t\tfilter(str_sub(geo,1,3)!=\"EFT\") %>%\n",
    "\t\tfilter(geo!=\"DE_TOT\")%>%\n",
    "\t\tfilter(geo!=\"TR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "111bceee-c48d-4bad-a434-1542c39aa8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# On enleve les données de l'Italie, car les deces annuels n'étaient pas comptabilisés avant 1985 (AC) ?\n",
    "\n",
    "es_pjan <- es_pjan %>%\n",
    "\t\tfilter(!(geo == \"IT\" & time <= \"1981-01-01\"))\n",
    "\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tfilter(!(geo == \"IT\" & time <= \"1981-01-01\"))\n",
    "\n",
    "# On ne garde que ceux qui ont 84 et on enlève les ligne \"TR\"\n",
    "es_pb_age_max_deces_84 <- es_pb_age_max %>%\n",
    "\t\tfilter(age_max_deces == 84 | age_max_pop == 84 ) %>%\n",
    "\t\tfilter(geo != \"TR\")\n",
    "\n",
    "if (shallDeleteVars) rm(es_pb_age_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7763cb8c-5739-4885-af74-fc85912cb6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, age, time, population)`\n"
     ]
    }
   ],
   "source": [
    "#### traitement des tables de pop\n",
    "\n",
    "#table de pop : on partitionne en deux tables : \n",
    "#celle avec les couples (geo, time) traites en age quinquennal jusqu'à 90+\n",
    "#celle avec les couples (geo, time) traites en age quinquennal jusqu'à 85+\n",
    "\n",
    "# Ajouter les colonnes population par tranche d'age et sexe de es_pjan\n",
    "es_pb_age_max_85_pjan <- es_pb_age_max_deces_84 %>%\n",
    "\t\tleft_join(es_pjan)\n",
    "\n",
    "# Mettre dans es_pjan90, les lignes de es_pjan qui ne sont pas dans es_pjan85\n",
    "es_pjan90 <- es_pjan %>%\n",
    "\t\tanti_join(es_pb_age_max_85_pjan)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d65a8bb-d692-4686-974c-677ca7f91ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### Ajouter une colonne agequinq correspondant à la tranche d'âge ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "## traitement de es_pb_age_max_85_pjan ##\n",
    "\n",
    "# Ajouter une colonne avec la tranche d'âge quinquennale jusqu'à 85\n",
    "es_pjan85_quinq <- a__f_quinquenisation(es_pb_age_max_85_pjan, shallGroup_ge85 = TRUE)\n",
    "\n",
    "# Ne garder que la colonne population\n",
    "es_pjan85_quinq <- es_pjan85_quinq %>%\n",
    "\t\tgroup_by(geo, sex, agequinq, time) %>% \n",
    "\t\tsummarise(population=sum(population))\n",
    "\n",
    "if (shallDeleteVars) rm(es_pb_age_max_85_pjan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68351af-ecbe-48d8-91d7-c2e58611b444",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "## traitement de es_pjan90 ##\n",
    "\n",
    "# Ajouter une colonne avec la tranche d'âge quinquennale\n",
    "es_pjan90_quinq <- a__f_quinquenisation(es_pjan90, shallGroup_ge85 = FALSE)\n",
    "\n",
    "# Synthetiser et ne garder que la colonne population\n",
    "es_pjan90_quinq <- es_pjan90_quinq %>%\n",
    "\t\tgroup_by(geo, sex, agequinq, time) %>% \n",
    "\t\tsummarise(population = sum(population))\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7acbcd5f-8181-4697-82ee-4125d635b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, age, time, deces)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### traitement des tables de deces ##\n",
    "\n",
    "#table de deces : on partitionne en deux tables : celle avec les couples (geo, time) traites en age quinquennal jusqu'à 90+\n",
    "#celle vec les couples (geo, time) traites en age quinquennal jusqu'à 85+\n",
    "\n",
    "es_deces_annuel_age85 <- es_pb_age_max_deces_84 %>%\n",
    "\t\tleft_join(b__es_deces_et_pop_par_annee) %>%\n",
    "\t\tfilter(!is.na(age))\n",
    "\n",
    "#prendre tous ceux qu'on n'a pas déjà pris dans les 85\n",
    "es_deces_annuel_age90 <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tanti_join(es_deces_annuel_age85)\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_pb_age_max_deces_84)\n",
    "if (shallDeleteVars) rm(b__es_deces_et_pop_par_annee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "107fddf6-4ce3-4438-80d1-23dbfea71f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### traitement de deces_annuel_age85 ###\n",
    "\n",
    "#mettre en age quinquennal\n",
    "\n",
    "# Ajouter une colonne avec la tranche d'âge quinquennale jusqu'à 85\n",
    "es_deces_annuel_age85_quinq <- a__f_quinquenisation(es_deces_annuel_age85, shallGroup_ge85 = TRUE)\n",
    "\n",
    "\n",
    "es_deces_annuel_age85_quinq <- es_deces_annuel_age85_quinq %>%\n",
    "\t\tgroup_by(geo, sex, agequinq, time) %>% \n",
    "\t\tsummarise(deces=sum(deces))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age85)\n",
    "\n",
    "\n",
    "## traitement de deces_annuel_age90 #\n",
    "\n",
    "# Ajouter une colonne avec la tranche d'âge quinquennale\n",
    "es_deces_annuel_age90_quinq <- a__f_quinquenisation(es_deces_annuel_age90, shallGroup_ge85 = FALSE)\n",
    "\n",
    "es_deces_annuel_age90_quinq <- es_deces_annuel_age90_quinq %>%\n",
    "\t\tgroup_by(geo, sex, agequinq, time) %>% \n",
    "\t\tsummarise(deces=sum(deces))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdff779e-47a6-40de-a3d3-07f22ebd3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### on concatene les tables 85 et 90 et on sauvegarde ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "es_deces_annuel_agequinq_le2020 <- bind_rows(es_deces_annuel_age90_quinq, es_deces_annuel_age85_quinq) %>%\n",
    "\t\t# Trier les lignes selon les colonnes\n",
    "\t\tarrange(geo, agequinq, sex, time)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age90_quinq)\n",
    "if (shallDeleteVars) rm(es_deces_annuel_age85_quinq)\n",
    "\n",
    "es_pjan_quinq <- bind_rows(es_pjan90_quinq, es_pjan85_quinq) %>%\n",
    "\t\t# Trier les lignes selon les colonnes\n",
    "\t\tarrange(geo, agequinq, sex, time)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan85_quinq)\n",
    "if (shallDeleteVars) rm(es_pjan90_quinq)\n",
    "\n",
    "# es_pjan_quinq indique la population pour chaque pays, chaque recensement, chaque tranche d'age \n",
    "# avec les tranches Y_GE85 et Y_GE90\n",
    "\n",
    "write.table(es_pjan_quinq, \"gen/csv/Eurostat_pjanquinq.csv\", row.names=FALSE, sep=\"t\", dec=\",\", na=\" \")\n",
    "\n",
    "saveRDS(es_pjan_quinq, file=\"gen/rds/Eurostat_pjanquinq.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea8c6fe-5b06-4f6a-aeda-d353d2a7171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex'. You can override using the\n",
      "`.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### on joint les deces et les populations ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "es_deces_et_pop_annuel_by_agequinq <- es_deces_annuel_agequinq_le2020 %>%\n",
    "\t\tinner_join(es_pjan_quinq, by=c(\"sex\", \"geo\", \"agequinq\", \"time\"))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_annuel_agequinq_le2020)\n",
    "\n",
    "#ajouter la population de l'annee 2020 correspondant du pays dans chaque pays*sexe*age*annee\n",
    "\n",
    "es_pjan_quinq_2020 <- es_pjan_quinq %>%\n",
    "\t\tfilter(time == \"2020-01-01\") %>%\n",
    "  dplyr::rename(pop2020=population) %>%\n",
    "\t\tselect(-time)\n",
    "\n",
    "es_pjan_quinq_2020_ge85 <- es_pjan_quinq_2020 %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y_GE90\", \"Y85-89\"))\n",
    "\n",
    "es_pjan_quinq_2020_ge85_85 <- es_pjan_quinq_2020_ge85 %>%\n",
    "\t\tmutate(agequinq=\"Y_GE85\") %>%\n",
    "\t\tgroup_by(geo, sex, agequinq) %>%\n",
    "\t\tsummarise(pop2020=sum(pop2020))\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2020_ge85)\n",
    "\n",
    "es_pjan_quinq_2020_popTot <- bind_rows(es_pjan_quinq_2020, es_pjan_quinq_2020_ge85_85) %>%\n",
    "\t\t# Trier les lignes selon les colonnes\n",
    "\t\tarrange(geo, agequinq, sex)\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2020)\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2020_ge85_85)\n",
    "\n",
    "es_deces_et_pop_annuel_by_agequinq <- es_deces_et_pop_annuel_by_agequinq %>%\n",
    "\t\tleft_join(es_pjan_quinq_2020_popTot, by=c(\"sex\", \"geo\", \"agequinq\"))\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2020_popTot)\n",
    "\n",
    "es_deces_et_pop_annuel_by_agequinq <- es_deces_et_pop_annuel_by_agequinq %>%\n",
    "\t\tfilter(str_sub(geo, 1, 2) != \"EU\") %>%\n",
    "\t\tfilter(str_sub(geo, 1, 2) != \"EA\") %>%\n",
    "\t\tfilter(str_sub(geo, 1, 3) != \"EEA\") %>%\n",
    "\t\tfilter(geo != \"EFTA\") %>%\n",
    "\t\tfilter(geo != \"DE_TOT\") %>%\n",
    "\t\tfilter(geo != \"AD\") %>%\n",
    "\t\tfilter(geo != \"BA\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30317288-6340-4a61-81b3-28381cbb4d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "# Début de création de la variable \"es_deces_complet\"\n",
    "#\n",
    "# Voici les colonnes que l'on va petit à petit ajouter dans la variable \"es_deces_complet\" :\n",
    "#\n",
    "#  agequinq\t\t\t\t\t: Tranche d'âge quinquennale (tranche de 5 ans)\n",
    "#  sex\t\t\t\t\t\t: Sexe\n",
    "#  geo\t\t\t\t\t\t: Indicatif du pays\n",
    "#  time\t\t\t\t\t\t: Année du recensement (Ex. 2013-01-01)\n",
    "#  population\t\t\t\t: Population du pays\n",
    "#  pop2020\t\t\t\t\t: Population lors du recensement 2020-01-01\n",
    "#  deces_theo_si_pop_2020\t: Décès théoriques qu'il y aurait dû avoir avec la population du pays en 2020\n",
    "#  deces2020\t\t\t\t\t\t: Décès réels observés en 2020 (obtenu par agrégation des deces par semaine 2020)\n",
    "#  pop_france2020\t\t\t: Population française en 2020 (sum(pop2020) après filtrage des lignes de la France)\n",
    "#  deces_theo_du_pays_si_pop_FR_2020\t\t: Décès que le pays aurait eu s'il avait la population de la France en 2020\n",
    "#\t\t\t\t\t\t\t  Devrait s'appeler : deces_theo_du_pays_si_pop_FR_2020\n",
    "#  location\t\t\t\t\t: Nom du pays\n",
    "#  zone\t\t\t\t\t\t: Est, Ouest\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    " #récupération des décès 2020\n",
    "deces2020 <- es_deces_et_pop_annuel_by_agequinq %>% \n",
    "  filter(time==\"2020-01-01\") %>% \n",
    "  dplyr::rename(deces2020=deces) %>% \n",
    "  select(-population,-time,-pop2020)\n",
    "\n",
    "\n",
    "#jointure des deces theoriques qu'on aurait dû avoir en 2020\n",
    "b__es_deces_et_pop_par_annee_agequinq <- es_deces_et_pop_annuel_by_agequinq %>%\n",
    "  left_join(deces2020, \n",
    "            by=c(\"sex\", \"geo\", \"agequinq\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87033245-f3cc-494e-a8bc-6f64f90c585d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Recuperer les deces 2021 grace au fichier par semaine d'EuroStat ####\n",
    "# et le concaténer aux deces annuel qui ne va que jusqu'en 2020\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "#Deces par tranche d'age quinquenal, par pays européen, par semaine, depuis les années 19xx\n",
    "es_deces_week <- a__original_es_deces_week\n",
    "\n",
    "es_deces_week$time <- as.character(a__original_es_deces_week$time)\n",
    "\n",
    "#isoler l'année 2021\n",
    "es_deces_week_2021 <- es_deces_week %>%\n",
    "  filter(str_sub(time, 1, 4) == \"2021\") \n",
    "\n",
    "# Creer une colonne deces2021Corriges : On ne prend que 3/7 pour la semaine 01, car le 01/01/2021 est un vendredi\n",
    "es_deces_week_2021 <- es_deces_week_2021 %>%\n",
    "  mutate(deces2021Corriges = if_else(str_sub(time, 6, 8) == \"01\",\n",
    "                                     floor(values*3/7),\n",
    "                                     values))\n",
    "\n",
    "# Corriger la colonne deces2021Corriges : On ne prend que 5/7 pour la semaine 53, car le 31/12/2021 est un vendredi\n",
    "es_deces_week_2021 <- es_deces_week_2021 %>%\n",
    "  mutate(deces2021Corriges=if_else(str_sub(time, 6, 8) == \"52\",\n",
    "                                   floor(deces2021Corriges*5/7),\n",
    "                                   deces2021Corriges))\n",
    "\n",
    "#supprimer les semaines 99 qui corresponde à des erreurs dans les données\n",
    "es_deces_week_2021 <- es_deces_week_2021 %>%\n",
    "  filter(str_sub(time, 6, 8) != \"99\")\n",
    "\n",
    "#Regrouper par age, sexe, geo et mettre ça dans deces2021 (= deces 2021 par age, sexe, pays)\n",
    "es_deces_2021_tot_by_agequinq_sex_geo <- es_deces_week_2021 %>%\n",
    "  group_by(geo, sex, age) %>%\n",
    "  summarise(deces2021 = sum(deces2021Corriges))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week_2021)\n",
    "\n",
    "#renommer la colonne age en agequinq, car c'est des tranches de 5 ans\n",
    "es_deces_2021_tot_by_agequinq_sex_geo <- es_deces_2021_tot_by_agequinq_sex_geo %>%\n",
    "  dplyr::rename(agequinq = age)\n",
    "\n",
    "#Memoriser les deces 2021 des plus de 85 ans\n",
    "es_deces_2021_tot_ge85 <- es_deces_2021_tot_by_agequinq_sex_geo %>%\n",
    "  filter(agequinq %in% c(\"Y_GE90\", \"Y85-89\"))\n",
    "\n",
    "# Synthetiser par pays, sexe et indiquer que tout ça, ce sont les > 85\n",
    "es_deces_2021_ge85_by_geo_sex <- es_deces_2021_tot_ge85 %>%\n",
    "  group_by(geo, sex) %>%\n",
    "  summarise(deces2021=sum(deces2021)) %>%\n",
    "  mutate(agequinq=\"Y_GE85\")\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_ge85)\n",
    "\n",
    "#Ajouter les lignes des plus de 85 ans (on a donc à la fois les tranches Y_GE90 et Y_GE85 (qui inclut aussi le Y_GE90)\n",
    "es_deces_2021_tot_ge85_ge90 <- bind_rows(es_deces_2021_tot_by_agequinq_sex_geo, \n",
    "                                         es_deces_2021_ge85_by_geo_sex)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2021_ge85_by_geo_sex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92135aed-3b45-4446-b1dd-5a68ca3e78e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Recuperer les deces 2022 grace au fichier par semaine d'EuroStat ####\n",
    "# et le concaténer aux deces annuel qui ne va que jusqu'en 2020\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "#Deces par tranche d'age quinquenal, par pays européen, par semaine, depuis les années 19xx\n",
    "es_deces_week <- a__original_es_deces_week\n",
    "\n",
    "es_deces_week$time <- as.character(a__original_es_deces_week$time)\n",
    "\n",
    "#isoler l'année 2022\n",
    "es_deces_week_2022 <- es_deces_week %>%\n",
    "  filter(str_sub(time, 1, 4) == \"2022\") \n",
    "\n",
    "# Creer une colonne deces2022 Corriges : On ne prend que 2/7 pour la semaine 01, car le 01/01/2022 est un samedi\n",
    "es_deces_week_2022 <- es_deces_week_2022 %>%\n",
    "  mutate(deces2022Corriges = if_else(str_sub(time, 6, 8) == \"01\",\n",
    "                                     floor(values*2/7),\n",
    "                                     values))\n",
    "\n",
    "# Corriger la colonne deces2021Corriges : On ne prend que 6/7 pour la semaine 52, car le 31/12/2021 est un samedi\n",
    "es_deces_week_2022 <- es_deces_week_2022 %>%\n",
    "  mutate(deces2022Corriges=if_else(str_sub(time, 6, 8) == \"52\",\n",
    "                                   floor(deces2022Corriges*6/7),\n",
    "                                   deces2022Corriges))\n",
    "\n",
    "#supprimer les semaines 99 qui corresponde à des erreurs dans les données\n",
    "es_deces_week_2022 <- es_deces_week_2022 %>%\n",
    "  filter(str_sub(time, 6, 8) != \"99\")\n",
    "\n",
    "#Regrouper par age, sexe, geo et mettre ça dans deces2021 (= deces 2022 par age, sexe, pays)\n",
    "es_deces_2022_tot_by_agequinq_sex_geo <- es_deces_week_2022 %>%\n",
    "  group_by(geo, sex, age) %>%\n",
    "  summarise(deces2022 = sum(deces2022Corriges))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week_2022)\n",
    "\n",
    "#renommer la colonne age en agequinq, car c'est des tranches de 5 ans\n",
    "es_deces_2022_tot_by_agequinq_sex_geo <- es_deces_2022_tot_by_agequinq_sex_geo %>%\n",
    "  dplyr::rename(agequinq = age)\n",
    "\n",
    "#Memoriser les deces 2022 des plus de 85 ans\n",
    "es_deces_2022_tot_ge85 <- es_deces_2022_tot_by_agequinq_sex_geo %>%\n",
    "  filter(agequinq %in% c(\"Y_GE90\", \"Y85-89\"))\n",
    "\n",
    "# Synthetiser par pays, sexe et indiquer que tout ça, ce sont les > 85\n",
    "es_deces_2022_ge85_by_geo_sex <- es_deces_2022_tot_ge85 %>%\n",
    "  group_by(geo, sex) %>%\n",
    "  summarise(deces2022=sum(deces2022)) %>%\n",
    "  mutate(agequinq=\"Y_GE85\")\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_ge85)\n",
    "\n",
    "#Ajouter les lignes des plus de 85 ans (on a donc à la fois les tranches Y_GE90 et Y_GE85 (qui inclut aussi le Y_GE90)\n",
    "es_deces_2022_tot_ge85_ge90 <- bind_rows(es_deces_2022_tot_by_agequinq_sex_geo, \n",
    "                                         es_deces_2022_ge85_by_geo_sex)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2022_ge85_by_geo_sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac525ca-8938-4ab5-bd10-02aacb0fd8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq, time)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "# Remplissage de la variable \"es_deces_complet\"\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "\n",
    "#ajout des deces 2021 et 2022 qui viennent d'être calculés aux deces annuels\n",
    "\n",
    "# Filtrer les lignes des Totaux\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_2021_tot_ge85_ge90 %>%\n",
    "  filter(sex != \"T\" & agequinq != \"TOTAL\" & agequinq != \"UNK\")\n",
    "\n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_2022_tot_ge85_ge90 %>%\n",
    "  filter(sex != \"T\" & agequinq != \"TOTAL\" & agequinq != \"UNK\")\n",
    "\n",
    "# Indiquer que ces deces sont ceux du recensement 2021\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>%\n",
    "  mutate(time = as.Date(\"2021-01-01\"),\n",
    "         deces = deces2021) %>% \n",
    "  select(-deces2021)\n",
    "\n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_et_pop_2022_par_agequinq_for_bind_rows %>%\n",
    "  mutate(time = as.Date(\"2022-01-01\"),\n",
    "         deces = deces2022) %>% \n",
    "  select(-deces2022)\n",
    "\n",
    "#synthetiser\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>%\n",
    "  group_by(geo, sex, agequinq, time) %>% \n",
    "  summarise(deces = sum(deces))\n",
    "\n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_et_pop_2022_par_agequinq_for_bind_rows %>%\n",
    "  group_by(geo, sex, agequinq, time) %>% \n",
    "  summarise(deces = sum(deces))\n",
    "\n",
    "# Créer les lignes de population correspondant à 2021 (par duplication de celles de 2019 + adaptations)\n",
    "es_pop2021_by_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  # Prendre les lignes 2019\n",
    "  filter(time == \"2019-01-01\") %>%\n",
    "  # Retirer toutes les colonnes inutiles dont population (qui est la population 2019) que l'on va \n",
    "  # re-initialiser avec la population 2021\n",
    "  select(-deces, -time, -population)\n",
    "\n",
    "# Récupérer la pop 2021\n",
    "es_pjan_quinq_2021 <- es_pjan_quinq %>%\n",
    "  filter(time == \"2021-01-01\")\n",
    "\n",
    "# Récupérer la pop 2022\n",
    "es_pjan_quinq_2022 <- es_pjan_quinq %>%\n",
    "  filter(time == \"2022-01-01\")\n",
    "\n",
    "# Ajouter les colonnes population et pop2020 correspondant à 2020\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>%\n",
    "  left_join(es_pop2021_by_agequinq) %>%\n",
    "  filter(!is.na(pop2020)) \n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_et_pop_2022_par_agequinq_for_bind_rows %>%\n",
    "  left_join(es_pop2021_by_agequinq) %>%\n",
    "  filter(!is.na(pop2020)) \n",
    "\n",
    "# Ajouter les colonnes population et pop2021 correspondant à 2021 et 2022\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>%\n",
    "  left_join(es_pjan_quinq_2021) \n",
    "\n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_et_pop_2022_par_agequinq_for_bind_rows %>%\n",
    "  left_join(es_pjan_quinq_2022)\n",
    "\n",
    "#remplir les blancs de  2021 et 2022 avec 2020 (il reste surtout l'arménie)\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>%\n",
    "  mutate(population=ifelse(is.na(population),pop2020,population))\n",
    "es_deces_et_pop_2022_par_agequinq_for_bind_rows <- es_deces_et_pop_2022_par_agequinq_for_bind_rows %>%\n",
    "  mutate(population=ifelse(is.na(population),pop2020,population))\n",
    "\n",
    "#sélectionner les pays pour lesquels il n'y a pas de données annuelles 2021\n",
    "selection_2021 <- b__es_deces_et_pop_par_annee_agequinq %>% \n",
    "  filter(time==\"2021-01-01\",sex==\"M\",agequinq==\"Y65-69\")\n",
    "es_deces_et_pop_2021_par_agequinq_for_bind_rows <- es_deces_et_pop_2021_par_agequinq_for_bind_rows %>% \n",
    "  filter(!(geo %in% selection_2021$geo))\n",
    "\n",
    "if (shallDeleteVars) rm(selection_2021)\n",
    "\n",
    "#Ajouter les données 2021 et 2022\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  bind_rows(es_deces_et_pop_2021_par_agequinq_for_bind_rows) %>%\n",
    "  bind_rows(es_deces_et_pop_2022_par_agequinq_for_bind_rows) %>% \n",
    "  # trier les lignes selon les colonnes suivantes\n",
    "  arrange(geo, sex, agequinq, time)\n",
    "\n",
    "# Reorganiser les colonnes\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  select(geo:time | population | pop2020 | deces | deces2020 | everything() )\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_et_pop_annuel_by_agequinq)\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_ge85_ge90)\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_ge85_ge90)\n",
    "if (shallDeleteVars) rm(es_pop2021_by_agequinq)\n",
    "if (shallDeleteVars) rm(es_deces_et_pop_2021_par_agequinq_for_bind_rows)\n",
    "if (shallDeleteVars) rm(es_deces_et_pop_2022_par_agequinq_for_bind_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37d87e3a-b652-49c8-8da7-92ce3b3d9fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'sex', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, sex, agequinq)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "##### Gestion de l'Allemagne pour laquelle il manque les donnees sexuees et des moins de 40 ans en 2021 et 2022 #####\n",
    "#\n",
    "\n",
    "#extraire les données de l'Allemagne\n",
    "es_deces_2021_tot_DE <- es_deces_2021_tot_by_agequinq_sex_geo %>%\n",
    "  filter(geo == \"DE\")\n",
    "es_deces_2022_tot_DE <- es_deces_2022_tot_by_agequinq_sex_geo %>%\n",
    "  filter(geo == \"DE\")\n",
    "\n",
    "#recuperation de la repartition de deces des moins de 40 en 2019 en Allemagne\n",
    "es_deces_complet_DE <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  filter(geo == \"DE\") %>%\n",
    "  filter(time == \"2019-01-01\") %>%\n",
    "  group_by(geo, sex, agequinq, time) %>%\n",
    "  summarise(population=sum(population), \n",
    "            deces=sum(deces))\n",
    "\n",
    "\n",
    "#Ajouter une colonne avec la proportion des deces / aux deces des moins de 40 ans\n",
    "es_deces_complet_DE <- es_deces_complet_DE %>%\n",
    "  mutate (tauxmortalite = (deces)/population) %>% \n",
    "  select(-population,-deces,-time)\n",
    "\n",
    "#récupération de la pop 2021 allemande\n",
    "es_pjan_quinq_de_2021_2022 <- es_pjan_quinq_2021 %>% rbind(es_pjan_quinq_2022) %>%  filter(geo==\"DE\"&time>=\"2021-01-01\")\n",
    "es_deces_complet_DE <-  es_pjan_quinq_de_2021_2022 %>% left_join(es_deces_complet_DE)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2022)\n",
    "\n",
    "#extraire les moins de 40 ans\n",
    "es_deces_complet_DE_lt40 <- es_deces_complet_DE %>%\n",
    "  filter(agequinq %in% c(\"Y_LT5\", \"Y5-9\", \"Y10-14\", \"Y15-19\", \"Y20-24\", \"Y25-29\", \"Y30-34\", \"Y35-39\"))\n",
    "\n",
    "#Application de la repartion des deces 2019 des moins de 40 ans a 2021\n",
    "es_deces_complet_DE_lt40 <- es_deces_complet_DE_lt40 %>%\n",
    "  mutate (deces = tauxmortalite * population)\n",
    "\n",
    "#supprimer la colonne partdecesmoins40\n",
    "es_deces_complet_DE_lt40 <- es_deces_complet_DE_lt40 %>%\n",
    "  select(-tauxmortalite) \n",
    "\n",
    "#supprimer les UNKnown et TOTAL\n",
    "es_deces_2021_tot_DE <- es_deces_2021_tot_DE %>%\n",
    "  filter(agequinq!=\"UNK\", agequinq != \"TOTAL\")\n",
    "es_deces_2022_tot_DE <- es_deces_2022_tot_DE %>%\n",
    "  filter(agequinq!=\"UNK\", agequinq != \"TOTAL\")\n",
    "\n",
    "#concatener les F dans les M et remplacer les T\n",
    "#Division par 2 du total pour chaque sexe\n",
    "es_deces_2021_tot_DE_M <- es_deces_2021_tot_DE %>%\n",
    "  mutate (sex=\"M\", deces = deces2021/2)\n",
    "\n",
    "es_deces_2021_tot_DE_F <- es_deces_2021_tot_DE %>%\n",
    "  mutate (sex=\"F\", deces = deces2021/2)\n",
    "\n",
    "es_deces_2021_tot_DE <- es_deces_2021_tot_DE_M %>%\n",
    "  rbind(es_deces_2021_tot_DE_F) %>% mutate(time=as.Date(\"2021-01-01\"))\n",
    "\n",
    "es_deces_2021_tot_DE<-es_deces_2021_tot_DE %>% \n",
    "  select(-deces2021)%>% \n",
    "  left_join(es_pjan_quinq_de_2021_2022)\n",
    "\n",
    "es_deces_2022_tot_DE_M <- es_deces_2022_tot_DE %>%\n",
    "  mutate (sex=\"M\", deces = deces2022/2)\n",
    "\n",
    "es_deces_2022_tot_DE_F <- es_deces_2022_tot_DE %>%\n",
    "  mutate (sex=\"F\", deces = deces2022/2)\n",
    "\n",
    "es_deces_2022_tot_DE <- es_deces_2022_tot_DE_M %>%\n",
    "  rbind(es_deces_2022_tot_DE_F) %>% mutate(time=as.Date(\"2022-01-01\"))\n",
    "\n",
    "es_deces_2022_tot_DE<-es_deces_2022_tot_DE %>% \n",
    "  select(-deces2022)%>% \n",
    "  left_join(es_pjan_quinq_de_2021_2022)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_de_2021_2022)\n",
    "\n",
    "#concaténer les lignes à ajouter\n",
    "es_deces_2021_2022_tot_DE <- es_deces_2021_tot_DE %>%\n",
    "  rbind(es_deces_2022_tot_DE) %>% \n",
    "  rbind(es_deces_complet_DE_lt40)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_complet_DE_lt40)\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_DE_M)\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_DE_F)\n",
    "\n",
    "# Prendre 2019\n",
    "es_deces_2019_complet_DE <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  filter(geo == \"DE\") %>%\n",
    "  filter(time == \"2019-01-01\") %>%\n",
    "  select(geo, sex, agequinq, pop2020, deces2020)\n",
    "\n",
    "\n",
    "# Joindre la colonne pop2020\n",
    "es_deces_2021_2022_tot_DE <- es_deces_2021_2022_tot_DE %>%\n",
    "  left_join(es_deces_2019_complet_DE)\n",
    "\n",
    "es_deces_2022_tot_DE <- es_deces_2021_2022_tot_DE %>% filter(time ==\"2022-01-01\")\n",
    "\n",
    "#Ajouter les lignes de l'Allemagne 2021 et 2022\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  rbind(es_deces_2022_tot_DE)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_complet_DE)\n",
    "if (shallDeleteVars) rm(es_deces_2019_complet_DE)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_by_agequinq_sex_geo)\n",
    "if (shallDeleteVars) rm(es_deces_2021_tot_DE)\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_2021)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2021_2022_tot_DE)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_DE)\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_DE_F)\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_DE_M)\n",
    "if (shallDeleteVars) rm(es_deces_2022_tot_by_agequinq_sex_geo)\n",
    "\n",
    "if (shallDeleteVars) rm()\n",
    "if (shallDeleteVars) rm()\n",
    "if (shallDeleteVars) rm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fc11c75-b857-41de-be87-0c603efeac0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22mThere were 35 warnings in `mutate()`.\n",
      "The first warning was:\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `agequinq = case_when(...)`.\n",
      "Caused by warning:\n",
      "\u001b[33m!\u001b[39m NAs introduced by coercion\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m Run `dplyr::last_dplyr_warnings()` to see the 34 remaining warnings.”\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'agequinq'. You can override using\n",
      "the `.groups` argument.\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mThere were 35 warnings in `mutate()`.\n",
      "The first warning was:\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `agequinq = case_when(...)`.\n",
      "Caused by warning:\n",
      "\u001b[33m!\u001b[39m NAs introduced by coercion\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m Run `dplyr::last_dplyr_warnings()` to see the 34 remaining warnings.”\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'agequinq'. You can override using\n",
      "the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, agequinq, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, agequinq)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'time', 'agequinq'. You can override\n",
      "using the `.groups` argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Récupérer les données anglaises ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "#récupérer les populations annuelles\n",
    "\n",
    "population_england <- read.csv(\"data/csv/population_england.csv\")\n",
    "population_ireland <- read.csv(\"data/csv/population_ireland.csv\")\n",
    "population_northern_ireland <- read.csv(\"data/csv/population_northern_ireland.csv\")\n",
    "population_scotland <- read.csv(\"data/csv/population_scotland.csv\")\n",
    "population_wales <- read.csv(\"data/csv/population_wales.csv\")\n",
    "\n",
    "#mettre les populations annuelles en lignes\n",
    "\n",
    "col_population_england <- colnames(population_england)\n",
    "population_england <- melt(population_england,id.vars = 'Age',measure.vars = col_population_england[col_population_england!='Age'])\n",
    "population_england <- population_england %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(population = value) %>% \n",
    "  mutate(geo=\"EN\")\n",
    "\n",
    "col_population_ireland <- colnames(population_ireland)\n",
    "population_ireland <- melt(population_ireland,id.vars = 'Age',measure.vars = col_population_ireland[col_population_ireland!='Age'])\n",
    "population_ireland <- population_ireland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(population = value)%>% \n",
    "  mutate(geo=\"IR\")\n",
    "\n",
    "\n",
    "col_population_northern_ireland <- colnames(population_northern_ireland)\n",
    "population_northern_ireland <- melt(population_northern_ireland,id.vars = 'Age',measure.vars = col_population_northern_ireland[col_population_northern_ireland!='Age'])\n",
    "population_northern_ireland <- population_northern_ireland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(population = value)%>% \n",
    "  mutate(geo=\"NI\")\n",
    "\n",
    "\n",
    "col_population_scotland <- colnames(population_scotland)\n",
    "population_scotland <- melt(population_scotland,id.vars = 'Age',measure.vars = col_population_scotland[col_population_scotland!='Age'])\n",
    "population_scotland <- population_scotland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(population = value)%>% \n",
    "  mutate(geo=\"SC\")\n",
    "\n",
    "\n",
    "col_population_wales <- colnames(population_wales)\n",
    "population_wales <- melt(population_wales,id.vars = 'Age',measure.vars = col_population_wales[col_population_wales!='Age'])\n",
    "population_wales <- population_wales %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(population = value)%>% \n",
    "  mutate(geo=\"WA\")\n",
    "\n",
    "#récupérer les décès annuels\n",
    "\n",
    "deces_england <- read.csv(\"data/csv/deces_england.csv\")\n",
    "deces_ireland <- read.csv(\"data/csv/deces_ireland.csv\")\n",
    "deces_northern_ireland <- read.csv(\"data/csv/deces_northern_ireland.csv\")\n",
    "deces_scotland <- read.csv(\"data/csv/deces_scotland.csv\")\n",
    "deces_wales <- read.csv(\"data/csv/deces_wales.csv\")\n",
    "\n",
    "#mettre les décès annuels en ligne\n",
    "\n",
    "col_deces_england <- colnames(deces_england)\n",
    "deces_england <- melt(deces_england,id.vars = 'Age',measure.vars = col_deces_england[col_deces_england!='Age'])\n",
    "deces_england <- deces_england %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(deces = value) %>% \n",
    "  mutate(geo=\"EN\")\n",
    "\n",
    "\n",
    "col_deces_ireland <- colnames(deces_ireland)\n",
    "deces_ireland <- melt(deces_ireland,id.vars = 'Age',measure.vars = col_deces_ireland[col_deces_ireland!='Age'])\n",
    "deces_ireland <- deces_ireland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(deces = value)%>% \n",
    "  mutate(geo=\"IR\")\n",
    "\n",
    "\n",
    "col_deces_northern_ireland <- colnames(deces_northern_ireland)\n",
    "deces_northern_ireland <- melt(deces_northern_ireland,id.vars = 'Age',measure.vars = col_deces_northern_ireland[col_deces_northern_ireland!='Age'])\n",
    "deces_northern_ireland <- deces_northern_ireland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(deces = value)%>% \n",
    "  mutate(geo=\"NI\")\n",
    "\n",
    "\n",
    "col_deces_scotland <- colnames(deces_scotland)\n",
    "deces_scotland <- melt(deces_scotland,id.vars = 'Age',measure.vars = col_deces_scotland[col_deces_scotland!='Age'])\n",
    "deces_scotland <- deces_scotland %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(deces = value)%>% \n",
    "  mutate(geo=\"SC\")\n",
    "\n",
    "\n",
    "col_deces_wales <- colnames(deces_wales)\n",
    "deces_wales <- melt(deces_wales,id.vars = 'Age',measure.vars = col_deces_wales[col_deces_wales!='Age'])\n",
    "deces_wales <- deces_wales %>% mutate(time = str_sub(variable,2,11)) %>% \n",
    "  mutate(time = as.Date(time, format = \"%Y . %m . %d\")) %>% \n",
    "  select(-variable) %>% \n",
    "  dplyr::rename(deces = value)%>% \n",
    "  mutate(geo=\"WA\")\n",
    "\n",
    "#regrouper les populations\n",
    "\n",
    "population_concat <- population_england %>% \n",
    "  rbind(population_ireland) %>% \n",
    "  rbind(population_northern_ireland) %>% \n",
    "  rbind(population_scotland) %>% \n",
    "  rbind(population_wales)\n",
    "\n",
    "#mettre les populations en tranches d'âge\n",
    "\n",
    "population_concat <- population_concat %>% mutate(agequinq=case_when( as.numeric(str_sub(Age,3,5)) <= 4 ~ \"Y_LT5\",\n",
    "                                                Age == \"Y_LT1\"~ \"Y_LT5\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 5 &  as.numeric(str_sub(Age,3,5)) < 10 ~ \"Y5-9\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 10 &  as.numeric(str_sub(Age,3,5)) < 15 ~ \"Y10-14\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 15 &  as.numeric(str_sub(Age,3,5)) < 20 ~ \"Y15-19\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 20 &  as.numeric(str_sub(Age,3,5)) < 25 ~ \"Y20-24\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 25 &  as.numeric(str_sub(Age,3,5)) < 30 ~ \"Y25-29\",  \n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 30 &  as.numeric(str_sub(Age,3,5)) < 35 ~ \"Y30-34\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 35 &  as.numeric(str_sub(Age,3,5)) < 40 ~ \"Y35-39\",  \n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 40 &  as.numeric(str_sub(Age,3,5)) < 45 ~ \"Y40-44\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 45 &  as.numeric(str_sub(Age,3,5)) < 50 ~ \"Y45-49\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 50 &  as.numeric(str_sub(Age,3,5)) < 55 ~ \"Y50-54\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 55 &  as.numeric(str_sub(Age,3,5)) < 60 ~ \"Y55-59\",  \n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 60 &  as.numeric(str_sub(Age,3,5)) < 65 ~ \"Y60-64\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 65 &  as.numeric(str_sub(Age,3,5)) < 70 ~ \"Y65-69\",  \n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 70 &  as.numeric(str_sub(Age,3,5)) < 75 ~ \"Y70-74\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 75 &  as.numeric(str_sub(Age,3,5)) < 80 ~ \"Y75-79\",  \n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 80 &  as.numeric(str_sub(Age,3,5)) < 85 ~ \"Y80-84\",\n",
    "                                                as.numeric(str_sub(Age,3,5)) >= 85 &  as.numeric(str_sub(Age,3,5)) < 90  & geo !=\"IR\" ~ \"Y85-89\",\n",
    "                                                TRUE ~ \"Y_OPEN\"))\n",
    "\n",
    "population_agequinq_concat <- population_concat %>% filter(time >= \"2002-01-01\") %>% \n",
    "  group_by(geo, agequinq, time) %>% \n",
    "  summarise(population = sum(population)) %>% \n",
    "  mutate(agequinq=if_else(geo==\"IR\"&agequinq==\"Y_OPEN\",\"Y_GE85\",agequinq)) %>% \n",
    "  mutate(agequinq=if_else(geo!=\"IR\"&agequinq==\"Y_OPEN\",\"Y_GE90\",agequinq))\n",
    "\n",
    "\n",
    "#regrouper les déces\n",
    "\n",
    "deces_concat <- deces_england %>% \n",
    "  rbind(deces_northern_ireland) %>% \n",
    "  rbind(deces_scotland) %>% \n",
    "  rbind(deces_wales)\n",
    "\n",
    "#mettre les décèes en tranches d'âge\n",
    "\n",
    "deces_concat <- deces_concat %>% mutate(agequinq=case_when( as.numeric(str_sub(Age,3,5)) <= 4 ~ \"Y_LT5\",\n",
    "                                                                      Age == \"Y_LT1\"~ \"Y_LT5\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 5 &  as.numeric(str_sub(Age,3,5)) < 10 ~ \"Y5-9\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 10 &  as.numeric(str_sub(Age,3,5)) < 15 ~ \"Y10-14\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 15 &  as.numeric(str_sub(Age,3,5)) < 20 ~ \"Y15-19\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 20 &  as.numeric(str_sub(Age,3,5)) < 25 ~ \"Y20-24\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 25 &  as.numeric(str_sub(Age,3,5)) < 30 ~ \"Y25-29\",  \n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 30 &  as.numeric(str_sub(Age,3,5)) < 35 ~ \"Y30-34\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 35 &  as.numeric(str_sub(Age,3,5)) < 40 ~ \"Y35-39\",  \n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 40 &  as.numeric(str_sub(Age,3,5)) < 45 ~ \"Y40-44\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 45 &  as.numeric(str_sub(Age,3,5)) < 50 ~ \"Y45-49\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 50 &  as.numeric(str_sub(Age,3,5)) < 55 ~ \"Y50-54\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 55 &  as.numeric(str_sub(Age,3,5)) < 60 ~ \"Y55-59\",  \n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 60 &  as.numeric(str_sub(Age,3,5)) < 65 ~ \"Y60-64\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 65 &  as.numeric(str_sub(Age,3,5)) < 70 ~ \"Y65-69\",  \n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 70 &  as.numeric(str_sub(Age,3,5)) < 75 ~ \"Y70-74\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 75 &  as.numeric(str_sub(Age,3,5)) < 80 ~ \"Y75-79\",  \n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 80 &  as.numeric(str_sub(Age,3,5)) < 85 ~ \"Y80-84\",\n",
    "                                                                      as.numeric(str_sub(Age,3,5)) >= 85 &  as.numeric(str_sub(Age,3,5)) < 90 ~ \"Y85-89\",\n",
    "                                                                      TRUE ~ \"Y_GE90\"))\n",
    "deces_ireland <- deces_ireland %>% mutate(agequinq = Age) %>% \n",
    "  mutate(agequinq=if_else(Age == \"Y_LT1\",\"Y_LT5\",Age)) %>% \n",
    "  mutate(agequinq=if_else(Age == \"Y1-4\",\"Y_LT5\",agequinq)) %>% \n",
    "  mutate(agequinq=if_else(agequinq==\"Y_OPEN\",\"Y_GE85\",agequinq))\n",
    "\n",
    "deces_concat <- deces_concat %>% \n",
    "  rbind(deces_ireland)\n",
    "\n",
    "#enlever les tirets\n",
    "\n",
    "deces_concat <- deces_concat %>% \n",
    "  mutate(deces=if_else(deces=='-','0',deces))\n",
    "\n",
    "deces_agequinq_concat <- deces_concat %>% filter(time >= \"2002-01-01\") %>% \n",
    "  group_by(geo, agequinq, time) %>% \n",
    "  summarise(deces = sum(as.numeric(deces)))\n",
    "\n",
    "#merge\n",
    "\n",
    "anglais <- deces_agequinq_concat %>% left_join(population_agequinq_concat)\n",
    "  \n",
    "anglais2020 <- anglais %>% filter (time==\"2020-01-01\") %>% \n",
    "  dplyr::rename (deces2020 =deces, pop2020=population) %>% \n",
    "  select(-time)\n",
    "\n",
    "anglais <- anglais %>% left_join(anglais2020) %>% mutate (sex = 'T')\n",
    "great_britain <- anglais %>% filter(geo %in% c(\"EN\",\"WA\",\"NI\",\"SC\")) %>% \n",
    "  mutate(geo=\"GB\") %>% group_by(geo,time,agequinq,sex) %>% \n",
    "  summarise(deces=sum(deces),deces2020=sum(deces2020),population=sum(population),pop2020=sum(pop2020))\n",
    "anglais <- anglais %>% rbind(great_britain)\n",
    "\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>% filter(geo!=\"IR\")\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>% rbind(anglais)\n",
    "\n",
    "if (shallDeleteVars) rm(population_agequinq_concat)\n",
    "if (shallDeleteVars) rm(population_concat)\n",
    "\n",
    "if (shallDeleteVars) rm(population_england)\n",
    "if (shallDeleteVars) rm(population_ireland)\n",
    "if (shallDeleteVars) rm(population_northern_ireland)\n",
    "if (shallDeleteVars) rm(population_scotland)\n",
    "if (shallDeleteVars) rm(population_wales)\n",
    "if (shallDeleteVars) rm(great_britain)\n",
    "if (shallDeleteVars) rm(anglais)\n",
    "if (shallDeleteVars) rm(anglais2020)\n",
    "\n",
    "if (shallDeleteVars) rm(col_population_england)\n",
    "if (shallDeleteVars) rm(col_population_ireland)\n",
    "if (shallDeleteVars) rm(col_population_northern_ireland)\n",
    "if (shallDeleteVars) rm(col_population_scotland)\n",
    "if (shallDeleteVars) rm(col_population_wales)\n",
    "\n",
    "if (shallDeleteVars) rm(deces_concat)\n",
    "if (shallDeleteVars) rm(deces_england)\n",
    "if (shallDeleteVars) rm(deces_ireland)\n",
    "if (shallDeleteVars) rm(deces_northern_ireland)\n",
    "if (shallDeleteVars) rm(deces_scotland)\n",
    "if (shallDeleteVars) rm(deces_wales)\n",
    "\n",
    "if (shallDeleteVars) rm(col_deces_england)\n",
    "if (shallDeleteVars) rm(col_deces_ireland)\n",
    "if (shallDeleteVars) rm(col_deces_northern_ireland)\n",
    "if (shallDeleteVars) rm(col_deces_scotland)\n",
    "if (shallDeleteVars) rm(col_deces_wales)\n",
    "\n",
    "if (shallDeleteVars) rm(deces_agequinq_concat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9404536-56cf-4a69-9249-078f61c3b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'sex'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'sex'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(sex, agequinq)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Calcul des deces theoriques et surmortalité ####\n",
    "#\n",
    "# + (NORMALISATION) en population française 2020\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# TODO TW m 2021_07_17 : Il vaudrait mieux faire toutes les normalisations à la fin de la construction de b__es_deces_complet\n",
    "# NORMALISATION : pour chaque recensement, calculer pour chaque pays les deces theoriques qu'il y aurait eu \n",
    "#s'il avait eu la population 2020. Mettre cela dans la colone  deces_theo_si_pop_2020\n",
    "\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "  mutate(deces_theo_si_pop_2020 = case_when(\n",
    "    population == 0 ~ 0,\n",
    "    TRUE ~ deces / (population) * pop2020))\n",
    "\n",
    "#Prendre les données valides FR 2020\n",
    "es_FR_pop_pop2020_deces2020 <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tfilter(time == \"2020-01-01\") %>%\n",
    "\t\tfilter(!is.na(population)) %>% \n",
    "\t\tfilter(!is.na(pop2020)) %>%\n",
    "\t\tfilter(!is.na(deces2020))%>% \n",
    "\t\tfilter(geo == \"FR\")\n",
    "\n",
    "#Synthetiser par tranches d'age et sexe\n",
    "es_FR_pop2020_by_agequinq_sex <- es_FR_pop_pop2020_deces2020 %>%\n",
    "\t\tgroup_by(sex, agequinq) %>%\n",
    "\t\tsummarise(pop_france2020 = sum(pop2020))\n",
    "\n",
    "#Ajouter le total des 2 sexes\n",
    "es_FR_pop2020_by_agequinq_sex_T <- es_FR_pop2020_by_agequinq_sex %>%\n",
    "  group_by(agequinq) %>%\n",
    "  summarise(pop_france2020 = sum(pop_france2020),sex='T')\n",
    "\n",
    "es_FR_pop2020_by_agequinq_sex <- es_FR_pop2020_by_agequinq_sex %>% rbind(es_FR_pop2020_by_agequinq_sex_T)\n",
    "\n",
    "if (shallDeleteVars) rm(es_FR_pop2020_by_agequinq_sex_T)\n",
    "\n",
    "# Regrouper les plus de 90 avec les 85-89\n",
    "es_FR_pop2020_ge85 <- es_FR_pop_pop2020_deces2020 %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y85-89\", \"Y_GE90\")) %>%\n",
    "\t\tmutate (agequinq = \"Y_GE85\") %>%\n",
    "\t\tgroup_by(sex, agequinq) %>%\n",
    "\t\tsummarise(pop_france2020 = sum(pop2020)) \n",
    "\n",
    "es_FR_pop2020_ge85_T <-es_FR_pop2020_ge85  %>%\n",
    "  group_by(agequinq) %>%\n",
    "  summarise(pop_france2020 = sum(pop_france2020),sex='T')\n",
    "\n",
    "es_FR_pop2020_ge85<-es_FR_pop2020_ge85 %>% rbind(es_FR_pop2020_ge85_T)\n",
    "\n",
    "if (shallDeleteVars) rm(es_FR_pop_pop2020_deces2020)\n",
    "\n",
    "#Ajouter les 2 lignes Y_GE85 H/F (qui regroupe les 85-89 et les > de 90) en plus des Y_GE90\n",
    "#(qui ne compte que les + de 90)\n",
    "#Ainsi, on pourra avoir les populations des >85 et des >90\n",
    "es_FR_pop2020_by_agequinq_sex <- es_FR_pop2020_by_agequinq_sex %>%\n",
    "\t\trbind(es_FR_pop2020_ge85)  \n",
    "\n",
    "if (shallDeleteVars) rm(es_FR_pop2020_ge85)\n",
    "if (shallDeleteVars) rm(es_FR_pop2020_ge85_T)\n",
    "\n",
    "# Ajouter la colonne pop_france2020 sur chaque tranche d'age de chaque pays\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tleft_join(es_FR_pop2020_by_agequinq_sex)\n",
    "\n",
    "if (shallDeleteVars) rm(es_FR_pop2020_by_agequinq_sex)\n",
    "\n",
    "# NORMALISATION : Ajouter une colonne deces_theo_du_pays_si_pop_FR_2020 : nb de deces que le pays aurait eu s'il avait la population 2020 de la France\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tmutate(deces_theo_du_pays_si_pop_FR_2020 = case_when(\n",
    "\t\t\t\t\t\tpopulation == 0 ~ 0,\n",
    "\t\t\t\t\t\tTRUE ~ deces/(population)*pop_france2020))\n",
    "\n",
    "# Ajouter une colonne surmortalite2020 (= sur-mortalité en 2020)\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tmutate (surmortalite2020 = (deces2020 - deces_theo_si_pop_2020) / deces_theo_si_pop_2020)\n",
    "\n",
    "\n",
    "\n",
    "#Synthtetiser par pays et recensement, les population, pop2020, deces-theo_2020...\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tfilter(!is.na(population)) %>%\n",
    "\t\tgroup_by(geo, time) %>%\n",
    "\t\tsummarise(population=sum(population), \n",
    "\t\t\t\t  pop2020=sum(pop2020), \n",
    "\t\t\t\t  deces=sum(deces), \n",
    "\t\t\t\t  deces2020=sum(deces2020), \n",
    "\t\t\t\t  deces_theo_si_pop_2020=sum(deces_theo_si_pop_2020), \n",
    "\t\t\t\t  deces_theo_du_pays_si_pop_FR_2020=sum(deces_theo_du_pays_si_pop_FR_2020))\n",
    "\n",
    "  \n",
    "#supprimer les ligne qui ont des NA\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tfilter(!is.na(deces2020)) %>%\n",
    "\t\tfilter(!is.na(deces_theo_si_pop_2020))\n",
    "\n",
    "# Ajouter une colonne surmortalite2020 (= sur-mortalité en 2020)\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tmutate (surmortalite2020 = (deces2020 - deces_theo_si_pop_2020)/deces_theo_si_pop_2020)\n",
    "\n",
    "# Ajouter une colonne taux_deces\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tmutate (taux_deces = (deces*100/population))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b2d2f42-1c4d-4483-a4d4-9f6729f20adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'time'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22mThere was 1 warning in `mutate()`.\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `numSemaineDanslAnnee = as.numeric(substr(time, 6, 8))`.\n",
      "Caused by warning:\n",
      "\u001b[33m!\u001b[39m NAs introduced by coercion”\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'agequinq', 'geo'. You can override using\n",
      "the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(agequinq, geo, anneesuivante)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(annee)`\n",
      "Warning message in right_join(es_pjan_quinq_pop_week, numSemainesDepuis2013Complet):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 39 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 1 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(annee)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'agequinq', 'geo'. You can override using\n",
      "the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(agequinq, geo, time)`\n",
      "\u001b[1m\u001b[22mAdding missing grouping variables: `agequinq`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(agequinq, geo, time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'agequinq', 'geo'. You can override using\n",
      "the `.groups` argument.\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'agequinq', 'geo'. You can override using\n",
      "the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(agequinq)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(agequinq, geo)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### STANDARDISATION des deces hebdomadaires des pays ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "# Deces hebdomadaires des pays\n",
    "\n",
    "es_deces_week_pays <- es_deces_week %>%\n",
    "\t\tfilter(sex == \"T\") %>%\n",
    "\t\tgroup_by(geo, time, age) %>% \n",
    "\t\tsummarise(deces=sum(values))\n",
    "\n",
    "es_deces_week_pays <- es_deces_week_pays %>%\n",
    "  dplyr::rename(agequinq = age)\n",
    "\n",
    "\n",
    "# Deces hebdomadaires France\n",
    "\n",
    "es_deces_week_France <- es_deces_week %>%\n",
    "\t\tgroup_by(geo, time) %>% \n",
    "\t\tsummarise(deces=sum(values)) %>%\n",
    "\t\tfilter(geo == \"FR\")\n",
    "\n",
    "## Trier les lignes par time\n",
    "#es_deces_week_France <- es_deces_week_France %>%\n",
    "#\t\tarrange(time)\n",
    "\n",
    "\n",
    "# Ajouter une colonne avec numero de semaine depuis 2013\n",
    "es_deces_week_France$numSemaineDepuis2013 <- 1:nrow(es_deces_week_France)\n",
    "\n",
    "\n",
    "#\n",
    "# Créer un DataFrame avec les numéros de semaines dans l'année et depuis 2013\n",
    "#\n",
    "\n",
    "# Commencer à préparer un DataFrame avec les numéros de semaines correspondants \n",
    "# aux dates des décès hebdo France\n",
    "numSemainesDepuis2013Complet <- ungroup(es_deces_week_France) %>%\n",
    "\t\tselect(time, \n",
    "\t\t\t\tnumSemaineDepuis2013)\n",
    "\n",
    "# Ajouter une colonne annee\n",
    "numSemainesDepuis2013Complet <- numSemainesDepuis2013Complet %>%\n",
    "\t\tmutate(annee = substr(time, 1, 4))\n",
    "\n",
    "# Ajouter une colonne numSemaineDanslAnnee avec le numero de semaine dans l'année en numérique\n",
    "numSemainesDepuis2013Complet <- numSemainesDepuis2013Complet %>%\n",
    "\t\tmutate(numSemaineDanslAnnee = as.numeric(substr(time, 6, 8)))\n",
    "\n",
    "# reorganiser l'ordre des colonnes\n",
    "numSemainesDepuis2013Complet <- numSemainesDepuis2013Complet %>%\n",
    "\t\tselect(annee, \n",
    "\t\t\t\ttime, \n",
    "\t\t\t\tnumSemaineDanslAnnee, \n",
    "\t\t\t\tnumSemaineDepuis2013)\n",
    "\n",
    "\n",
    "#\n",
    "# Créer un DataFrame avec le nombre de semaines dans chaque année de 2013 à 2023\n",
    "#\n",
    "\n",
    "# Compter le nombre de semaines dans chaque année\n",
    "nbSemainesParAnneeDepuis2013 <- count(numSemainesDepuis2013Complet, annee) %>%\n",
    "  dplyr::rename(nbSemainesDansAnnee = n)\n",
    "\n",
    "# Forcer 52 semaines en 2021,2022,2023\n",
    "nbSemainesParAnneeDepuis2013 <- nbSemainesParAnneeDepuis2013 %>%\n",
    "\t\tmutate(nbSemainesDansAnnee = if_else(annee %in% c(2021,2022,2023), \n",
    "\t\t\t\t\t\tas.integer(52),\n",
    "\t\t\t\t\t\tnbSemainesDansAnnee))\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week)\n",
    "if (shallDeleteVars) rm(es_deces_week_France)\n",
    "\n",
    "#####standardisation des deces hebdomadaires des pays\n",
    "\n",
    "#calcul de la population hebdomadaire par tranche d'âge\n",
    "es_pjan_quinq_pop_week <- es_pjan_quinq %>%\n",
    "\t\tgroup_by(agequinq, geo, time) %>%\n",
    "\t\tsummarise(population=sum(population)) \n",
    "\n",
    "es_pjan_quinq_pop_week2 <- es_pjan_quinq_pop_week %>%\n",
    "  dplyr::rename(popanneesuivante = population)\n",
    "\n",
    "es_pjan_quinq_pop_week2 <- es_pjan_quinq_pop_week2 %>%\n",
    "  dplyr::rename(anneesuivante = time)\n",
    "\n",
    "es_pjan_quinq_pop_week <- es_pjan_quinq_pop_week %>%\n",
    "  dplyr::rename(pop = population)\n",
    "\n",
    "es_pjan_quinq_pop_week <- es_pjan_quinq_pop_week %>%\n",
    "\t\tmutate(anneesuivante = time + years(1))\n",
    "\n",
    "es_pjan_quinq_pop_week <- inner_join(es_pjan_quinq_pop_week, es_pjan_quinq_pop_week2)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_pop_week2)\n",
    "\n",
    "es_pjan_quinq_pop_week <- es_pjan_quinq_pop_week %>%\n",
    "\t\tmutate(annee=substr(time, 1, 4))\n",
    "\n",
    "es_pjan_quinq_pop_week <- es_pjan_quinq_pop_week %>%\n",
    "\t\tselect(-time)\n",
    "\n",
    "es_pjan_pop_week_age <- right_join(es_pjan_quinq_pop_week, numSemainesDepuis2013Complet)\n",
    "\n",
    "es_pjan_pop_week_age <- right_join(nbSemainesParAnneeDepuis2013, es_pjan_pop_week_age)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_pop_week)\n",
    "if (shallDeleteVars) rm(nbSemainesParAnneeDepuis2013)\n",
    "\n",
    "#calcul de la population hebdomadaire en fonction de l'année en cours et de la suivante\n",
    "\n",
    "es_pjan_pop_week_age <- es_pjan_pop_week_age %>%\n",
    "\t\tmutate(pop_week=(pop + (popanneesuivante-pop) * (numSemaineDanslAnnee-1) / as.numeric(nbSemainesDansAnnee)))\n",
    "\n",
    "es_pjan_pop_week_age_quinq_final <- es_pjan_pop_week_age %>%\n",
    "\t\tselect(-nbSemainesDansAnnee, -pop, -annee, -anneesuivante, -popanneesuivante, -numSemaineDanslAnnee)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_pop_week_age)\n",
    "\n",
    "es_pjan_pop_week_age_quinq_final <- es_pjan_pop_week_age_quinq_final %>%\n",
    "\t\tgroup_by(agequinq, geo, time) %>% \n",
    "\t\tsummarise(pop_week=sum(pop_week))\n",
    "\n",
    "#calcul de mortalite hebdomadaire\n",
    "\n",
    "# Prendre les plus de 85\n",
    "es_deces_week_ge85 <- es_deces_week_pays %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y_GE90\", \"Y85-89\"))\n",
    "\n",
    "# Les affecter à la tranche d'age des plus de 85 ans\n",
    "es_deces_week_ge85 <- es_deces_week_ge85 %>%\n",
    "\t\tgroup_by(geo, time) %>%\n",
    "\t\tsummarise(deces=sum(deces)) %>%\n",
    "\t\tmutate(agequinq=\"Y_GE85\")\n",
    "\n",
    "# On met les décès hebdo dans cette variable. On ajoutera plus tard la colonne mortalité\n",
    "es_deces_mortalite_week <- bind_rows(es_deces_week_pays, es_deces_week_ge85)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week_pays)\n",
    "if (shallDeleteVars) rm(es_deces_week_ge85)\n",
    "\n",
    "es_deces_mortalite_week <- left_join(es_pjan_pop_week_age_quinq_final, es_deces_mortalite_week)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_pop_week_age_quinq_final)\n",
    "\n",
    "es_deces_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tfilter(agequinq != \"UNK\", agequinq != \"TOTAL\")\n",
    "\n",
    "es_deces_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tfilter(as.numeric(substr(time, 1, 4)) >= 2013)\n",
    "\n",
    "es_deces_week_mortalite_week_a_enlever <- es_deces_mortalite_week %>%\n",
    "\t\tfilter(agequinq == \"Y20-24\"&is.na(pop_week)) %>%\n",
    "\t\tselect(geo, time)\n",
    "\n",
    "es_deces_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tanti_join((es_deces_week_mortalite_week_a_enlever))\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week_mortalite_week_a_enlever)\n",
    "\n",
    "es_deces_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tfilter(!is.na(deces))\n",
    "\n",
    "# Ajout de la colonne tx_mortalite_week\n",
    "es_deces_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tmutate(tx_mortalite_week = deces / pop_week)\n",
    "\n",
    "\n",
    "#on calcule la population 2020 des pays du fichier \n",
    "es_pjan_quinq_pop_2020_totale <- es_pjan_quinq %>%\n",
    "\t\tfilter(time == \"2020-01-01\") %>%\n",
    "\t\tgroup_by(agequinq, geo, time) %>% \n",
    "\t\tsummarise(population=sum(population)) %>%\n",
    "\t\tselect(-time) %>% \n",
    "  dplyr::rename(pop2020=population)\n",
    "\n",
    "#on calcule la population 2020 France \n",
    "es_pjan_quinq_pop_2020_France <- es_pjan_quinq %>%\n",
    "\t\tfilter(time == \"2020-01-01\") %>%\n",
    "\t\tfilter(geo == \"FR\") %>%\n",
    "\t\tgroup_by(agequinq, geo, time) %>% \n",
    "\t\tsummarise(population=sum(population)) \n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq)\n",
    "\n",
    "es_pjan_quinq_pop_2020_France <- ungroup(es_pjan_quinq_pop_2020_France) %>%\n",
    "\t\tselect(-time, -geo) %>% \n",
    "  dplyr::rename(pop20france=population)\n",
    "\n",
    "#ajout du cas avec les Y_GE85\n",
    "es_pjan_quinq_pop_2020_France_85 <- es_pjan_quinq_pop_2020_France %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y85-89\", \"Y_GE90\")) %>%\n",
    "\t\tmutate (agequinq = \"Y_GE85\") %>%\n",
    "\t\tgroup_by(agequinq) %>%\n",
    "\t\tsummarise(pop20france = sum(pop20france))\n",
    "\n",
    "es_pjan_quinq_pop_2020_France <- es_pjan_quinq_pop_2020_France %>%\n",
    "\t\trbind(es_pjan_quinq_pop_2020_France_85)  \n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_pop_2020_France_85)\n",
    "\n",
    "es_pjan_quinq_pop_2020_totale <- es_pjan_quinq_pop_2020_totale %>%\n",
    "\t\tleft_join(es_pjan_quinq_pop_2020_France)\n",
    "\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_pop_2020_France)\n",
    "\n",
    "#on joint avec la table du taux de mortalite\n",
    "es_taux_mortalite_week <- es_deces_mortalite_week %>%\n",
    "\t\tleft_join(es_pjan_quinq_pop_2020_totale)\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_mortalite_week)\n",
    "if (shallDeleteVars) rm(es_pjan_quinq_pop_2020_totale)\n",
    "\n",
    "#on calcule les deces standardises par pays et age quinquennal\n",
    "es_taux_mortalite_week <- es_taux_mortalite_week %>%\n",
    "\t\t# tx_mortalite_week est le taux de mortalité de chaque semaine \n",
    "\t\t# pop2020 est la population du pays en 2020 pour chaque tranche d'âge\n",
    "\t\tmutate(deces_standardises_si_pop_2020 = tx_mortalite_week * pop2020, \n",
    "\t\t\t\t# pop20france est la population de la France en 2020 pour chaque tranche d'âge\n",
    "\t\t\t\tdeces_standardises_si_pop_FR_2020 = tx_mortalite_week * pop20france)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a2727e9-2c83-4be4-8383-7197c77846a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo'. You can override using the `.groups`\n",
      "argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, numSemaineDepuis2013)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "# Calcul de la mortalité et des décès standardisés (si la population était celle de 2020)\n",
    "# en regroupant certaines tranches d'âge ensemble\n",
    "#\n",
    "# Début de création de la variable : es_deces_standard_owid_vaccination_by_pays_semaine\n",
    "# Voici les colonnes que l'on va petit à petit ajouter dans la variable :\n",
    "#\n",
    "#  geo\t\t\t\t\t\t\t\t\t\t: Indicatif du pays\n",
    "#  time\t\t\t\t\t\t\t\t\t\t: Semaine concernée (Ex. 2015W01)\n",
    "#  numSemaineDepuis2013\t\t\t\t\t\t\t: numéro de semaine incrémenté depuis 2013W1\n",
    "#\n",
    "#\n",
    "#  deces_standardises_si_pop_2020\t\t\t: Deces standardisés ramené à la population 2020 ( = tx_mortalite_week * pop2020)\n",
    "#  deces_tot\t\t\t\t\t\t\t\t: Nombre de décès toutes causes dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020\t\t: Deces standardisés ramené à la population de la France en 2020 ( = tx_mortalite_week * pop20france)\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_ge40\t\t: \n",
    "#  deces_tot_plus_40\t\t\t\t\t\t: Nombre de décès toutes causes des >= 40 ans, dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020_ge40\t:\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_ge60\t\t:\n",
    "#  deces_tot_plus_60\t\t\t\t\t\t: Nombre de décès toutes causes des >= 60 ans, dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020_ge60\t:\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_40_60\t\t:\n",
    "#  deces_tot_40_60\t\t\t\t\t\t\t: Nombre de décès toutes causes des 40 à 60 ans, dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020_40_60\t:\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_lt40\t\t: Nombre de décès toutes causes des < 40 ans, dans la semaine\n",
    "#  deces_tot_moins40\t\t\t\t:\n",
    "#  deces_standardises_si_pop_FR_2020_lt40\t:\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_60_64\t\t:\n",
    "#  deces_tot_60_64\t\t\t\t\t\t\t: Nombre de décès toutes causes des 60 à 64 ans, dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020_60_64\t:\n",
    "#\n",
    "#  deces_standardises_si_pop_2020_65_69\t\t:\n",
    "#  deces_tot_65_69\t\t\t\t\t\t\t: Nombre de décès toutes causes des 65 à 69 ans, dans la semaine\n",
    "#  deces_standardises_si_pop_FR_2020_65_69\t:\n",
    "#\n",
    "#  Response_measure\t\t\t\t\t\t\t: Mesures gouvernementales (confinement ...) mises en place\n",
    "#\n",
    "#  new_deaths\t\t\t\t\t\t\t\t: Nouveaux décès attribués au COVID selon OWID\n",
    "#  new_cases\t\t\t\t\t\t\t\t: Nouveaux tests positifs au COVID selon OWID\n",
    "#  new_vaccinations\t\t\t\t\t\t\t: Nouvelles vaccinations contre COVID selon OWID\n",
    "#  new_vaccinations_smoothed_per_million\t: Nouvelles vaccinations contre COVID par million selon OWID\n",
    "#\n",
    "#  location\t\t\t\t\t: Nom du pays\n",
    "#  zone\t\t\t\t\t\t: Est, Ouest\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, de toute la population\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- es_taux_mortalite_week %>%\n",
    "\t\tgroup_by(geo, time) %>% \n",
    "\t\tsummarise(deces_tot=sum(deces), \n",
    "\t\t\t\tdeces_standardises_si_pop_2020 = sum(deces_standardises_si_pop_2020), \n",
    "\t\t\t\tdeces_standardises_si_pop_FR_2020 = sum(deces_standardises_si_pop_FR_2020),\n",
    "\t\t\t\tpop_week=sum(pop_week))\n",
    "\n",
    "# Ajouter la colonne avec le numéro de semaine depuis 2013\n",
    "\n",
    "# créer un DataFrame avec juste les colonnes time et numSemaineDepuis2013\n",
    "numSemainesDepuis2013 <- numSemainesDepuis2013Complet %>%\n",
    "\t\tselect(time, \n",
    "\t\t\t\tnumSemaineDepuis2013)\n",
    "\n",
    "# Ajouter une colonne avec le n° de semaine depuis 2013\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tleft_join(numSemainesDepuis2013)\n",
    "\n",
    "# Réordonner les colonnes\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tselect(geo:time | numSemaineDepuis2013 | everything())\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, moins de 15 ans\n",
    "\n",
    "es_taux_mortalite_week_lt15 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y_LT5\", \"Y5-9\", \"Y10-14\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_lt15 <- es_taux_mortalite_week_lt15 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_moins15=sum(deces), \n",
    "    deces_standardises_si_pop_2020_lt15=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_lt15=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_lt15=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_lt15 <- es_deces_week_standardises_si_pop_2020_lt15 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, des 15-24 ans\n",
    "\n",
    "es_taux_mortalite_week_15_24 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y15-19\", \"Y20-24\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_15_24 <- es_taux_mortalite_week_15_24 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_15_24=sum(deces), \n",
    "    deces_standardises_si_pop_2020_15_24=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_15_24=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_15_24=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_15_24 <- es_deces_week_standardises_si_pop_2020_15_24 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, des 15-40 ans\n",
    "\n",
    "es_taux_mortalite_week_15_40 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y15-19\", \"Y20-24\", \"Y25-29\", \"Y30-34\", \"Y35-39\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_15_40 <- es_taux_mortalite_week_15_40 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_15_40=sum(deces), \n",
    "    deces_standardises_si_pop_2020_15_40=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_15_40=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_15_40=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_15_40 <- es_deces_week_standardises_si_pop_2020_15_40 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, des 25-49 ans\n",
    "\n",
    "es_taux_mortalite_week_25_49 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y25-29\", \"Y30-34\", \"Y35-39\",\"Y40-44\", \"Y45-49\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_25_49 <- es_taux_mortalite_week_25_49 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_25_49=sum(deces), \n",
    "    deces_standardises_si_pop_2020_25_49=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_25_49=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_25_49=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_25_49 <- es_deces_week_standardises_si_pop_2020_25_49 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "\n",
    "# on somme pour avoir les deces par pays et par semaine, des plus de 40 ans\n",
    "\n",
    "es_taux_mortalite_week_ge40 <- es_taux_mortalite_week %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y_GE85\", \"Y40-44\", \"Y45-49\", \"Y50-54\", \"Y55-59\", \"Y60-64\", \"Y65-69\", \"Y70-74\", \"Y75-79\", \"Y80-84\", \"Y85-89\", \"Y_GE90\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge40 <- es_taux_mortalite_week_ge40 %>%\n",
    "\t\tgroup_by(geo, time) %>% \n",
    "\t\tsummarise(deces_tot_plus_40 = sum(deces), \n",
    "\t\t\t\tdeces_standardises_si_pop_2020_ge40 = sum(deces_standardises_si_pop_2020), \n",
    "\t\t\t\tdeces_standardises_si_pop_FR_2020_ge40 = sum(deces_standardises_si_pop_FR_2020),\n",
    "\t\t\t\tpop_week_ge40=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge40 <- es_deces_week_standardises_si_pop_2020_ge40 %>%\n",
    "\t\tleft_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, des 40-50 ans\n",
    "es_taux_mortalite_week_40_50 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y40-44\", \"Y45-49\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_40_50 <- es_taux_mortalite_week_40_50 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_40_50=sum(deces), \n",
    "    deces_standardises_si_pop_2020_40_50=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_40_50=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_40_50=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_40_50 <- es_deces_week_standardises_si_pop_2020_40_50 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, des 40-60 ans\n",
    "es_taux_mortalite_week_40_60 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y40-44\", \"Y45-49\", \"Y50-54\", \"Y55-59\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_40_60 <- es_taux_mortalite_week_40_60 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_40_60=sum(deces), \n",
    "    deces_standardises_si_pop_2020_40_60=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_40_60=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_40_60=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_40_60 <- es_deces_week_standardises_si_pop_2020_40_60 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine des 50-59 ans\n",
    "\n",
    "es_taux_mortalite_week_50_59 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y50-54\",\"Y55-59\"))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_50_59 <- es_taux_mortalite_week_50_59 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_50_59=sum(deces), \n",
    "    deces_standardises_si_pop_2020_50_59=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_50_59=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_50_59=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_50_59 <- es_deces_week_standardises_si_pop_2020_50_59 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine des 60-69 ans\n",
    "\n",
    "es_taux_mortalite_week_60_69 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y60-64\",\"Y65-69\"))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_60_69 <- es_taux_mortalite_week_60_69 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_60_69=sum(deces), \n",
    "    deces_standardises_si_pop_2020_60_69=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_60_69=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_60_69=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_60_69 <- es_deces_week_standardises_si_pop_2020_60_69 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine 65-69 ans\n",
    "\n",
    "es_taux_mortalite_week_65_69 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y65-69\"))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_65_69 <- es_taux_mortalite_week_65_69 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_65_69=sum(deces), \n",
    "    deces_standardises_si_pop_2020_65_69=sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_65_69=sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_65_69=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_65_69 <- es_deces_week_standardises_si_pop_2020_65_69 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, plus de 60 ans\n",
    "\n",
    "es_taux_mortalite_week_ge60 <- es_taux_mortalite_week %>%\n",
    "\t\tfilter(agequinq %in% c(\"Y_GE85\", \"Y60-64\", \"Y65-69\", \"Y70-74\", \"Y75-79\", \"Y80-84\", \"Y85-89\", \"Y_GE90\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge60 <- es_taux_mortalite_week_ge60 %>%\n",
    "\t\tgroup_by(geo, time) %>% \n",
    "\t\tsummarise(\n",
    "\t\t\t\tdeces_tot_plus_60 = sum(deces), \n",
    "\t\t\t\tdeces_standardises_si_pop_2020_ge60 = sum(deces_standardises_si_pop_2020), \n",
    "\t\t\t\tdeces_standardises_si_pop_FR_2020_ge60 = sum(deces_standardises_si_pop_FR_2020),\n",
    "\t\t\t\tpop_week_ge60=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge60 <- es_deces_week_standardises_si_pop_2020_ge60 %>%\n",
    "\t\tleft_join(numSemainesDepuis2013)\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, 70-79 ans\n",
    "\n",
    "es_taux_mortalite_week_70_79 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y70-74\", \"Y75-79\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_70_79 <- es_taux_mortalite_week_70_79 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_70_79 = sum(deces), \n",
    "    deces_standardises_si_pop_2020_70_79 = sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_70_79 = sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_70_79=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_70_79 <- es_deces_week_standardises_si_pop_2020_70_79 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "\n",
    "#on somme pour avoir les deces par pays et par semaine, plus de 80 ans\n",
    "\n",
    "es_taux_mortalite_week_ge80 <- es_taux_mortalite_week %>%\n",
    "  filter(agequinq %in% c(\"Y80-84\", \"Y85-89\", \"Y_GE90\")) \n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge80 <- es_taux_mortalite_week_ge80 %>%\n",
    "  group_by(geo, time) %>% \n",
    "  summarise(\n",
    "    deces_tot_plus_80 = sum(deces), \n",
    "    deces_standardises_si_pop_2020_ge80 = sum(deces_standardises_si_pop_2020), \n",
    "    deces_standardises_si_pop_FR_2020_ge80 = sum(deces_standardises_si_pop_FR_2020),\n",
    "    pop_week_ge80=sum(pop_week))\n",
    "\n",
    "es_deces_week_standardises_si_pop_2020_ge80 <- es_deces_week_standardises_si_pop_2020_ge80 %>%\n",
    "  left_join(numSemainesDepuis2013)\n",
    "\n",
    "\n",
    "\n",
    "#jointure des colonnes\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_ge40) %>% \n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_ge60) %>%\n",
    "    left_join(es_deces_week_standardises_si_pop_2020_ge80) %>%\n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_40_60) %>% \n",
    "    left_join(es_deces_week_standardises_si_pop_2020_40_50) %>% \n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_lt15) %>%\n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_50_59)%>%\n",
    "    left_join(es_deces_week_standardises_si_pop_2020_60_69)%>% \n",
    "\t\tleft_join(es_deces_week_standardises_si_pop_2020_65_69)%>% \n",
    "    left_join(es_deces_week_standardises_si_pop_2020_15_40)%>% \n",
    "    left_join(es_deces_week_standardises_si_pop_2020_15_24)%>% \n",
    "    left_join(es_deces_week_standardises_si_pop_2020_70_79)%>% \n",
    "    left_join(es_deces_week_standardises_si_pop_2020_25_49)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_ge40)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_ge60)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_ge80)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_40_60)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_40_50)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_lt15)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_15_40)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_15_24)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_50_59)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_60_69)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_65_69)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_70_79)\n",
    "if (shallDeleteVars) rm(es_taux_mortalite_week_25_49)\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_ge40) \n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_ge60)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_ge80)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_40_60)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_70_79) \n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_40_50) \n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_lt15)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_15_40)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_15_24)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_50_59) \n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_60_69) \n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_65_69)\n",
    "if (shallDeleteVars) rm(es_deces_week_standardises_si_pop_2020_25_49)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73fa9509-8b0d-4dd8-8ce5-445c8c1b06d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/eu/ecdc/a__original_eu_mesures.RDS) présent. On re-charge le fichier dans (a__original_eu_mesures), sans le re-télécharger.\n",
      "\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time_start)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time_end)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "# Recuperation des mesures prises par les pays europeens\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "a__original_eu_mesures  <- a__f_downloadIfNeeded(\n",
    "\t\tsourceType = K_SOURCE_TYPE_CSV, \n",
    "\t\tUrlOrEuroStatNameToDownload = \"https://www.ecdc.europa.eu/sites/default/files/documents/response_graphs_data_2022-01-27.csv\",\n",
    "\t\trepertoire = file.path(K_DIR_EXT_DATA_EUROPE,\"ecdc\"),\n",
    "\t\tvar = a__original_eu_mesures)\n",
    "\n",
    "eu_mesures_gouv <- a__original_eu_mesures\n",
    "\n",
    "#\n",
    "# Convertir les dates en n° de semaines\n",
    "#\n",
    "\n",
    "# Convertir les string en date\n",
    "eu_mesures_gouv <- eu_mesures_gouv %>%\n",
    "\t\tmutate(date_start = as.Date(date_start), \n",
    "\t\t\t\tdate_end = as.Date(date_end))\n",
    "\n",
    "# Convertir en n° de semaine (20xxWyy)\n",
    "# TODO TW : Utiliser a__f_get_eurostat_week\n",
    "eu_mesures_gouv <- eu_mesures_gouv %>%\n",
    "\t\tmutate(time_start = paste0(isoyear(date_start),\n",
    "\t\t\t\t\t\t\"W\", \n",
    "\t\t\t\t\t\tas.integer(isoweek(date_start)/10), \n",
    "\t\t\t\t\t\tisoweek(date_start) - as.integer(isoweek(date_start)/10)*10))\n",
    "\n",
    "eu_mesures_gouv <- eu_mesures_gouv %>%\n",
    "\t\tmutate(time_end = paste0(isoyear(date_end), \n",
    "\t\t\t\t\t\t\"W\", as.integer(isoweek(date_end)/10), \n",
    "\t\t\t\t\t\tisoweek(date_end) - as.integer(isoweek(date_end)/10)*10))\n",
    "\n",
    "# Ajouter le code geo du pays et réorganiser les colonnes\n",
    "eu_mesures_gouv <- eu_mesures_gouv %>%\n",
    "\t\tmutate(geo = case_when(Country == \"Austria\"~\"AT\",\n",
    "\t\t\t\t\t\tCountry == \"Bulgaria\"~\"BG\",\n",
    "\t\t\t\t\t\tCountry == \"Croatia\" ~\"HR\",\n",
    "\t\t\t\t\t\tCountry == \"Estonia\"~\"EE\",\n",
    "\t\t\t\t\t\tCountry == \"Germany\"~\"DE\",\n",
    "\t\t\t\t\t\tCountry == \"Greece\"~\"EL\",\n",
    "\t\t\t\t\t\tCountry == \"Iceland\"~\"IS\",\n",
    "\t\t\t\t\t\tCountry == \"Latvia\"~\"LV\",\n",
    "\t\t\t\t\t\tCountry == \"Malta\"~\"MT\",\n",
    "\t\t\t\t\t\tCountry == \"Netherlands\"~\"NL\",\n",
    "\t\t\t\t\t\tCountry == \"Poland\"~\"PL\",\n",
    "\t\t\t\t\t\tCountry == \"Portugal\"~\"PT\",\n",
    "\t\t\t\t\t\tCountry == \"Slovakia\"~\"SK\",\n",
    "\t\t\t\t\t\tCountry == \"Slovenia\"~\"SI\",\n",
    "\t\t\t\t\t\tCountry == \"Spain\"~\"ES\",\n",
    "\t\t\t\t\t\tCountry == \"Sweden\"~\"SE\",\n",
    "\t\t\t\t\t\tCountry == \"Switzerland\"~\"CH\",\n",
    "\t\t\t\t\t\tTRUE~str_to_upper(substr(Country, 1, 2)))) %>%\n",
    "\t\tselect(Country,\n",
    "\t\t\t\tgeo,\n",
    "\t\t\t\tdate_start:time_end,\n",
    "\t\t\t\teverything()) %>%\n",
    "\t\t# Trier\n",
    "\t\tarrange(Country,\n",
    "\t\t\t\tgeo,\n",
    "\t\t\t\tdate_start)\n",
    "\n",
    "#\n",
    "# Créer un df geo, Response_measure (debut ou fin de confinement), time (week)\n",
    "# pour pouvoir le merger dans le df des décès standardisés\n",
    "#\n",
    "\n",
    "# Ajouter les colonnes semaine_debut/semaine_fin\n",
    "\n",
    "# Filtrer les débuts de confinement\n",
    "eu_lockdown <- eu_mesures_gouv %>%\n",
    "\t\tfilter(Response_measure == \"StayHomeOrder\")\n",
    "\n",
    "# Créer un df avec les n° de semaines depuis 2013, mais avec des en-tête de colonnes time_start et semaine_debut\n",
    "numSemaineDepuis2013_for_eu_lockdown_start <- numSemainesDepuis2013 %>%\n",
    "  dplyr::rename (time_start = time, \n",
    "\t\t\t\tsemaine_debut = numSemaineDepuis2013)\n",
    "\n",
    "# Joindre la colonne semaine_debut\n",
    "eu_lockdown <- left_join(eu_lockdown, \n",
    "\t\tnumSemaineDepuis2013_for_eu_lockdown_start)\n",
    "\n",
    "# Créer un df avec les n° de semaines depuis 2013, mais avec des en-tête de colonnes time_end et semaine_fin\n",
    "numSemaineDepuis2013_for_eu_lockdown_end <- numSemainesDepuis2013 %>%\n",
    "  dplyr::rename (time_end = time,\n",
    "\t\t\t\tsemaine_fin = numSemaineDepuis2013)\n",
    "\n",
    "# Joindre la colonne semaine_fin\n",
    "eu_lockdown <- left_join(eu_lockdown, \n",
    "\t\tnumSemaineDepuis2013_for_eu_lockdown_end)\n",
    "\n",
    "\n",
    "# Mettre eu_lockdown dans un format compatible des décès standardisés\t\t\t\t \n",
    "\n",
    "# Remettre les dates de début dans la colonne \"time\" afin de pouvoir les joindre dans b__es_deces_week_standardises_si_pop_2020_owid_vaccination\n",
    "eu_lockdown_start <- eu_lockdown %>%\n",
    "\t\tselect(geo, \n",
    "\t\t\t\tResponse_measure, \n",
    "\t\t\t\ttime_start) %>%\n",
    "  dplyr::rename(time = time_start) %>%\n",
    "\t\tmutate(Response_measure = \"StayHomeOrderStart\")\n",
    "\n",
    "# Remettre les dates de fin dans la colonne \"time\" afin de pouvoir les joindre dans b__es_deces_week_standardises_si_pop_2020_owid_vaccination\n",
    "eu_lockdown_end <- eu_lockdown %>%\n",
    "\t\tselect(geo, \n",
    "\t\t\t\tResponse_measure, \n",
    "\t\t\t\ttime_end) %>%\n",
    "  dplyr::rename(time = time_end) %>%\n",
    "\t\tmutate(Response_measure = \"StayHomeOrderEnd\")\n",
    "\n",
    "# Concaténer les lignes\n",
    "eu_lockdown_for_join <- eu_lockdown_start %>%\n",
    "\t\trbind(eu_lockdown_end)\n",
    "\n",
    "# Joindre la colonne Response_measure pour chaque semaine\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(b__es_deces_week_standardises_si_pop_2020_owid_vaccination,\n",
    "\t\teu_lockdown_for_join)\n",
    "\n",
    "# Forcer le type de mesure gouvernementale en fonction des semaines\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(Response_measure = case_when(\n",
    "\t\t\t\t\t\tgeo == \"AT\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<383 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"AT\" & numSemaineDepuis2013 == 376 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"BE\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<384 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"CH\" & numSemaineDepuis2013 >  416 & numSemaineDepuis2013<422 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"CY\" & numSemaineDepuis2013 == 378  ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"CY\" & numSemaineDepuis2013 >  378 & numSemaineDepuis2013<383 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"CY\" & numSemaineDepuis2013 == 383  ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"CY\" & numSemaineDepuis2013 == 419  ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"CY\" & numSemaineDepuis2013 == 436  ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"CZ\" & numSemaineDepuis2013 == 378  ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"CZ\" & numSemaineDepuis2013 >  378 & numSemaineDepuis2013<381 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"CZ\" & numSemaineDepuis2013 == 381  ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"DE\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<385 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"EE\" & numSemaineDepuis2013 >  375 & numSemaineDepuis2013<386 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"EL\" & numSemaineDepuis2013 >  375 & numSemaineDepuis2013<378 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"EL\" & numSemaineDepuis2013 == 378 ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"EL\" & numSemaineDepuis2013 >  378 & numSemaineDepuis2013<384 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"ES\" & numSemaineDepuis2013 == 376 ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"ES\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<383 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"FR\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<385 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"HU\" & numSemaineDepuis2013 == 378 ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"HU\" & numSemaineDepuis2013 >  378 & numSemaineDepuis2013<386 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"HU\" & numSemaineDepuis2013 == 386 ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"IT\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<384 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"IT\" & numSemaineDepuis2013 >  408 & numSemaineDepuis2013<411 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"LV\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<386 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"LU\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<381 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"LI\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<391 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"LI\" & numSemaineDepuis2013 >  409 & numSemaineDepuis2013<417 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"NL\" & numSemaineDepuis2013 >  376 & numSemaineDepuis2013<385 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"NL\" & numSemaineDepuis2013 >  415 & numSemaineDepuis2013<422 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"NO\" & numSemaineDepuis2013 >  410 & numSemaineDepuis2013<419 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"PL\" & numSemaineDepuis2013 >  378 & numSemaineDepuis2013<381 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tgeo == \"PL\" & numSemaineDepuis2013 >  380 & numSemaineDepuis2013<384 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"PL\" & numSemaineDepuis2013 == 384 ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"PT\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<383 ~ \"StayHomeGen\",\n",
    "\t\t\t\t\t\tgeo == \"PT\" & numSemaineDepuis2013 == 377 ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"PT\" & numSemaineDepuis2013 == 383 ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"PT\" & numSemaineDepuis2013 == 420 ~ \"StayHomeOrderStart\",\n",
    "\t\t\t\t\t\tgeo == \"PT\" & numSemaineDepuis2013 == 435 ~ \"StayHomeOrderEnd\",\n",
    "\t\t\t\t\t\tgeo == \"SI\" & numSemaineDepuis2013 >  377 & numSemaineDepuis2013<383 ~ \"StayHome\",\n",
    "\t\t\t\t\t\tTRUE ~ Response_measure))\n",
    "\n",
    "# Reorganiser les colonnes\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tselect(geo:numSemaineDepuis2013,\n",
    "\t\t\t\tResponse_measure,\n",
    "\t\t\t\teverything())\n",
    "\n",
    "if (shallDeleteVars) rm(numSemainesDepuis2013)\n",
    "if (shallDeleteVars) rm(eu_mesures_gouv)\n",
    "if (shallDeleteVars) rm(eu_lockdown)\n",
    "if (shallDeleteVars) rm(eu_lockdown_end)\n",
    "if (shallDeleteVars) rm(eu_lockdown_start)\n",
    "if (shallDeleteVars) rm(numSemaineDepuis2013_for_eu_lockdown_start)\n",
    "if (shallDeleteVars) rm(eu_lockdown_for_join)\n",
    "if (shallDeleteVars) rm(numSemaineDepuis2013_for_eu_lockdown_end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9357c6a-dadc-4dc8-9fc6-3a16d4da59e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/eu/ecdc/a__vaccination_age.RDS) présent. On re-charge le fichier dans (a__vaccination_age), sans le re-télécharger.\n",
      "\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time, Region)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time, Region)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time, Region)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time, Region)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time, Region)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "##### Recuperation des donnees de vaccination par age ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "a__vaccination_age  <- a__f_downloadIfNeeded(\n",
    "  sourceType = K_SOURCE_TYPE_CSV, \n",
    "  UrlOrEuroStatNameToDownload = \"https://opendata.ecdc.europa.eu/covid19/vaccine_tracker/csv/data.csv\",\n",
    "  repertoire = file.path(K_DIR_EXT_DATA_EUROPE,\"ecdc\"),\n",
    "  var = a__vaccination_age)\n",
    "\n",
    "a__vaccination_age <- a__vaccination_age %>% \n",
    "  mutate(time = paste0(str_sub(YearWeekISO,1,4),str_sub(YearWeekISO,6,8))) %>% \n",
    "  mutate(total_dose = FirstDose + SecondDose + UnknownDose + DoseAdditional1)\n",
    "\n",
    "vaccination_simple <-dcast(a__vaccination_age,\n",
    "                           time + Region ~ TargetGroup,\n",
    "                           value.var = \"total_dose\",\n",
    "                           fun.aggregate = sum)\n",
    "\n",
    "vaccination_dose1 <-dcast(a__vaccination_age,\n",
    "                           time + Region ~ TargetGroup,\n",
    "                           value.var = \"FirstDose\",\n",
    "                           fun.aggregate = sum)\n",
    "\n",
    "colnames(vaccination_dose1)[3:19] <- paste(colnames(vaccination_dose1)[3:19], \"dose1\", sep = \"_\")\n",
    "\n",
    "vaccination_dose2 <-dcast(a__vaccination_age,\n",
    "                          time + Region ~ TargetGroup,\n",
    "                          value.var = \"SecondDose\",\n",
    "                          fun.aggregate = sum)\n",
    "\n",
    "colnames(vaccination_dose2)[3:19] <- paste(colnames(vaccination_dose2)[3:19], \"dose2\", sep = \"_\")\n",
    "\n",
    "vaccination_dose3 <-dcast(a__vaccination_age,\n",
    "                          time + Region ~ TargetGroup,\n",
    "                          value.var = \"DoseAdditional1\",\n",
    "                          fun.aggregate = sum)\n",
    "\n",
    "colnames(vaccination_dose3)[3:19] <- paste(colnames(vaccination_dose3)[3:19], \"dose3\", sep = \"_\")\n",
    "\n",
    "vaccination_dose4 <-dcast(a__vaccination_age,\n",
    "                          time + Region ~ TargetGroup,\n",
    "                          value.var = \"DoseAdditional2\",\n",
    "                          fun.aggregate = sum)\n",
    "\n",
    "colnames(vaccination_dose4)[3:19] <- paste(colnames(vaccination_dose4)[3:19], \"dose4\", sep = \"_\")\n",
    "\n",
    "vaccination_dose5 <-dcast(a__vaccination_age,\n",
    "                          time + Region ~ TargetGroup,\n",
    "                          value.var = \"DoseAdditional3\",\n",
    "                          fun.aggregate = sum)\n",
    "\n",
    "colnames(vaccination_dose5)[3:19] <- paste(colnames(vaccination_dose5)[3:19], \"dose5\", sep = \"_\")\n",
    "\n",
    "vaccination_simple <-vaccination_simple %>% left_join(vaccination_dose1) %>% \n",
    "  left_join(vaccination_dose2) %>% \n",
    "  left_join(vaccination_dose3) %>% \n",
    "  left_join(vaccination_dose4) %>% \n",
    "  left_join(vaccination_dose5)\n",
    "\n",
    "if (shallDeleteVars) rm(vaccination_dose2)\n",
    "if (shallDeleteVars) rm(vaccination_dose1)\n",
    "if (shallDeleteVars) rm(vaccination_dose3)\n",
    "if (shallDeleteVars) rm(vaccination_dose4)\n",
    "if (shallDeleteVars) rm(vaccination_dose5)\n",
    "\n",
    "\n",
    "vaccination_simple <- vaccination_simple %>% dplyr::rename(geo = Region)\n",
    "\n",
    "\n",
    "#Ajouter les infos de vaccination de owid aux données de décès EuroStat\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(b__es_deces_week_standardises_si_pop_2020_owid_vaccination,\n",
    "                                                                        vaccination_simple)\n",
    "\n",
    "if (shallDeleteVars) rm(vaccination_simple)\n",
    "if (shallDeleteVars) rm(a__vaccination_age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75081a56-5b25-4bd8-ae5b-0fbddefdd340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fichier (inst/extdata/world/owid//a__original_owid_covid_data.RDS) présent. On re-charge le fichier dans (a__original_owid_covid_data), sans le re-télécharger.\n",
      "\n",
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'location', 'iso_code'. You can override\n",
      "using the `.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n"
     ]
    }
   ],
   "source": [
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Recuperation des donnees ourworldindata ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "a__original_owid_covid_data <- a__f_downloadIfNeeded(\n",
    "\t\tsourceType = K_SOURCE_TYPE_CSV, \n",
    "\t\tUrlOrEuroStatNameToDownload = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\",\n",
    "\t\trepertoire = file.path(K_DIR_EXT_DATA_WORLD,\"owid/\"),\n",
    "\t\tvar = a__original_owid_covid_data) \n",
    "\n",
    "b__owid_covid_data <- a__original_owid_covid_data\n",
    "\n",
    "b__owid_covid_data <- b__owid_covid_data %>%\n",
    "\t\tmutate(date = as.Date(date))\n",
    "\n",
    "# Ajouter colonne time de la forme 2020W09\n",
    "b__owid_covid_data <- b__owid_covid_data %>%\n",
    "\t\tmutate(time = paste0(isoyear(date),\n",
    "\t\t\t\t\t\t\"W\",\n",
    "\t\t\t\t\t\tas.integer(isoweek(date)/10),\n",
    "\t\t\t\t\t\tisoweek(date) - as.integer(isoweek(date)/10)*10))\n",
    "\n",
    "# Remplacer les na par 0\n",
    "b__owid_covid_data <- b__owid_covid_data %>%\n",
    "\t\tmutate(new_vaccinations = if_else(is.na(new_vaccinations),\n",
    "\t\t\t\t\t\t0,\n",
    "\t\t\t\t\t\tnew_vaccinations)) %>%\n",
    "\t\tmutate(new_deaths = if_else(is.na(new_deaths),\n",
    "\t\t\t\t\t\t0,\n",
    "\t\t\t\t\t\tnew_deaths)) %>%\n",
    "\t\tmutate(new_cases = if_else(is.na(new_cases),\n",
    "\t\t\t\t\t\t0,\n",
    "\t\t\t\t\t\tnew_cases)) %>%\n",
    "\t\tmutate(new_vaccinations_smoothed_per_million = if_else(is.na(new_vaccinations_smoothed_per_million),\n",
    "\t\t\t\t\t\t0,\n",
    "\t\t\t\t\t\tnew_vaccinations_smoothed_per_million))\n",
    "\n",
    "# Synthetiser par pays (uniquement Europe + Arménie et Georgie), code pays, n° semaine\n",
    "owid_covid_Europe_week <- b__owid_covid_data %>%\n",
    "\t\tfilter(continent == \"Europe\" | iso_code == \"ARM\" | iso_code == \"GEO\") %>%\n",
    "\t\tgroup_by(location,\n",
    "\t\t\t\tiso_code,\n",
    "\t\t\t\ttime) %>%\n",
    "\t\tsummarise(new_cases = sum(new_cases),\n",
    "\t\t\t\tnew_deaths = sum(new_deaths),\n",
    "\t\t\t\tnew_vaccinations = sum(new_vaccinations),\n",
    "\t\t\t\tnew_vaccinations_smoothed_per_million = sum(new_vaccinations_smoothed_per_million))\n",
    "\n",
    "# Ajouter une colonne geo avec les 2 premières lettre de l'iso_code des pays, sauf pour quelques uns\n",
    "owid_covid_Europe_week <- owid_covid_Europe_week %>%\n",
    "\t\tmutate(geo = case_when(iso_code == \"DNK\"~\"DK\",\n",
    "\t\t\t\t\t\tiso_code == \"SRB\"~\"RS\",\n",
    "\t\t\t\t\t\tiso_code == \"EST\"~\"EE\",\n",
    "\t\t\t\t\t\tiso_code == \"GRC\"~\"EL\",\n",
    "\t\t\t\t\t\tiso_code == \"MNE\"~\"ME\",\n",
    "\t\t\t\t\t\tiso_code == \"MLT\"~\"MT\",\n",
    "\t\t\t\t\t\tiso_code == \"SWE\"~\"SE\",\n",
    "\t\t\t\t\t\tiso_code == \"SVN\"~\"SI\",\n",
    "\t\t\t\t\t\tiso_code == \"SVK\"~\"SK\",\n",
    "\t\t\t\t\t\tiso_code == \"POL\"~\"PL\",\n",
    "\t\t\t\t\t\tiso_code == \"PRT\"~\"PT\",\n",
    "\t\t\t\t\t\tiso_code == \"ARM\"~\"AM\",\n",
    "\t\t\t\t\t\tiso_code == \"AUT\"~\"AT\",\n",
    "\t\t\t\t\t\tiso_code == \"FRO\"~\"FO\",\n",
    "\t\t\t\t\t\tTRUE~substr(iso_code, 1, 2)))\n",
    "\n",
    "# Ajouter les colonnes avec les numeros de semaine depuis 2013\n",
    "owid_covid_Europe_week <- owid_covid_Europe_week %>%\n",
    "\t\tleft_join(numSemainesDepuis2013Complet)\n",
    "\n",
    "if (shallDeleteVars) rm(numSemainesDepuis2013Complet)\n",
    "\n",
    "owid_covid_Europe_geo_week <- ungroup(owid_covid_Europe_week) %>%\n",
    "\t\tselect(geo,\n",
    "\t\t\t\ttime,\n",
    "\t\t\t\tnew_deaths,\n",
    "\t\t\t\tnew_cases,\n",
    "\t\t\t\tnew_vaccinations,\n",
    "\t\t\t\tnew_vaccinations_smoothed_per_million)\n",
    "\n",
    "#Ajouter les infos de vaccination de owid aux données de décès EuroStat\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(b__es_deces_week_standardises_si_pop_2020_owid_vaccination,\n",
    "\t\towid_covid_Europe_geo_week)\n",
    "\n",
    "if (shallDeleteVars) rm(owid_covid_Europe_geo_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82bce4fe-654d-464f-a03b-f8411b1303cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m`summarise()` has grouped output by 'geo', 'time'. You can override using the\n",
      "`.groups` argument.\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, age_group)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time, deces_covid_80plus)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, time)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "# Recuperation des donnees ined sur les décès Covid par âge\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "b__ined_covid_data <- read.csv(\"data/csv/Cum_deaths_by_age_sex.csv\") %>% \n",
    "  filter(age_group != \"Total unknown\")%>%\n",
    "  filter(!((country_code==\"FRA\"& death_reference_date_type ==\"report\")|(country_code==\"NLD\"& death_reference_date_type ==\"report\"))) %>% \n",
    "  mutate(geo = case_when(country_code == \"AUT\"~\"AT\",\n",
    "                         country_code == \"DNK\"~\"DK\",\n",
    "                         country_code == \"PRT\"~\"PT\",\n",
    "                         country_code == \"SWE\"~\"SE\",\n",
    "                         TRUE~substr(country_code, 1, 2)),\n",
    "         death_reference_date = as.Date(death_reference_date),\n",
    "         week=isoweek(death_reference_date),\n",
    "        year = isoyear(death_reference_date),\n",
    "        time = case_when(week<10 ~ paste0(year,\"W0\",week),\n",
    "                         TRUE~paste0(year,\"W\",week))) %>% \n",
    "  select(geo,time,age_group,cum_death_both,year,week) %>% \n",
    "  mutate(cum_death_both = case_when(is.na(cum_death_both)~as.integer(0),\n",
    "                                    TRUE~cum_death_both))\n",
    "\n",
    "\n",
    "b__ined_covid_data_group<-b__ined_covid_data %>% \n",
    "  filter(geo %in% c(\"AT\",\"BE\",\"DK\",\"FR\",\"ES\",\"DE\",\"IT\",\"NE\",\"NO\",\"PT\",\"RO\",\"SE\",\"CH\")) %>% \n",
    "  group_by(geo,time,age_group) %>% \n",
    "  summarise(cum_death_both=base::max(cum_death_both),year=mean(year),week=mean(week))\n",
    "\n",
    "#décumuler les données\n",
    "\n",
    "b__ined_covid_data_group_prec<-b__ined_covid_data_group %>% \n",
    "  mutate(time = case_when(week<9 ~ paste0(year,\"W0\",week+1),\n",
    "                          week<52 ~ paste0(year,\"W\",week+1),\n",
    "                          week==52 & year==2020 ~ \"2020W53\",\n",
    "                          week==52 & year==2021 ~ \"2022W01\",\n",
    "                          week==53 ~ paste0(year+1,\"W01\"),\n",
    "                       TRUE~paste0(year,\"W\",week)),\n",
    "         cum_death_both_prec = cum_death_both) %>% \n",
    "  select(-cum_death_both,-year,-week)\n",
    "\n",
    "b__ined_covid_data_group <- b__ined_covid_data_group %>% left_join(b__ined_covid_data_group_prec) %>% \n",
    "  mutate(new_death = case_when(is.na(cum_death_both_prec) ~ cum_death_both,\n",
    "                               TRUE~cum_death_both-cum_death_both_prec))\n",
    "#créer les fichiers par tranche d'âge\n",
    "\n",
    "#0-4 ans\n",
    "b__ined_covid_data_group_0_4 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"0-4\") %>% \n",
    "  mutate(deces_covid_0_4 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                     TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_0_4)\n",
    "\n",
    "#0-9 ans\n",
    "b__ined_covid_data_group_0_9 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"0-9\") %>% \n",
    "  mutate(deces_covid_0_9 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                     TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_0_9)\n",
    "\n",
    "#0-24 ans\n",
    "b__ined_covid_data_group_0_24 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"0-24\") %>% \n",
    "  mutate(deces_covid_0_24 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                      TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_0_24)\n",
    "\n",
    "#5-14 ans\n",
    "b__ined_covid_data_group_5_14 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"5-14\") %>% \n",
    "  mutate(deces_covid_5_14 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                      TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_5_14)\n",
    "\n",
    "#10-19 ans\n",
    "b__ined_covid_data_group_10_19 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"10-19\") %>% \n",
    "  mutate(deces_covid_10_19 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_10_19)\n",
    "\n",
    "#15-24 ans\n",
    "b__ined_covid_data_group_15_24 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"15-24\") %>% \n",
    "  mutate(deces_covid_15_24 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_15_24)\n",
    "\n",
    "#20-29 ans\n",
    "b__ined_covid_data_group_20_29 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"20-29\") %>% \n",
    "  mutate(deces_covid_20_29 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_20_29)\n",
    "\n",
    "#25-34 ans\n",
    "b__ined_covid_data_group_25_34 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"25-34\") %>% \n",
    "  mutate(deces_covid_25_34 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_25_34)\n",
    "\n",
    "#25-44 ans\n",
    "b__ined_covid_data_group_25_44 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"25-44\") %>% \n",
    "  mutate(deces_covid_25_44 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_25_44)\n",
    "\n",
    "#30-39 ans\n",
    "b__ined_covid_data_group_30_39 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"30-39\") %>% \n",
    "  mutate(deces_covid_30_39 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_30_39)\n",
    "\n",
    "#35-44 ans\n",
    "b__ined_covid_data_group_35_44 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"35-44\") %>% \n",
    "  mutate(deces_covid_35_44 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_35_44)\n",
    "\n",
    "#40-49 ans\n",
    "b__ined_covid_data_group_40_49 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"40-49\") %>% \n",
    "  mutate(deces_covid_40_49 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_40_49)\n",
    "\n",
    "#45-54 ans\n",
    "b__ined_covid_data_group_45_54 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"45-54\") %>% \n",
    "  mutate(deces_covid_45_54 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_45_54)\n",
    "\n",
    "#45-64 ans\n",
    "b__ined_covid_data_group_45_64 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"45-64\") %>% \n",
    "  mutate(deces_covid_45_64 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_45_64)\n",
    "\n",
    "#50-59 ans\n",
    "b__ined_covid_data_group_50_59 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"50-59\") %>% \n",
    "  mutate(deces_covid_50_59 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_50_59)\n",
    "\n",
    "#55-64 ans\n",
    "b__ined_covid_data_group_55_64 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"55-64\") %>% \n",
    "  mutate(deces_covid_55_64 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_55_64)\n",
    "\n",
    "#60-69 ans\n",
    "b__ined_covid_data_group_60_69 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"60-69\") %>% \n",
    "  mutate(deces_covid_60_69 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_60_69)\n",
    "\n",
    "#65-74 ans\n",
    "b__ined_covid_data_group_65_74 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"65-74\") %>% \n",
    "  mutate(deces_covid_65_74 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_65_74)\n",
    "\n",
    "#70-74 ans\n",
    "b__ined_covid_data_group_70_74 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"70-74\") %>% \n",
    "  mutate(deces_covid_70_74 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_70_74)\n",
    "\n",
    "#70-79 ans\n",
    "b__ined_covid_data_group_70_79 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"70-79\") %>% \n",
    "  mutate(deces_covid_70_79 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_70_79)\n",
    "\n",
    "#75-79 ans\n",
    "b__ined_covid_data_group_75_79 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"75-79\") %>% \n",
    "  mutate(deces_covid_75_79 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_75_79)\n",
    "\n",
    "#75-84 ans\n",
    "b__ined_covid_data_group_75_84 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"75-84\") %>% \n",
    "  mutate(deces_covid_75_84 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_75_84)\n",
    "\n",
    "#80-84 ans\n",
    "b__ined_covid_data_group_80_84 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"80-84\") %>% \n",
    "  mutate(deces_covid_80_84 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_80_84)\n",
    "\n",
    "#80-89 ans\n",
    "b__ined_covid_data_group_80_89 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"80-89\") %>% \n",
    "  mutate(deces_covid_80_89 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_80_89)\n",
    "\n",
    "#85-89 ans\n",
    "b__ined_covid_data_group_85_89 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"85-89\") %>% \n",
    "  mutate(deces_covid_85_89 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_85_89)\n",
    "\n",
    "#85-94 ans\n",
    "b__ined_covid_data_group_85_94 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"85-94\") %>% \n",
    "  mutate(deces_covid_85_94 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_85_94)\n",
    "\n",
    "#90-99 ans\n",
    "b__ined_covid_data_group_90_99 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"90-99\") %>% \n",
    "  mutate(deces_covid_90_99 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                       TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_90_99)\n",
    "\n",
    "#<40 ans\n",
    "b__ined_covid_data_group_moins40 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"<40\") %>% \n",
    "  mutate(deces_covid_moins40 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                         TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_moins40)\n",
    "\n",
    "#<50 ans\n",
    "b__ined_covid_data_group_moins50 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"<50\") %>% \n",
    "  mutate(deces_covid_moins50 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                         TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_moins50)\n",
    "\n",
    "#<60 ans\n",
    "b__ined_covid_data_group_moins60 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"<60\") %>% \n",
    "  mutate(deces_covid_moins60 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                         TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_moins60)\n",
    "\n",
    "#<70 ans\n",
    "b__ined_covid_data_group_moins70 <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"<70\") %>% \n",
    "  mutate(deces_covid_moins70 = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                         TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_moins70)\n",
    "\n",
    "#80+ ans\n",
    "b__ined_covid_data_group_80plus <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"80+\") %>% \n",
    "  mutate(deces_covid_80plus = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                        TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_80plus)\n",
    "\n",
    "#85+ ans\n",
    "b__ined_covid_data_group_85plus <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"85+\") %>% \n",
    "  mutate(deces_covid_85plus = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                        TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_85plus)\n",
    "\n",
    "#90+ ans\n",
    "b__ined_covid_data_group_90plus <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"90+\") %>% \n",
    "  mutate(deces_covid_90plus = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                        TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_90plus)\n",
    "\n",
    "#95+ ans\n",
    "b__ined_covid_data_group_95plus <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"95+\") %>% \n",
    "  mutate(deces_covid_95plus = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                        TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_95plus)\n",
    "\n",
    "\n",
    "#100+ ans\n",
    "b__ined_covid_data_group_100plus <- b__ined_covid_data_group %>% \n",
    "  filter(age_group == \"100+\") %>% \n",
    "  mutate(deces_covid_100plus = case_when(is.na(new_death) ~ as.integer(0),\n",
    "                                        TRUE~new_death)) %>% \n",
    "  select(geo,time,deces_covid_100plus)\n",
    "\n",
    "b__ined_covid_data_regroupe <- b__ined_covid_data_group_0_24 %>% \n",
    "  full_join(b__ined_covid_data_group_0_4) %>% \n",
    "  full_join(b__ined_covid_data_group_0_9) %>% \n",
    "  full_join(b__ined_covid_data_group_10_19) %>% \n",
    "  full_join(b__ined_covid_data_group_15_24) %>% \n",
    "  full_join(b__ined_covid_data_group_20_29) %>% \n",
    "  full_join(b__ined_covid_data_group_25_34) %>% \n",
    "  full_join(b__ined_covid_data_group_25_44) %>% \n",
    "  full_join(b__ined_covid_data_group_30_39) %>% \n",
    "  full_join(b__ined_covid_data_group_35_44) %>% \n",
    "  full_join(b__ined_covid_data_group_40_49) %>% \n",
    "  full_join(b__ined_covid_data_group_45_54) %>% \n",
    "  full_join(b__ined_covid_data_group_45_64) %>% \n",
    "  full_join(b__ined_covid_data_group_5_14) %>% \n",
    "  full_join(b__ined_covid_data_group_50_59) %>% \n",
    "  full_join(b__ined_covid_data_group_55_64) %>% \n",
    "  full_join(b__ined_covid_data_group_60_69) %>%\n",
    "  full_join(b__ined_covid_data_group_65_74) %>% \n",
    "  full_join(b__ined_covid_data_group_70_74) %>% \n",
    "  full_join(b__ined_covid_data_group_70_79) %>% \n",
    "  full_join(b__ined_covid_data_group_75_79) %>% \n",
    "  full_join(b__ined_covid_data_group_75_84) %>% \n",
    "  full_join(b__ined_covid_data_group_80_84) %>% \n",
    "  full_join(b__ined_covid_data_group_80_89) %>%\n",
    "  full_join(b__ined_covid_data_group_90_99) %>% \n",
    "  full_join(b__ined_covid_data_group_80plus) %>% \n",
    "  full_join(b__ined_covid_data_group_85_89) %>% \n",
    "  full_join(b__ined_covid_data_group_85_94) %>%\n",
    "  full_join(b__ined_covid_data_group_80plus) %>% \n",
    "  full_join(b__ined_covid_data_group_85plus) %>% \n",
    "  full_join(b__ined_covid_data_group_90plus) %>% \n",
    "  full_join(b__ined_covid_data_group_95plus) %>%\n",
    "  full_join(b__ined_covid_data_group_100plus) %>% \n",
    "  full_join(b__ined_covid_data_group_moins40) %>% \n",
    "  full_join(b__ined_covid_data_group_moins50) %>% \n",
    "  full_join(b__ined_covid_data_group_moins60) %>% \n",
    "  full_join(b__ined_covid_data_group_moins70)\n",
    "  \n",
    "b__ined_covid_data_regroupe <- b__ined_covid_data_regroupe %>% \n",
    "  mutate(deces_covid_moins60 = case_when(geo==\"DK\"& time==\"2020W14\" ~ as.integer(4),\n",
    "                                         geo==\"DK\"& time==\"2020W15\" ~ as.integer(3),\n",
    "                                         geo==\"DK\"& !is.na(deces_covid_50_59) ~ deces_covid_0_9 + deces_covid_10_19 + deces_covid_20_29+deces_covid_30_39+deces_covid_40_49+deces_covid_50_59,\n",
    "                                         TRUE ~ deces_covid_moins60))%>% \n",
    "  mutate(deces_covid_60_69 = case_when(geo==\"DK\"& time==\"2020W14\" ~ as.integer(20),\n",
    "                                       geo==\"DK\"& time==\"2020W15\" ~ as.integer(13),\n",
    "                                         TRUE ~ deces_covid_60_69)) %>% \n",
    "  select(-deces_covid_moins70)\n",
    "\n",
    "b__ined_covid_data_regroupe <- b__ined_covid_data_regroupe %>% \n",
    "  mutate(deces_covid_moins60 = case_when(geo==\"DE\"& time==\"2020W14\" ~ as.integer(47),\n",
    "                                        geo==\"DE\"& time==\"2020W18\" ~ as.integer(42),\n",
    "                                        geo==\"DE\"& time==\"2020W39\"~as.integer(7),\n",
    "                                        geo==\"DE\"& !is.na(deces_covid_50_59) ~ deces_covid_0_9 + deces_covid_10_19 + deces_covid_20_29+deces_covid_30_39+deces_covid_40_49+deces_covid_50_59,\n",
    "                                         TRUE ~ deces_covid_moins60)) %>% \n",
    "  mutate(deces_covid_60_69 = case_when(geo==\"DE\"& time==\"2020W39\" ~ as.integer(4),\n",
    "                                       TRUE ~ deces_covid_60_69)) %>% \n",
    "  mutate(deces_covid_70_79 = case_when(geo==\"DE\"& time==\"2020W39\" ~ as.integer(12),\n",
    "                                       TRUE ~ deces_covid_70_79)) %>% \n",
    "  mutate(deces_covid_80_89 = case_when(geo==\"DE\"& time==\"2020W39\" ~ as.integer(17),\n",
    "                                       TRUE ~ deces_covid_80_89)) %>%\n",
    "  mutate(deces_covid_90_99 = case_when(geo==\"DE\"& time==\"2020W39\" ~ as.integer(7),\n",
    "                                       TRUE ~ deces_covid_90_99)) %>%\n",
    "  mutate(deces_covid_100plus = case_when(geo==\"DE\"& time==\"2020W39\" ~ as.integer(0),\n",
    "                                       TRUE ~ deces_covid_100plus)) %>% \n",
    "  mutate(deces_covid_100plus = case_when(geo==\"DE\"& time==\"2020W18\" ~ as.integer(0),\n",
    "                                         TRUE ~ deces_covid_100plus)) %>%\n",
    "  mutate(deces_covid_90_99 = case_when(geo==\"DE\"& time==\"2020W18\" ~ as.integer(236),\n",
    "                                         TRUE ~ deces_covid_90_99)) %>% \n",
    "  mutate(deces_covid_90plus = case_when(geo==\"DE\"& time==\"2020W49\" ~ as.integer(557),\n",
    "                                       TRUE ~ deces_covid_90plus)) %>% \n",
    "  mutate(deces_covid_80plus = case_when(geo==\"DE\"&!is.na(deces_covid_100plus) ~ deces_covid_100plus + deces_covid_90_99+deces_covid_80_89,\n",
    "                                        TRUE ~ deces_covid_80plus))\n",
    "  \n",
    "b__ined_covid_data_regroupe <- b__ined_covid_data_regroupe %>% \n",
    "  mutate(deces_covid_80plus = case_when(geo %in% c(\"NL\",\"IT\",\"DK\")~deces_covid_80_89+deces_covid_90plus,\n",
    "                                        TRUE~deces_covid_80plus)) %>% \n",
    "  mutate(deces_covid_85plus = case_when(geo %in% c(\"FR\")~deces_covid_85_94+deces_covid_95plus,\n",
    "                                        TRUE~deces_covid_85plus))\n",
    "\n",
    "b__ined_covid_data_regroupe <- b__ined_covid_data_regroupe %>% \n",
    "  mutate(deces_covid_0_9 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                     geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                        TRUE~deces_covid_0_9)) %>% \n",
    "  mutate(deces_covid_10_19 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                     TRUE~deces_covid_10_19)) %>%\n",
    "  mutate(deces_covid_20_29 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_20_29)) %>% \n",
    "  mutate(deces_covid_30_39 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_30_39)) %>% \n",
    "  mutate(deces_covid_40_49 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_40_49)) %>% \n",
    "  mutate(deces_covid_50_59 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_50_59)) %>% \n",
    "  mutate(deces_covid_60_69 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_60_69)) %>% \n",
    "  mutate(deces_covid_70_79 = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                       geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_70_79)) %>% \n",
    "  mutate(deces_covid_80plus = case_when(geo==\"PT\"& time==\"2020W34\" ~ as.integer(0),\n",
    "                                        geo==\"PT\"& time==\"2020W48\" ~ as.integer(0),\n",
    "                                       TRUE~deces_covid_80plus)) \n",
    "\n",
    "rm(b__ined_covid_data_group_0_24)\n",
    "rm(b__ined_covid_data_group_0_4)\n",
    "rm(b__ined_covid_data_group_0_9)\n",
    "rm(b__ined_covid_data_group_10_19)\n",
    "rm(b__ined_covid_data_group_15_24)\n",
    "rm(b__ined_covid_data_group_20_29)\n",
    "rm(b__ined_covid_data_group_25_34)\n",
    "rm(b__ined_covid_data_group_25_44)\n",
    "rm(b__ined_covid_data_group_30_39)\n",
    "rm(b__ined_covid_data_group_35_44)\n",
    "rm(b__ined_covid_data_group_40_49)\n",
    "rm(b__ined_covid_data_group_45_54)\n",
    "rm(b__ined_covid_data_group_45_64)\n",
    "rm(b__ined_covid_data_group_5_14)\n",
    "rm(b__ined_covid_data_group_50_59)\n",
    "rm(b__ined_covid_data_group_55_64)\n",
    "rm(b__ined_covid_data_group_60_69)\n",
    "rm(b__ined_covid_data_group_65_74)\n",
    "rm(b__ined_covid_data_group_70_74)\n",
    "rm(b__ined_covid_data_group_70_79)\n",
    "rm(b__ined_covid_data_group_75_79)\n",
    "rm(b__ined_covid_data_group_75_84)\n",
    "rm(b__ined_covid_data_group_80_84)\n",
    "rm(b__ined_covid_data_group_80_89)\n",
    "rm(b__ined_covid_data_group_90_99)\n",
    "rm(b__ined_covid_data_group_80plus)\n",
    "rm(b__ined_covid_data_group_85_89)\n",
    "rm(b__ined_covid_data_group_85_94)\n",
    "rm(b__ined_covid_data_group_85plus)\n",
    "rm(b__ined_covid_data_group_90plus)\n",
    "rm(b__ined_covid_data_group_95plus)\n",
    "rm(b__ined_covid_data_group_100plus)\n",
    "rm(b__ined_covid_data_group_moins40)\n",
    "rm(b__ined_covid_data_group_moins50)\n",
    "rm(b__ined_covid_data_group_moins60)\n",
    "rm(b__ined_covid_data_group_moins70)\n",
    "rm(b__ined_covid_data)\n",
    "rm(b__ined_covid_data_group)\n",
    "rm(b__ined_covid_data_group_prec)\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <-b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  left_join(b__ined_covid_data_regroupe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a0654a-1f7f-4640-9b58-1d61c200b8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------------------------------------#\n",
    "#### Ajout du nom des pays et zone est-ouest ####\n",
    "#-----------------------------------------------#\n",
    "\n",
    "# Extraire les ID et noms des pays\n",
    "pays_geo_nom_zone <- ungroup(owid_covid_Europe_week) %>%\n",
    "\t\tselect(geo, location) %>%\n",
    "\t\tdistinct(geo, location)\n",
    "\n",
    "#ajouter les ID et noms des territoires de UK\n",
    "nom_anglais = data.frame(geo = c(\"EN\",\"NI\",\"SC\",\"WA\"), location = c(\"England\",\"Northern Ireland\",\"Scotland\",\"Wales\"))\n",
    "pays_geo_nom_zone <- pays_geo_nom_zone %>% rbind(nom_anglais)\n",
    "\n",
    "if (shallDeleteVars) rm(nom_anglais)\n",
    "if (shallDeleteVars) rm(owid_covid_Europe_week)\n",
    "\n",
    "# Ajouter une colonne zone pour indiquer si c'est un pays de l'Est ou de l'Ouest\n",
    "pays_geo_nom_zone <- pays_geo_nom_zone %>%\n",
    "\t\tmutate(zone=case_when( geo == \"AL\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"AM\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"BG\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"CY\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"EE\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"EL\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"FI\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"GE\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"HR\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"HU\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"LT\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"LV\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"ME\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"PL\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"RO\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"RS\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"SI\"~ \"Est\",\n",
    "\t\t\t\t\t\tgeo == \"SK\"~ \"Est\",\n",
    "\t\t\t\t\t\tTRUE~ \"Ouest\", ))\n",
    "\n",
    "# Ajouter les colonnes avec les id, nom et zone des pays\n",
    "b__es_deces_et_pop_par_annee <- left_join(b__es_deces_et_pop_par_annee,\n",
    "\t\tpays_geo_nom_zone)\n",
    "\n",
    "# Reorganiser les colonnes\n",
    "b__es_deces_et_pop_par_annee <- b__es_deces_et_pop_par_annee %>%\n",
    "\t\tselect(geo | location:zone | time | population | pop2020 | deces | deces2020 | deces_theo_si_pop_2020 | surmortalite2020 | everything() )\n",
    "\n",
    "\n",
    "#Ajouter les colonnes avec les id, nom et zone des pays\n",
    "b__es_deces_et_pop_par_annee_agequinq <- left_join(b__es_deces_et_pop_par_annee_agequinq,\n",
    "\t\tpays_geo_nom_zone)\n",
    "\n",
    "# Reorganiser les colonnes\n",
    "b__es_deces_et_pop_par_annee_agequinq <- b__es_deces_et_pop_par_annee_agequinq %>%\n",
    "\t\tselect(geo | location:zone | sex:time | population | pop2020 | pop_france2020 | deces | deces2020 | deces_theo_si_pop_2020 | surmortalite2020 | everything() )\n",
    "\n",
    "\n",
    "#Ajouter les colonnes avec les id, nom et zone des pays\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(b__es_deces_week_standardises_si_pop_2020_owid_vaccination,\n",
    "\t\tpays_geo_nom_zone)\n",
    "\n",
    "# Réordonner les colonnes\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tselect(geo | location | zone | time | numSemaineDepuis2013 | everything())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b1760e-896b-4fca-a045-a369d6e8cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo)`\n",
      "\u001b[1m\u001b[22mJoining with `by = join_by(geo, numSemaineDepuis2013)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-----------------------------------------------------------#\n",
    "#### complement de donnees pour etude de la surmortalite ####\n",
    "#-----------------------------------------------------------#\n",
    "\n",
    "# Ajout colonne deces_hors_covid\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(deces_hors_covid = deces_tot - new_deaths)\n",
    "\n",
    "# Ajout colonne part_deces_covid\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(part_deces_covid = new_deaths / deces_tot)\n",
    "#----------------------------------------------------------------------#\n",
    "#### Calcul des binf, bsup, moyenne, surmortalité par tranche d'âge ####\n",
    "#----------------------------------------------------------------------#\n",
    "\n",
    "#-----#\n",
    "#Total#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tgroup_by(geo) %>% \n",
    "\t\tsummarise(\n",
    "\t\t\t\tmoyenne = mean(deces_standardises_si_pop_2020), \n",
    "\t\t\t\tvariance = sd(deces_standardises_si_pop_2020)) %>%\n",
    "\t\tmutate(\n",
    "\t\t\t\tbsup = moyenne + 1.5 * variance,\n",
    "\t\t\t\tbinf = moyenne - 1.5 * variance )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "\t\tb__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "\t\tIC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(surmortalite = case_when(\n",
    "\t\t\t\t\t\tdeces_standardises_si_pop_2020 <= binf ~ \"sous-mortalite\",\n",
    "\t\t\t\t\t\tdeces_standardises_si_pop_2020 >= bsup ~ \"surmortalite\",\n",
    "\t\t\t\t\t\tTRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(valeur_surmortalite = case_when(\n",
    "\t\t\t\t\t\tsurmortalite == \"sous-mortalite\" ~ deces_standardises_si_pop_2020 - binf,\n",
    "\t\t\t\t\t\tsurmortalite == \"surmortalite\" ~ deces_standardises_si_pop_2020 - bsup,\n",
    "\t\t\t\t\t\tTRUE ~ 0)) %>%\n",
    "\t\tmutate(part_surmortalite = valeur_surmortalite / deces_standardises_si_pop_2020 * 100) %>%\n",
    "\t\tmutate(ecart_moyenne_relatif = (deces_standardises_si_pop_2020 - moyenne) / moyenne * 100) %>%\n",
    "  mutate(ecart_moyenne = (deces_standardises_si_pop_2020 - moyenne))\n",
    "\n",
    "#-----#\n",
    "#15-24#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_15_24 = mean(deces_standardises_si_pop_2020_15_24), \n",
    "    variance_15_24 = sd(deces_standardises_si_pop_2020_15_24)) %>%\n",
    "  mutate(\n",
    "    bsup_15_24 = moyenne_15_24 + 1.5 * variance_15_24,\n",
    "    binf_15_24 = moyenne_15_24 - 1.5 * variance_15_24 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_15_24 = case_when(\n",
    "    deces_standardises_si_pop_2020_15_24 <= binf_15_24 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_15_24 >= bsup_15_24 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_15_24 = case_when(\n",
    "    surmortalite_15_24 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_15_24 - binf_15_24,\n",
    "    surmortalite_15_24 == \"surmortalite\" ~ deces_standardises_si_pop_2020_15_24 - bsup_15_24,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_15_24 = valeur_surmortalite_15_24 / deces_standardises_si_pop_2020_15_24 * 100) %>%\n",
    "  mutate(ecart_moyenne_15_24_relatif = (deces_standardises_si_pop_2020_15_24 - moyenne_15_24) / moyenne_15_24 * 100)%>%\n",
    "  mutate(ecart_moyenne_15_24 = (deces_standardises_si_pop_2020_15_24 - moyenne_15_24))\n",
    "\n",
    "#-----#\n",
    "#25-49#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_25_49 = mean(deces_standardises_si_pop_2020_25_49), \n",
    "    variance_25_49 = sd(deces_standardises_si_pop_2020_25_49)) %>%\n",
    "  mutate(\n",
    "    bsup_25_49 = moyenne_25_49 + 1.5 * variance_25_49,\n",
    "    binf_25_49 = moyenne_25_49 - 1.5 * variance_25_49 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_25_49 = case_when(\n",
    "    deces_standardises_si_pop_2020_25_49 <= binf_25_49 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_25_49 >= bsup_25_49 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_25_49 = case_when(\n",
    "    surmortalite_25_49 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_25_49 - binf_25_49,\n",
    "    surmortalite_25_49 == \"surmortalite\" ~ deces_standardises_si_pop_2020_25_49 - bsup_25_49,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_25_49 = valeur_surmortalite_25_49 / deces_standardises_si_pop_2020_25_49 * 100) %>%\n",
    "  mutate(ecart_moyenne_25_49_relatif = (deces_standardises_si_pop_2020_25_49 - moyenne_25_49) / moyenne_25_49 * 100)%>%\n",
    "  mutate(ecart_moyenne_25_49 = (deces_standardises_si_pop_2020_25_49 - moyenne_25_49))\n",
    "\n",
    "#-----#\n",
    "#50-59#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_50_59 = mean(deces_standardises_si_pop_2020_50_59), \n",
    "    variance_50_59 = sd(deces_standardises_si_pop_2020_50_59)) %>%\n",
    "  mutate(\n",
    "    bsup_50_59 = moyenne_50_59 + 1.5 * variance_50_59,\n",
    "    binf_50_59 = moyenne_50_59 - 1.5 * variance_50_59 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_50_59 = case_when(\n",
    "    deces_standardises_si_pop_2020_50_59 <= binf_50_59 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_50_59 >= bsup_50_59 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_50_59 = case_when(\n",
    "    surmortalite_50_59 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_50_59 - binf_50_59,\n",
    "    surmortalite_50_59 == \"surmortalite\" ~ deces_standardises_si_pop_2020_50_59 - bsup_50_59,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_50_59 = valeur_surmortalite_50_59 / deces_standardises_si_pop_2020_50_59 * 100) %>%\n",
    "  mutate(ecart_moyenne_50_59_relatif = (deces_standardises_si_pop_2020_50_59 - moyenne_50_59) / moyenne_50_59 * 100)%>%\n",
    "  mutate(ecart_moyenne_50_59 = (deces_standardises_si_pop_2020_50_59 - moyenne_50_59))\n",
    "\n",
    "#-----#\n",
    "#60-69#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_60_69 = mean(deces_standardises_si_pop_2020_60_69), \n",
    "    variance_60_69 = sd(deces_standardises_si_pop_2020_60_69)) %>%\n",
    "  mutate(\n",
    "    bsup_60_69 = moyenne_60_69 + 1.5 * variance_60_69,\n",
    "    binf_60_69 = moyenne_60_69 - 1.5 * variance_60_69 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_60_69 = case_when(\n",
    "    deces_standardises_si_pop_2020_60_69 <= binf_60_69 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_60_69 >= bsup_60_69 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_60_69 = case_when(\n",
    "    surmortalite_60_69 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_60_69 - binf_60_69,\n",
    "    surmortalite_60_69 == \"surmortalite\" ~ deces_standardises_si_pop_2020_60_69 - bsup_60_69,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_60_69 = valeur_surmortalite_60_69 / deces_standardises_si_pop_2020_60_69 * 100) %>%\n",
    "  mutate(ecart_moyenne_60_69_relatif = (deces_standardises_si_pop_2020_60_69 - moyenne_60_69) / moyenne_60_69 * 100)%>%\n",
    "  mutate(ecart_moyenne_60_69 = (deces_standardises_si_pop_2020_60_69 - moyenne_60_69))\n",
    "\n",
    "\n",
    "#-----#\n",
    "#70-79#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_70_79 = mean(deces_standardises_si_pop_2020_70_79), \n",
    "    variance_70_79 = sd(deces_standardises_si_pop_2020_70_79)) %>%\n",
    "  mutate(\n",
    "    bsup_70_79 = moyenne_70_79 + 1.5 * variance_70_79,\n",
    "    binf_70_79 = moyenne_70_79 - 1.5 * variance_70_79 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_70_79 = case_when(\n",
    "    deces_standardises_si_pop_2020_70_79 <= binf_70_79 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_70_79 >= bsup_70_79 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_70_79 = case_when(\n",
    "    surmortalite_70_79 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_70_79 - binf_70_79,\n",
    "    surmortalite_70_79 == \"surmortalite\" ~ deces_standardises_si_pop_2020_70_79 - bsup_70_79,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_70_79 = valeur_surmortalite_70_79 / deces_standardises_si_pop_2020_70_79 * 100) %>%\n",
    "  mutate(ecart_moyenne_70_79_relatif = (deces_standardises_si_pop_2020_70_79 - moyenne_70_79) / moyenne_70_79 * 100)%>%\n",
    "  mutate(ecart_moyenne_70_79 = (deces_standardises_si_pop_2020_70_79 - moyenne_70_79))\n",
    "\n",
    "\n",
    "\n",
    "#-----#\n",
    "# ge80#\n",
    "#-----#\n",
    "\n",
    "# Calcul des colonnes moyenne, variance, bsup, binf\n",
    "IC_deces <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  filter(numSemaineDepuis2013 > 287 ) %>% \n",
    "  group_by(geo) %>% \n",
    "  summarise(\n",
    "    moyenne_ge80 = mean(deces_standardises_si_pop_2020_ge80), \n",
    "    variance_ge80 = sd(deces_standardises_si_pop_2020_ge80)) %>%\n",
    "  mutate(\n",
    "    bsup_ge80 = moyenne_ge80 + 1.5 * variance_ge80,\n",
    "    binf_ge80 = moyenne_ge80 - 1.5 * variance_ge80 )\n",
    "\n",
    "# Ajout des colonnes moyenne, variance, bsup, binf\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "  b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \n",
    "  IC_deces)\n",
    "\n",
    "rm(IC_deces)\n",
    "\n",
    "# Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(surmortalite_ge80 = case_when(\n",
    "    deces_standardises_si_pop_2020_ge80 <= binf_ge80 ~ \"sous-mortalite\",\n",
    "    deces_standardises_si_pop_2020_ge80 >= bsup_ge80 ~ \"surmortalite\",\n",
    "    TRUE ~ \"mortalite normale\"))\n",
    "\n",
    "# Valeurs de Sur-mortalité et sous-mortalité (lorsque ça dépasse les bornes)\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "  mutate(valeur_surmortalite_ge80 = case_when(\n",
    "    surmortalite_ge80 == \"sous-mortalite\" ~ deces_standardises_si_pop_2020_ge80 - binf_ge80,\n",
    "    surmortalite_ge80 == \"surmortalite\" ~ deces_standardises_si_pop_2020_ge80 - bsup_ge80,\n",
    "    TRUE ~ 0)) %>%\n",
    "  mutate(part_surmortalite_ge80 = valeur_surmortalite_ge80 / deces_standardises_si_pop_2020_ge80 * 100) %>%\n",
    "  mutate(ecart_moyenne_ge80_relatif = (deces_standardises_si_pop_2020_ge80 - moyenne_ge80) / moyenne_ge80 * 100)%>%\n",
    "  mutate(ecart_moyenne_ge80 = (deces_standardises_si_pop_2020_ge80 - moyenne_ge80))\n",
    "\n",
    "\n",
    "# Créer un tableau avec les colonnes \"_prec\" qui correspondront après le left-join aux valeurs de la semaine précédente\n",
    "# grâce au décalage de 1 semaine\n",
    "\n",
    "valeurs_de_la_semaine_precedente <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate (numSemaineDepuis2013 = numSemaineDepuis2013 + 1, \n",
    "\t\t\t\tdeces_standard_tot_prec = deces_standardises_si_pop_2020, \n",
    "\t\t\t\tnew_deaths_prec= new_deaths,\n",
    "\t\t\t\tdeces_tot_prec = deces_tot,\n",
    "\t\t\t\tnew_cases_prec = new_cases,\n",
    "\t\t\t\tnew_vaccinations_prec = new_vaccinations,\n",
    "\t\t\t\tResponse_measure_prec = Response_measure,\n",
    "\t\t\t\t#21\n",
    "\t\t\t\tsurmortalite_prec = surmortalite) %>%\n",
    "\t\tselect(geo, \n",
    "\t\t\t\tnumSemaineDepuis2013, \n",
    "\t\t\t\tdeces_standard_tot_prec, \n",
    "\t\t\t\tnew_deaths_prec, \n",
    "\t\t\t\tdeces_tot_prec, \n",
    "\t\t\t\tnew_cases_prec, \n",
    "\t\t\t\tnew_vaccinations_prec, \n",
    "\t\t\t\tResponse_measure_prec, \n",
    "\t\t\t\tsurmortalite_prec)\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- left_join(\n",
    "\t\tb__es_deces_week_standardises_si_pop_2020_owid_vaccination , \n",
    "\t\tvaleurs_de_la_semaine_precedente)\n",
    "\n",
    "rm(valeurs_de_la_semaine_precedente)\n",
    "\n",
    "# Ajouter les colonnes de variation des données entre la semaine précédente et la semaine courante\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>%\n",
    "\t\tmutate(\n",
    "\t\t\t\tdeces_tot_var = deces_tot - deces_tot_prec,\n",
    "\t\t\t\tdeces_standard_tot_var = deces_standardises_si_pop_2020 - deces_standard_tot_prec,\n",
    "\t\t\t\tnew_deaths_var = new_deaths - new_deaths_prec,\n",
    "\t\t\t\tnew_cases_var = new_cases - new_cases_prec,\n",
    "\t\t\t\tnew_vaccinations_var = new_vaccinations - new_vaccinations_prec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad27a9-13e6-4c35-9a74-ec7158eb4616",
   "metadata": {},
   "source": [
    "## Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### \n",
    "\n",
    "_**J'ai séparé en 5 parties, puis plus, ce gros traitement, pour isoler la plus petite partie qui me fait péter la mémoire du kernel R**_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e5f5b2e-b9af-4efa-8290-6a7e7a3b27b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_15_24)`.”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_25_49)`.”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_50_59)`.”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_60_69)`.”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_70_79)`.”\n",
      "Warning message:\n",
      "“\u001b[1m\u001b[22m`cols` is now required when using `unnest()`.\n",
      "\u001b[36mℹ\u001b[39m Please use `cols = c(data.y, predit_plus_80)`.”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##-------------------------------------------------------------------------------------##\n",
    "#\n",
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### PARTIE 1\n",
    "#\n",
    "##-------------------------------------------------------------------------------------##\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  mutate(semaine = str_sub(time,6,8),\n",
    "         annee= as.numeric(str_sub(time,1,4)))\n",
    "\n",
    "\n",
    "annees_13_18 <- ungroup(b__es_deces_week_standardises_si_pop_2020_owid_vaccination) %>% \n",
    "  filter(!(str_sub(time,1,4)==\"2019\"|str_sub(time,1,4)==\"2020\"|str_sub(time,1,4)==\"2021\"|str_sub(time,1,4)==\"2022\"|str_sub(time,1,4)==\"2023\"|str_sub(time,1,4)==\"2024\"))%>%\n",
    "  select(semaine,annee,geo,\n",
    "         deces_tot_15_24,\n",
    "         deces_tot_25_49,\n",
    "         deces_tot_50_59,\n",
    "         deces_tot_60_69,\n",
    "         deces_tot_70_79,\n",
    "         deces_tot_plus_80)\n",
    "\n",
    "donnees_semaine_pays<-b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  select(semaine, annee ,geo) \n",
    "\n",
    "\n",
    "donnees_semaine_pays_hors_allemagne <- donnees_semaine_pays %>% filter(geo!=\"DE\")\n",
    "\n",
    "#faire la régression linéaire de chaque semaine pour tous les âges\n",
    "\n",
    "\n",
    "#15-24 ans\n",
    "  \n",
    "  res15_24<- annees_13_18 %>%\n",
    "    group_by(semaine,geo) %>%\n",
    "    nest() %>%\n",
    "    inner_join(donnees_semaine_pays_hors_allemagne %>% group_by(semaine,geo) %>% nest(),\n",
    "               by = c(\"semaine\",\"geo\")) %>%\n",
    "    mutate(model = data.x %>% map(~lm(deces_tot_15_24 ~ annee, data=.)),\n",
    "           predit_15_24 = map2(model, data.y, predict)) %>% \n",
    "    select(-data.x, -model) %>%\n",
    "    unnest() \n",
    "\n",
    "\n",
    "#25-49 ans\n",
    "\n",
    "res25_49<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_tot_25_49 ~ annee, data=.)),\n",
    "         predit_25_49 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest() \n",
    "\n",
    "#50_59 ans\n",
    "\n",
    "res50_59<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_tot_50_59 ~ annee, data=.)),\n",
    "         predit_50_59 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest() \n",
    "\n",
    "#60_69 ans\n",
    "\n",
    "res60_69<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_tot_60_69 ~ annee, data=.)),\n",
    "         predit_60_69 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()  \n",
    "\n",
    "#70_79 ans\n",
    "\n",
    "res70_79<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_tot_70_79 ~ annee, data=.)),\n",
    "         predit_70_79 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()   \n",
    "\n",
    "#plus_80 ans\n",
    "\n",
    "resplus_80<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_tot_plus_80 ~ annee, data=.)),\n",
    "         predit_plus_80 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7934807-0837-4f5b-96b7-406fea0fcee2",
   "metadata": {},
   "source": [
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018: Jointure à gauche sur les tranches d'âge\n",
    "\n",
    "_**Celui-là ci-dessous, c'est la plus petite partie qui me fait péter la mémoire du kernel R**_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea9b64-0670-4985-ab92-9cdff42b6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in left_join(., res15_24, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res25_49, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res50_59, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res60_69, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##-------------------------------------------------------------------------------------##\n",
    "#\n",
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### PARTIE 2 \n",
    "#\n",
    "##-------------------------------------------------------------------------------------##\n",
    "\n",
    "#jointure\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination<-b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "    left_join(res15_24, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "    left_join(res25_49, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "    left_join(res50_59, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "    left_join(res60_69, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "    left_join(res70_79, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "    left_join(resplus_80, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  mutate(predit_15_24= if_else(predit_15_24<0,0,predit_15_24),\n",
    "         predit_25_49= if_else(predit_25_49<0,0,predit_25_49),\n",
    "         predit_50_59= if_else(predit_50_59<0,0,predit_50_59),\n",
    "         predit_60_69= if_else(predit_60_69<0,0,predit_60_69),\n",
    "         predit_70_79= if_else(predit_70_79<0,0,predit_70_79),\n",
    "         predit_plus_80= if_else(predit_plus_80<0,0,predit_plus_80)) %>% \n",
    "    mutate(diff_deces_tot_predit_15_24=deces_tot_15_24 -predit_15_24,\n",
    "           diff_deces_tot_predit_25_49=deces_tot_25_49 -predit_25_49,\n",
    "           diff_deces_tot_predit_50_59=deces_tot_50_59 - predit_50_59,\n",
    "           diff_deces_tot_predit_60_69=deces_tot_60_69 - predit_60_69,\n",
    "           diff_deces_tot_predit_70_79=deces_tot_70_79 - predit_70_79,\n",
    "           diff_deces_tot_predit_ge80=deces_tot_plus_80 - predit_plus_80) %>% \n",
    "    mutate(pos_diff_deces_tot_predit_15_24=(diff_deces_tot_predit_15_24>0),\n",
    "           pos_diff_deces_tot_predit_25_49=(diff_deces_tot_predit_25_49>0),\n",
    "           pos_diff_deces_tot_predit_50_59=(diff_deces_tot_predit_50_59>0),\n",
    "           pos_diff_deces_tot_predit_60_69=(diff_deces_tot_predit_60_69>0),\n",
    "           pos_diff_deces_tot_predit_70_79=(diff_deces_tot_predit_70_79>0),\n",
    "           pos_diff_deces_tot_predit_plus_80=(diff_deces_tot_predit_ge80>0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad7728b-f46c-406e-995c-5d6cb15f1dd5",
   "metadata": {},
   "source": [
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018: Faire la régression sur les décès standards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762fb4a2-2f75-4887-9760-31a8aefa57ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in left_join(., res15_24, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res25_49, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res50_59, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res60_69, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n"
     ]
    }
   ],
   "source": [
    "##-------------------------------------------------------------------------------------##\n",
    "#\n",
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### PARTIE 3\n",
    "#\n",
    "##-------------------------------------------------------------------------------------##\n",
    "\n",
    "#Faire la régression sur les décès standards\n",
    "\n",
    "annees_13_18 <- ungroup(b__es_deces_week_standardises_si_pop_2020_owid_vaccination) %>% \n",
    "  filter(!(str_sub(time,1,4)==\"2019\"|str_sub(time,1,4)==\"2020\"|str_sub(time,1,4)==\"2021\"|str_sub(time,1,4)==\"2022\"|str_sub(time,1,4)==\"2023\"|str_sub(time,1,4)==\"2024\"))%>%\n",
    "  filter(geo!=\"UK\") %>% \n",
    "  select(semaine,annee,geo,\n",
    "         deces_standardises_si_pop_2020_15_24,\n",
    "         deces_standardises_si_pop_2020_25_49,\n",
    "         deces_standardises_si_pop_2020_50_59,\n",
    "         deces_standardises_si_pop_2020_60_69,\n",
    "         deces_standardises_si_pop_2020_70_79,\n",
    "         deces_standardises_si_pop_2020_ge80)\n",
    "\n",
    "\n",
    "\n",
    "donnees_semaine_pays<-b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  select(semaine, annee ,geo) \n",
    "\n",
    "\n",
    "donnees_semaine_pays_hors_allemagne <- donnees_semaine_pays %>% filter(geo!=\"DE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac4647-5de9-4576-b40f-35ea4e7c20ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in left_join(., res15_24, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res25_49, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res50_59, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res60_69, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##-------------------------------------------------------------------------------------##\n",
    "#\n",
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### PARTIE 4 \n",
    "#\n",
    "##-------------------------------------------------------------------------------------##\n",
    "\n",
    "\n",
    "#faire la régression linéaire de chaque semaine pour tous les âges\n",
    "\n",
    "\n",
    "#15-24 ans\n",
    "\n",
    "res15_24<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays_hors_allemagne %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_15_24 ~ annee, data=.)),\n",
    "         predit_stand_15_24 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest() \n",
    "\n",
    "\n",
    "#25-49 ans\n",
    "\n",
    "res25_49<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_25_49 ~ annee, data=.)),\n",
    "         predit_stand_25_49 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest() \n",
    "\n",
    "#50_59 ans\n",
    "\n",
    "res50_59<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_50_59 ~ annee, data=.)),\n",
    "         predit_stand_50_59 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest() \n",
    "\n",
    "#60_69 ans\n",
    "\n",
    "res60_69<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_60_69 ~ annee, data=.)),\n",
    "         predit_stand_60_69 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()  \n",
    "\n",
    "#70_79 ans\n",
    "\n",
    "res70_79<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_70_79 ~ annee, data=.)),\n",
    "         predit_stand_70_79 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()   \n",
    "\n",
    "#plus_80 ans\n",
    "\n",
    "resplus_80<- annees_13_18 %>%\n",
    "  group_by(semaine,geo) %>%\n",
    "  nest() %>%\n",
    "  inner_join(donnees_semaine_pays %>% group_by(semaine,geo) %>% nest(),\n",
    "             by = c(\"semaine\",\"geo\")) %>%\n",
    "  mutate(model = data.x %>% map(~lm(deces_standardises_si_pop_2020_ge80 ~ annee, data=.)),\n",
    "         predit_stand_plus_80 = map2(model, data.y, predict)) %>% \n",
    "  select(-data.x, -model) %>%\n",
    "  unnest()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d4b2f6-8fdf-453c-86dd-f1e6a4f51b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in left_join(., res15_24, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res25_49, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res50_59, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n",
      "Warning message in left_join(., res60_69, by = c(\"semaine\", \"annee\", \"geo\")):\n",
      "“\u001b[1m\u001b[22mDetected an unexpected many-to-many relationship between `x` and `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 2 of `x` matches multiple rows in `y`.\n",
      "\u001b[36mℹ\u001b[39m Row 28 of `y` matches multiple rows in `x`.\n",
      "\u001b[36mℹ\u001b[39m If a many-to-many relationship is expected, set `relationship =\n",
      "  \"many-to-many\"` to silence this warning.”\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##-------------------------------------------------------------------------------------##\n",
    "#\n",
    "#### Insertion d'une régression linéaire des décès hebdomadaires basée sur 2013-2018 #### PARTIE 5 \n",
    "#\n",
    "##-------------------------------------------------------------------------------------##\n",
    "\n",
    "#jointure\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination<-b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  left_join(res15_24, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  left_join(res25_49, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  left_join(res50_59, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  left_join(res60_69, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  left_join(res70_79, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  left_join(resplus_80, by = c(\"semaine\",\"annee\",\"geo\")) %>% \n",
    "  mutate(predit_stand_15_24= if_else(predit_stand_15_24<0,0,predit_stand_15_24),\n",
    "         predit_stand_25_49= if_else(predit_stand_25_49<0,0,predit_stand_25_49),\n",
    "         predit_stand_50_59= if_else(predit_stand_50_59<0,0,predit_stand_50_59),\n",
    "         predit_stand_60_69= if_else(predit_stand_60_69<0,0,predit_stand_60_69),\n",
    "         predit_stand_70_79= if_else(predit_stand_70_79<0,0,predit_stand_70_79),\n",
    "         predit_stand_plus_80= if_else(predit_stand_plus_80<0,0,predit_stand_plus_80)) %>% \n",
    "  mutate(diff_deces_tot_predit_stand_15_24=deces_standardises_si_pop_2020_15_24 - predit_stand_15_24,\n",
    "         diff_deces_tot_predit_stand_25_49=deces_standardises_si_pop_2020_25_49 -predit_stand_25_49,\n",
    "         diff_deces_tot_predit_stand_50_59=deces_standardises_si_pop_2020_50_59 -predit_stand_50_59,\n",
    "         diff_deces_tot_predit_stand_60_69=deces_standardises_si_pop_2020_60_69 - predit_stand_60_69,\n",
    "         diff_deces_tot_predit_stand_70_79=deces_standardises_si_pop_2020_70_79 - predit_stand_70_79,\n",
    "         diff_deces_tot_predit_stand_ge80=deces_standardises_si_pop_2020_ge80 - predit_stand_plus_80) %>% \n",
    "  mutate(pos_diff_deces_tot_predit_stand_15_24=(diff_deces_tot_predit_stand_15_24>0),\n",
    "         pos_diff_deces_tot_predit_stand_25_49=(diff_deces_tot_predit_stand_25_49>0),\n",
    "         pos_diff_deces_tot_predit_stand_50_59=(diff_deces_tot_predit_stand_50_59>0),\n",
    "         pos_diff_deces_tot_predit_stand_60_69=(diff_deces_tot_predit_stand_60_69>0),\n",
    "         pos_diff_deces_tot_predit_stand_70_79=(diff_deces_tot_predit_stand_70_79>0),\n",
    "         pos_diff_deces_tot_predit_stand_plus_80=(diff_deces_tot_predit_stand_ge80>0))\n",
    "\n",
    "rm(res15_24)\n",
    "rm(res25_49)\n",
    "rm(res50_59)\n",
    "rm(res60_69)\n",
    "rm(res70_79)\n",
    "rm(resplus_80)\n",
    "rm(annees_13_18)\n",
    "\n",
    "#Calculer les z-scores\n",
    "\n",
    "#Calculer la variance du modèle\n",
    "\n",
    "sigma<- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  select (diff_deces_tot_predit_15_24,\n",
    "          diff_deces_tot_predit_25_49,\n",
    "          diff_deces_tot_predit_50_59,\n",
    "          diff_deces_tot_predit_60_69,\n",
    "          diff_deces_tot_predit_70_79,\n",
    "          diff_deces_tot_predit_ge80,\n",
    "          geo, semaine) %>%\n",
    "  mutate(carre15_24 = diff_deces_tot_predit_15_24*diff_deces_tot_predit_15_24,\n",
    "         carre25_49 = diff_deces_tot_predit_25_49*diff_deces_tot_predit_25_49,\n",
    "         carre50_59 = diff_deces_tot_predit_50_59*diff_deces_tot_predit_50_59,\n",
    "         carre60_69 = diff_deces_tot_predit_60_69*diff_deces_tot_predit_60_69,\n",
    "         carre70_79 = diff_deces_tot_predit_70_79*diff_deces_tot_predit_70_79,\n",
    "         carrege80 = diff_deces_tot_predit_ge80*diff_deces_tot_predit_ge80)\n",
    "\n",
    "sigma <- sigma %>% group_by(geo,semaine) %>% \n",
    "  summarise(sigma15_24=sum(carre15_24)/6,\n",
    "            sigma25_49=sum(carre25_49)/6,\n",
    "            sigma50_59=sum(carre50_59)/6,\n",
    "            sigma60_69=sum(carre60_69)/6,\n",
    "            sigma70_79=sum(carre70_79)/6,\n",
    "            sigmage80=sum(carrege80)/6)\n",
    "\n",
    "#jointure\n",
    "  \n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  left_join(sigma)\n",
    "\n",
    "if (shallDeleteVars) rm(sigma)\n",
    "\n",
    "#calcul des z-scores\n",
    "\n",
    "b__es_deces_week_standardises_si_pop_2020_owid_vaccination <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  mutate(z_score_15_24 = diff_deces_tot_predit_15_24/sigma15_24,\n",
    "         z_score_25_49 = diff_deces_tot_predit_15_24/sigma25_49,\n",
    "         z_score_50_59 = diff_deces_tot_predit_15_24/sigma50_59,\n",
    "         z_score_60_69 = diff_deces_tot_predit_15_24/sigma60_69,\n",
    "         z_score_70_79 = diff_deces_tot_predit_15_24/sigma70_79,\n",
    "         z_score_ge80 = diff_deces_tot_predit_15_24/sigmage80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815bc11f-5da7-43be-99af-d67ee848d450",
   "metadata": {},
   "source": [
    "\n",
    "# Sauvegarde des Tables finales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53c54a-e31b-4305-8be4-14566a25beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##----------------------------------------------------------------------------##\n",
    "#\n",
    "#### Sauvegarde des Tables finales ####\n",
    "#\n",
    "##----------------------------------------------------------------------------##\n",
    "\n",
    "#\n",
    "#Table Patrick\n",
    "#\n",
    "\n",
    "patrick <- b__es_deces_week_standardises_si_pop_2020_owid_vaccination %>% \n",
    "  select(geo,location,time,numSemaineDepuis2013,Response_measure,deces_tot,deces_standardises_si_pop_2020,\n",
    "         deces_tot_15_24,deces_standardises_si_pop_2020_15_24,deces_tot_25_49,deces_standardises_si_pop_2020_25_49,\n",
    "         deces_tot_50_59,deces_standardises_si_pop_2020_50_59,deces_tot_60_69,deces_standardises_si_pop_2020_60_69,\n",
    "         deces_tot_70_79,deces_standardises_si_pop_2020_70_79,deces_tot_plus_80,deces_standardises_si_pop_2020_ge80,\n",
    "         predit_15_24,predit_25_49,predit_50_59,predit_60_69,predit_70_79,predit_plus_80,\n",
    "         predit_stand_15_24,predit_stand_25_49,predit_stand_50_59,predit_stand_60_69,predit_stand_70_79,predit_stand_plus_80,\n",
    "         `Age<18_dose1`,Age0_4_dose1,Age10_14_dose1,Age15_17_dose1,Age18_24_dose1,Age25_49_dose1,Age5_9_dose1,\n",
    "         Age50_59_dose1,Age60_69_dose1,Age70_79_dose1,`Age80+_dose1`,\n",
    "         `Age<18_dose2`,Age0_4_dose2,Age10_14_dose2,Age15_17_dose2,Age18_24_dose2,Age25_49_dose2,Age5_9_dose2,\n",
    "         Age50_59_dose2,Age60_69_dose2,Age70_79_dose2,`Age80+_dose2`,\n",
    "         `Age<18_dose3`,Age0_4_dose3,Age10_14_dose3,Age15_17_dose3,Age18_24_dose3,Age25_49_dose3,Age5_9_dose3,\n",
    "         Age50_59_dose3,Age60_69_dose3,Age70_79_dose3,`Age80+_dose3`,\n",
    "         deces_covid_0_4,deces_covid_0_9,deces_covid_0_24,deces_covid_10_19,deces_covid_15_24,deces_covid_20_29,\n",
    "         deces_covid_25_34,deces_covid_25_44,deces_covid_30_39,deces_covid_35_44,deces_covid_40_49,deces_covid_45_54,\n",
    "         deces_covid_45_64,deces_covid_50_59,deces_covid_55_64,deces_covid_5_14,deces_covid_60_69,deces_covid_65_74,\n",
    "         deces_covid_70_74,deces_covid_70_79,deces_covid_75_79,deces_covid_80plus,deces_covid_75_84,deces_covid_85plus,\n",
    "         deces_covid_moins40,deces_covid_moins50,deces_covid_moins60,\n",
    "         pop_week,pop_week_15_24,pop_week_25_49,pop_week_50_59,pop_week_60_69,pop_week_70_79,pop_week_ge80,\n",
    "         z_score_15_24,z_score_25_49,z_score_50_59,z_score_60_69,z_score_70_79,z_score_ge80)\n",
    "\n",
    "saveRDS(patrick, file=\"gen/rds/patrick.RDS\")\n",
    "\n",
    "if (shallDeleteVars) rm(patrick)\n",
    "\n",
    "\n",
    "#\n",
    "# Deces standardisés par pays, par semaine + confinements + vaccinations\n",
    "#\n",
    "\n",
    "saveRDS(b__es_deces_week_standardises_si_pop_2020_owid_vaccination, file=\"gen/rds/Eurostat_owid_deces_standard_pays_semaine.RDS\")\n",
    "\n",
    "# Generer un csv séparé par \"t\"\n",
    "write.table(b__es_deces_week_standardises_si_pop_2020_owid_vaccination, \"gen/csv/Eurostat_owid_deces_standard_pays_semaine.csv\", row.names=FALSE, sep=\"t\", dec=\",\", na=\" \")\n",
    "\n",
    "#\n",
    "# Deces théoriques par pays et par an\n",
    "#\n",
    "\n",
    "saveRDS(b__es_deces_et_pop_par_annee, file=\"gen/rds/Eurostat_deces_par_annee.RDS\")\n",
    "\n",
    "write.table(b__es_deces_et_pop_par_annee, \"gen/csv/Eurostat_deces_par_annee.csv\", row.names=FALSE, sep=\"t\", dec=\",\", na=\" \")\n",
    "\n",
    "\n",
    "#\n",
    "# Deces par tranche d'age\n",
    "#\n",
    "\n",
    "saveRDS(b__es_deces_et_pop_par_annee_agequinq, file=\"gen/rds/Eurostat_deces_par_annee_agequinq.RDS\")\n",
    "\n",
    "# Generer un tsv\n",
    "write.table(b__es_deces_et_pop_par_annee_agequinq, \"gen/csv/Eurostat_deces_par_annee_agequinq.csv\", row.names=FALSE, sep=\"t\", dec=\",\", na=\" \")\n",
    "\n",
    "\n",
    "if (shallDeleteVars) rm(pays_geo_nom_zone)\n",
    "\n",
    "if (shallDeleteVars) rm(deces2020)\n",
    "if (shallDeleteVars) rm(donnees_semaine_pays)\n",
    "if (shallDeleteVars) rm(donnees_semaine_pays_hors_allemagne)\n",
    "if (shallDeleteVars) rm(a__original_es_deces_annuel_le2020)\n",
    "if (shallDeleteVars) rm(a__original_es_deces_week)\n",
    "if (shallDeleteVars) rm(a__original_es_pjan_le2020)\n",
    "if (shallDeleteVars) rm(a__original_es_proj)\n",
    "if (shallDeleteVars) rm(a__original_eu_mesures)\n",
    "if (shallDeleteVars) rm(a__original_owid_covid_data)\n",
    "if (shallDeleteVars) rm(b__ined_covid_data_regroupe)\n",
    "if (shallDeleteVars) rm(b__owid_covid_data)\n",
    "\n",
    "message(\"Terminé 010\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
